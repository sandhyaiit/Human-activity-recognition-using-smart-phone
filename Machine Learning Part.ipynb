{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import default_timer to compute durations\n",
    "from timeit import default_timer as timer\n",
    "Debut=timer() # start time\n",
    "\n",
    "import numpy as np # import numpy library\n",
    "import pandas as pd # importing pandas library\n",
    "\n",
    "# scrapping file paths\n",
    "from glob import glob\n",
    "\n",
    "# Allows the use of display() for DataFrames\n",
    "from IPython.display import display \n",
    "\n",
    "from matplotlib import pyplot as plt # import matplot. pyplot to allow figure's plotting\n",
    "#plt.style.use('bmh') # for better plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# scrapping data files path\n",
    "DF_paths_list=sorted(glob(\"Data/New-Data/full_Datasets_type_I_and_II/*\"))\n",
    "display(DF_paths_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Importing Dataset type I and II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading datasets(these datasets are the outputs of the signal processing pipeline )\n",
    "Dataset_I_part1 = pd.read_csv('Dataset_I_part1.csv')\n",
    "Dataset_I_part2 = pd.read_csv('Dataset_I_part2.csv')\n",
    "Dataset_II_part1= pd.read_csv('Dataset_II_part1.csv')\n",
    "Dataset_II_part2= pd.read_csv('Dataset_II_part2.csv')\n",
    "\n",
    "# select parts two be conctenated\n",
    "frames_I=[Dataset_I_part1,Dataset_I_part2]\n",
    "frames_II=[Dataset_II_part1,Dataset_II_part2]\n",
    "\n",
    "# concatenate each dataframes' parts\n",
    "Dataset_type_I=pd.concat(frames_I)\n",
    "Dataset_type_II=pd.concat(frames_II)\n",
    "\n",
    "# index reset\n",
    "Dataset_type_I.reset_index(level=0, drop=True, inplace=True)\n",
    "Dataset_type_II.reset_index(level=0, drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Datasets Exploration and Exploratory Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.1. Datapoints number per each tuple (user,activity) function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns a table includes the number of \n",
    "# windows per each tuple(user_id , activity id) included in the dataset \n",
    "\n",
    "def num_row_user_act(Df):\n",
    "    \n",
    "    user_Ids=sorted(Df['user_Id'].unique()) # extracting and sorting unqiue user ids \n",
    "    activity_Ids=sorted(Df['activity_Id'].unique()) # extracting and sorting unqiue activity ids \n",
    "    act_columns=['Activity '+str(int(Id)) for Id in activity_Ids ] # defining column names used in output table\n",
    "    \n",
    "    if len(activity_Ids)==7: # adapting column names in case the function deals with dataset type III\n",
    "        act_columns=act_columns[0:6]+['P_Transitions'] \n",
    "    \n",
    "    users_index=['User '+ str(int(Id)) for Id in user_Ids] # defining rows names used in output table\n",
    "    \n",
    "    # counting the number of windows per each tuple(user_id,activity_id)\n",
    "    # store these values in 2D numpy array\n",
    "    data=np.array([ [len(Df[(Df[\"user_Id\"]== user_ID) &(Df[\"activity_Id\"]==activity_ID)]) \n",
    "               for activity_ID in activity_Ids ] for user_ID in user_Ids])\n",
    "    \n",
    "    # Create a pandas dataframe from the array above\n",
    "    win_per_act_per_user=pd.DataFrame(data = data,columns=act_columns,index=users_index)\n",
    "    \n",
    "    \n",
    "    return win_per_act_per_user # returns the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II.2. Visualizing Activities Distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##################################################################################\n",
    "# This function returns the weights activity and visualize the distribution of a column\n",
    "# This function will be applied only to target columns\n",
    "def visualize_column(Df,column):\n",
    "    \n",
    "    labels= sorted(Df[column].unique()) # extracting and sorting activity unique ids\n",
    "    Als_dict={ key: len(Df[Df[column]==key]) for key in labels} # counting the number of windows per activity\n",
    "    data=[Als_dict[key] for key in labels] # sorting these numbers\n",
    "    \n",
    "    weights=np.array(data)/float(np.array(data).sum()) # calculating weights of each activity\n",
    "    \n",
    "    columns=[\"Activity \"+str(int(key)) for key in labels] # defining columns of weights' table\n",
    "    \n",
    "    Df_weights=pd.DataFrame(data=None,columns=columns)# defining an empty dataframe with column names\n",
    "    Df_weights.loc['Weights']=weights # appending weights row\n",
    "    \n",
    "    print(\"_____ The weights of each activity _____\")\n",
    "    display(Df_weights) # displying weights table\n",
    "    print(\"\")\n",
    "    plt.bar(columns,data) # ploting activity distribution\n",
    "    plt.xlabel('Activity Labels') # set X axis info\n",
    "    plt.ylabel('Number of Data points') # set Y axis info\n",
    "    plt.title('Number of Data points per activity') # set the figure's title\n",
    "    plt.show() # showing the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration PipeLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_exploration_pipeline(Dataset,typ,outliers):\n",
    "    # inputs:\n",
    "    #        Dataset: a pandas dataframe can be a full dataset (I or II), \n",
    "    #               cleaned dataset(I or II or III), outliers dataset (I or II)\n",
    "    \n",
    "    #        typ    : integer type of the dataset possible values: 1(for dataset type I), 2(for type II) or 3 (for type III)\n",
    "    #        outliers: Boolean if true dataset we are dealing with is an outlier dataset(contain outlier values)         \n",
    "    \n",
    "    # columns names of the dataset\n",
    "    columns=Dataset.columns\n",
    "    \n",
    "    if not outliers:  # in case we are not dealing with outliers datasets  \n",
    "        # Adapting the dataset name switch the typ\n",
    "        if typ==1:\n",
    "            Dataset_name=\"Dataset type I \"\n",
    "        if typ==2:\n",
    "            Dataset_name=\"Dataset type II \"\n",
    "        if typ==3:\n",
    "            Dataset_name=\"Dataset type III \"\n",
    "    else:# in case we are dealing with outliers\n",
    "        \n",
    "        # adapting the dataset names switch the case\n",
    "        if typ==1:\n",
    "            Dataset_name=\"Outliers of Dataset type I \"\n",
    "        if typ==2:\n",
    "            Dataset_name=\"Outliers ofDataset type II \"\n",
    "    \n",
    "    # general info about the dataset: number of rows and columns\n",
    "    print(  Dataset_name+'has a shape of: '+ str(Dataset.shape[0]) +' rows and '+str(Dataset.shape[1])+' columns')\n",
    "    print(\"\")\n",
    "    print(\"\")    \n",
    "    print(\"\")\n",
    "    \n",
    "    if not outliers: # in case dataset is not an outlier dataset\n",
    "        print(\"The first 3 rows of \"+Dataset_name +\":\")\n",
    "        display(Dataset.iloc[0:3]) # display the first 3 rows\n",
    "        print(\"\")\n",
    "        print(\"\")    \n",
    "        print(\"\")\n",
    "        print(\"rows 500, 501, 502 of \"+Dataset_name +\":\")\n",
    "        display(Dataset.iloc[500:503]) # display rows 500,501 and 502\n",
    "        print(\"\")\n",
    "        print(\"\")    \n",
    "        print(\"\")\n",
    "        print(\"Description of the 10 first features:\")\n",
    "        display(Dataset.describe()[columns[0:10]]) # statistics of the first ten time domain features\n",
    "        print(\"\")\n",
    "        print(\"\")    \n",
    "        print(\"\")\n",
    "        print(\"Description of the 10 first frequency features:\")\n",
    "        display(Dataset.describe()[columns[265:275]]) # statistics of the first ten frequency domain features\n",
    "        print(\"\")\n",
    "        print(\"\")    \n",
    "        print(\"\")\n",
    "    Stats= num_row_user_act(Dataset)# generate number of windows per each tuple (user,activity)\n",
    "    print(\"Number of windows per user and per each activity:\")\n",
    "    display(Stats)# display the table\n",
    "    print(\"\")\n",
    "    print(\"\")    \n",
    "    print(\"\")\n",
    "    print(\"Statistics of table above:\")\n",
    "    display(Stats.describe())# table's statics\n",
    "    print(\"\")\n",
    "    print(\"\")    \n",
    "    print(\"\")\n",
    "    visualize_column(Dataset,\"activity_Id\") # visualize activity distribution of the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset type I has a shape of: 10399 rows and 642 columns\n",
      "\n",
      "\n",
      "\n",
      "The first 3 rows of Dataset type I :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_body_acc_mean()_X</th>\n",
       "      <th>t_body_acc_mean()_Y</th>\n",
       "      <th>t_body_acc_mean()_Z</th>\n",
       "      <th>t_body_acc_std()_X</th>\n",
       "      <th>t_body_acc_std()_Y</th>\n",
       "      <th>t_body_acc_std()_Z</th>\n",
       "      <th>t_body_acc_mad()_X</th>\n",
       "      <th>t_body_acc_mad()_Y</th>\n",
       "      <th>t_body_acc_mad()_Z</th>\n",
       "      <th>t_body_acc_max()_X</th>\n",
       "      <th>...</th>\n",
       "      <th>f_body_gyro_Jerk_Mag_kurtosis()</th>\n",
       "      <th>angle0()</th>\n",
       "      <th>angle1()</th>\n",
       "      <th>angle2()</th>\n",
       "      <th>angle3()</th>\n",
       "      <th>angle4()</th>\n",
       "      <th>angle5()</th>\n",
       "      <th>angle6()</th>\n",
       "      <th>activity_Id</th>\n",
       "      <th>user_Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.004441</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>0.013983</td>\n",
       "      <td>0.027372</td>\n",
       "      <td>0.004725</td>\n",
       "      <td>0.019132</td>\n",
       "      <td>0.025280</td>\n",
       "      <td>0.010209</td>\n",
       "      <td>...</td>\n",
       "      <td>104.954731</td>\n",
       "      <td>1.070749</td>\n",
       "      <td>1.431913</td>\n",
       "      <td>2.116867</td>\n",
       "      <td>1.431211</td>\n",
       "      <td>0.152888</td>\n",
       "      <td>1.692169</td>\n",
       "      <td>1.478284</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000713</td>\n",
       "      <td>-0.003098</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.004491</td>\n",
       "      <td>0.012449</td>\n",
       "      <td>0.022660</td>\n",
       "      <td>0.004168</td>\n",
       "      <td>0.014039</td>\n",
       "      <td>0.022765</td>\n",
       "      <td>0.009030</td>\n",
       "      <td>...</td>\n",
       "      <td>109.749747</td>\n",
       "      <td>1.652580</td>\n",
       "      <td>1.856253</td>\n",
       "      <td>1.210803</td>\n",
       "      <td>1.753009</td>\n",
       "      <td>0.149532</td>\n",
       "      <td>1.687352</td>\n",
       "      <td>1.477548</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000301</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>-0.004280</td>\n",
       "      <td>0.004866</td>\n",
       "      <td>0.009352</td>\n",
       "      <td>0.016821</td>\n",
       "      <td>0.005255</td>\n",
       "      <td>0.010157</td>\n",
       "      <td>0.020681</td>\n",
       "      <td>0.011261</td>\n",
       "      <td>...</td>\n",
       "      <td>110.445137</td>\n",
       "      <td>1.776612</td>\n",
       "      <td>1.159471</td>\n",
       "      <td>1.763958</td>\n",
       "      <td>2.682216</td>\n",
       "      <td>0.157004</td>\n",
       "      <td>1.696158</td>\n",
       "      <td>1.476770</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 642 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   t_body_acc_mean()_X  t_body_acc_mean()_Y  t_body_acc_mean()_Z  \\\n",
       "0             0.002012             0.000431             0.004441   \n",
       "1            -0.000713            -0.003098             0.000823   \n",
       "2            -0.000301             0.004025            -0.004280   \n",
       "\n",
       "   t_body_acc_std()_X  t_body_acc_std()_Y  t_body_acc_std()_Z  \\\n",
       "0            0.004025            0.013983            0.027372   \n",
       "1            0.004491            0.012449            0.022660   \n",
       "2            0.004866            0.009352            0.016821   \n",
       "\n",
       "   t_body_acc_mad()_X  t_body_acc_mad()_Y  t_body_acc_mad()_Z  \\\n",
       "0            0.004725            0.019132            0.025280   \n",
       "1            0.004168            0.014039            0.022765   \n",
       "2            0.005255            0.010157            0.020681   \n",
       "\n",
       "   t_body_acc_max()_X  ...  f_body_gyro_Jerk_Mag_kurtosis()  angle0()  \\\n",
       "0            0.010209  ...                       104.954731  1.070749   \n",
       "1            0.009030  ...                       109.749747  1.652580   \n",
       "2            0.011261  ...                       110.445137  1.776612   \n",
       "\n",
       "   angle1()  angle2()  angle3()  angle4()  angle5()  angle6()  activity_Id  \\\n",
       "0  1.431913  2.116867  1.431211  0.152888  1.692169  1.478284          5.0   \n",
       "1  1.856253  1.210803  1.753009  0.149532  1.687352  1.477548          5.0   \n",
       "2  1.159471  1.763958  2.682216  0.157004  1.696158  1.476770          5.0   \n",
       "\n",
       "   user_Id  \n",
       "0      1.0  \n",
       "1      1.0  \n",
       "2      1.0  \n",
       "\n",
       "[3 rows x 642 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "rows 500, 501, 502 of Dataset type I :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_body_acc_mean()_X</th>\n",
       "      <th>t_body_acc_mean()_Y</th>\n",
       "      <th>t_body_acc_mean()_Z</th>\n",
       "      <th>t_body_acc_std()_X</th>\n",
       "      <th>t_body_acc_std()_Y</th>\n",
       "      <th>t_body_acc_std()_Z</th>\n",
       "      <th>t_body_acc_mad()_X</th>\n",
       "      <th>t_body_acc_mad()_Y</th>\n",
       "      <th>t_body_acc_mad()_Z</th>\n",
       "      <th>t_body_acc_max()_X</th>\n",
       "      <th>...</th>\n",
       "      <th>f_body_gyro_Jerk_Mag_kurtosis()</th>\n",
       "      <th>angle0()</th>\n",
       "      <th>angle1()</th>\n",
       "      <th>angle2()</th>\n",
       "      <th>angle3()</th>\n",
       "      <th>angle4()</th>\n",
       "      <th>angle5()</th>\n",
       "      <th>angle6()</th>\n",
       "      <th>activity_Id</th>\n",
       "      <th>user_Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>-0.002612</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>-0.001619</td>\n",
       "      <td>0.189157</td>\n",
       "      <td>0.185271</td>\n",
       "      <td>0.183038</td>\n",
       "      <td>0.143988</td>\n",
       "      <td>0.175647</td>\n",
       "      <td>0.132513</td>\n",
       "      <td>0.591082</td>\n",
       "      <td>...</td>\n",
       "      <td>91.491078</td>\n",
       "      <td>2.062117</td>\n",
       "      <td>2.679764</td>\n",
       "      <td>1.156250</td>\n",
       "      <td>2.219589</td>\n",
       "      <td>0.678680</td>\n",
       "      <td>1.872693</td>\n",
       "      <td>2.156621</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>-0.004327</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>-0.001459</td>\n",
       "      <td>0.182054</td>\n",
       "      <td>0.194016</td>\n",
       "      <td>0.194199</td>\n",
       "      <td>0.143727</td>\n",
       "      <td>0.216793</td>\n",
       "      <td>0.127459</td>\n",
       "      <td>0.579079</td>\n",
       "      <td>...</td>\n",
       "      <td>78.446975</td>\n",
       "      <td>2.215386</td>\n",
       "      <td>0.809965</td>\n",
       "      <td>1.322636</td>\n",
       "      <td>1.171731</td>\n",
       "      <td>0.683628</td>\n",
       "      <td>1.868445</td>\n",
       "      <td>2.164451</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.000866</td>\n",
       "      <td>-0.002031</td>\n",
       "      <td>-0.002663</td>\n",
       "      <td>0.184468</td>\n",
       "      <td>0.172920</td>\n",
       "      <td>0.201545</td>\n",
       "      <td>0.138529</td>\n",
       "      <td>0.199514</td>\n",
       "      <td>0.139102</td>\n",
       "      <td>0.579079</td>\n",
       "      <td>...</td>\n",
       "      <td>74.697056</td>\n",
       "      <td>0.646230</td>\n",
       "      <td>2.160502</td>\n",
       "      <td>2.508356</td>\n",
       "      <td>0.320551</td>\n",
       "      <td>0.689991</td>\n",
       "      <td>1.858852</td>\n",
       "      <td>2.176837</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 642 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     t_body_acc_mean()_X  t_body_acc_mean()_Y  t_body_acc_mean()_Z  \\\n",
       "500            -0.002612             0.001936            -0.001619   \n",
       "501            -0.004327             0.000869            -0.001459   \n",
       "502             0.000866            -0.002031            -0.002663   \n",
       "\n",
       "     t_body_acc_std()_X  t_body_acc_std()_Y  t_body_acc_std()_Z  \\\n",
       "500            0.189157            0.185271            0.183038   \n",
       "501            0.182054            0.194016            0.194199   \n",
       "502            0.184468            0.172920            0.201545   \n",
       "\n",
       "     t_body_acc_mad()_X  t_body_acc_mad()_Y  t_body_acc_mad()_Z  \\\n",
       "500            0.143988            0.175647            0.132513   \n",
       "501            0.143727            0.216793            0.127459   \n",
       "502            0.138529            0.199514            0.139102   \n",
       "\n",
       "     t_body_acc_max()_X  ...  f_body_gyro_Jerk_Mag_kurtosis()  angle0()  \\\n",
       "500            0.591082  ...                        91.491078  2.062117   \n",
       "501            0.579079  ...                        78.446975  2.215386   \n",
       "502            0.579079  ...                        74.697056  0.646230   \n",
       "\n",
       "     angle1()  angle2()  angle3()  angle4()  angle5()  angle6()  activity_Id  \\\n",
       "500  2.679764  1.156250  2.219589  0.678680  1.872693  2.156621          2.0   \n",
       "501  0.809965  1.322636  1.171731  0.683628  1.868445  2.164451          2.0   \n",
       "502  2.160502  2.508356  0.320551  0.689991  1.858852  2.176837          2.0   \n",
       "\n",
       "     user_Id  \n",
       "500      2.0  \n",
       "501      2.0  \n",
       "502      2.0  \n",
       "\n",
       "[3 rows x 642 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Description of the 10 first features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_body_acc_mean()_X</th>\n",
       "      <th>t_body_acc_mean()_Y</th>\n",
       "      <th>t_body_acc_mean()_Z</th>\n",
       "      <th>t_body_acc_std()_X</th>\n",
       "      <th>t_body_acc_std()_Y</th>\n",
       "      <th>t_body_acc_std()_Z</th>\n",
       "      <th>t_body_acc_mad()_X</th>\n",
       "      <th>t_body_acc_mad()_Y</th>\n",
       "      <th>t_body_acc_mad()_Z</th>\n",
       "      <th>t_body_acc_max()_X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10399.000000</td>\n",
       "      <td>10399.000000</td>\n",
       "      <td>10399.000000</td>\n",
       "      <td>10399.000000</td>\n",
       "      <td>10399.000000</td>\n",
       "      <td>10399.000000</td>\n",
       "      <td>10399.000000</td>\n",
       "      <td>10399.000000</td>\n",
       "      <td>10399.000000</td>\n",
       "      <td>10399.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000181</td>\n",
       "      <td>-0.000253</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.128598</td>\n",
       "      <td>0.085825</td>\n",
       "      <td>0.071912</td>\n",
       "      <td>0.120879</td>\n",
       "      <td>0.077916</td>\n",
       "      <td>0.065929</td>\n",
       "      <td>0.316530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.009100</td>\n",
       "      <td>0.006948</td>\n",
       "      <td>0.006990</td>\n",
       "      <td>0.139670</td>\n",
       "      <td>0.081466</td>\n",
       "      <td>0.068746</td>\n",
       "      <td>0.132093</td>\n",
       "      <td>0.073289</td>\n",
       "      <td>0.060767</td>\n",
       "      <td>0.345820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.047488</td>\n",
       "      <td>-0.038424</td>\n",
       "      <td>-0.047545</td>\n",
       "      <td>0.001815</td>\n",
       "      <td>0.002281</td>\n",
       "      <td>0.003507</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.002089</td>\n",
       "      <td>0.002521</td>\n",
       "      <td>0.003151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.003148</td>\n",
       "      <td>-0.003659</td>\n",
       "      <td>-0.003376</td>\n",
       "      <td>0.009211</td>\n",
       "      <td>0.012132</td>\n",
       "      <td>0.011688</td>\n",
       "      <td>0.009886</td>\n",
       "      <td>0.012923</td>\n",
       "      <td>0.012555</td>\n",
       "      <td>0.018161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000080</td>\n",
       "      <td>-0.000127</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>0.023508</td>\n",
       "      <td>0.031908</td>\n",
       "      <td>0.029514</td>\n",
       "      <td>0.024822</td>\n",
       "      <td>0.032945</td>\n",
       "      <td>0.031158</td>\n",
       "      <td>0.053550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.003343</td>\n",
       "      <td>0.003268</td>\n",
       "      <td>0.003301</td>\n",
       "      <td>0.242569</td>\n",
       "      <td>0.159502</td>\n",
       "      <td>0.128384</td>\n",
       "      <td>0.229137</td>\n",
       "      <td>0.141543</td>\n",
       "      <td>0.116171</td>\n",
       "      <td>0.615332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.046679</td>\n",
       "      <td>0.036071</td>\n",
       "      <td>0.045893</td>\n",
       "      <td>0.635720</td>\n",
       "      <td>0.341042</td>\n",
       "      <td>0.353751</td>\n",
       "      <td>0.655178</td>\n",
       "      <td>0.339054</td>\n",
       "      <td>0.364321</td>\n",
       "      <td>1.226526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       t_body_acc_mean()_X  t_body_acc_mean()_Y  t_body_acc_mean()_Z  \\\n",
       "count         10399.000000         10399.000000         10399.000000   \n",
       "mean              0.000181            -0.000253             0.000043   \n",
       "std               0.009100             0.006948             0.006990   \n",
       "min              -0.047488            -0.038424            -0.047545   \n",
       "25%              -0.003148            -0.003659            -0.003376   \n",
       "50%               0.000080            -0.000127            -0.000052   \n",
       "75%               0.003343             0.003268             0.003301   \n",
       "max               0.046679             0.036071             0.045893   \n",
       "\n",
       "       t_body_acc_std()_X  t_body_acc_std()_Y  t_body_acc_std()_Z  \\\n",
       "count        10399.000000        10399.000000        10399.000000   \n",
       "mean             0.128598            0.085825            0.071912   \n",
       "std              0.139670            0.081466            0.068746   \n",
       "min              0.001815            0.002281            0.003507   \n",
       "25%              0.009211            0.012132            0.011688   \n",
       "50%              0.023508            0.031908            0.029514   \n",
       "75%              0.242569            0.159502            0.128384   \n",
       "max              0.635720            0.341042            0.353751   \n",
       "\n",
       "       t_body_acc_mad()_X  t_body_acc_mad()_Y  t_body_acc_mad()_Z  \\\n",
       "count        10399.000000        10399.000000        10399.000000   \n",
       "mean             0.120879            0.077916            0.065929   \n",
       "std              0.132093            0.073289            0.060767   \n",
       "min              0.001536            0.002089            0.002521   \n",
       "25%              0.009886            0.012923            0.012555   \n",
       "50%              0.024822            0.032945            0.031158   \n",
       "75%              0.229137            0.141543            0.116171   \n",
       "max              0.655178            0.339054            0.364321   \n",
       "\n",
       "       t_body_acc_max()_X  \n",
       "count        10399.000000  \n",
       "mean             0.316530  \n",
       "std              0.345820  \n",
       "min              0.003151  \n",
       "25%              0.018161  \n",
       "50%              0.053550  \n",
       "75%              0.615332  \n",
       "max              1.226526  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Description of the 10 first frequency features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_body_acc_mean()_X</th>\n",
       "      <th>f_body_acc_mean()_Y</th>\n",
       "      <th>f_body_acc_mean()_Z</th>\n",
       "      <th>f_body_acc_std()_X</th>\n",
       "      <th>f_body_acc_std()_Y</th>\n",
       "      <th>f_body_acc_std()_Z</th>\n",
       "      <th>f_body_acc_mad()_X</th>\n",
       "      <th>f_body_acc_mad()_Y</th>\n",
       "      <th>f_body_acc_mad()_Z</th>\n",
       "      <th>f_body_acc_max()_X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10399.000000</td>\n",
       "      <td>10399.000000</td>\n",
       "      <td>10399.000000</td>\n",
       "      <td>10399.000000</td>\n",
       "      <td>10399.000000</td>\n",
       "      <td>10399.000000</td>\n",
       "      <td>10399.000000</td>\n",
       "      <td>10399.000000</td>\n",
       "      <td>10399.000000</td>\n",
       "      <td>10399.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.745333</td>\n",
       "      <td>0.551104</td>\n",
       "      <td>0.452787</td>\n",
       "      <td>1.249054</td>\n",
       "      <td>0.799908</td>\n",
       "      <td>0.675420</td>\n",
       "      <td>0.329930</td>\n",
       "      <td>0.261509</td>\n",
       "      <td>0.240862</td>\n",
       "      <td>7.971712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.813909</td>\n",
       "      <td>0.550454</td>\n",
       "      <td>0.453078</td>\n",
       "      <td>1.358776</td>\n",
       "      <td>0.742929</td>\n",
       "      <td>0.637685</td>\n",
       "      <td>0.381239</td>\n",
       "      <td>0.290441</td>\n",
       "      <td>0.273881</td>\n",
       "      <td>8.898660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.015014</td>\n",
       "      <td>0.019182</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>0.013632</td>\n",
       "      <td>0.019417</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.006711</td>\n",
       "      <td>0.006004</td>\n",
       "      <td>0.011886</td>\n",
       "      <td>0.051908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.045469</td>\n",
       "      <td>0.057965</td>\n",
       "      <td>0.061821</td>\n",
       "      <td>0.095906</td>\n",
       "      <td>0.127022</td>\n",
       "      <td>0.120482</td>\n",
       "      <td>0.019641</td>\n",
       "      <td>0.021335</td>\n",
       "      <td>0.030041</td>\n",
       "      <td>0.677059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.125650</td>\n",
       "      <td>0.167383</td>\n",
       "      <td>0.150461</td>\n",
       "      <td>0.243477</td>\n",
       "      <td>0.327786</td>\n",
       "      <td>0.308786</td>\n",
       "      <td>0.062413</td>\n",
       "      <td>0.062228</td>\n",
       "      <td>0.065755</td>\n",
       "      <td>1.728940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.435898</td>\n",
       "      <td>1.051040</td>\n",
       "      <td>0.828692</td>\n",
       "      <td>2.324872</td>\n",
       "      <td>1.468506</td>\n",
       "      <td>1.171809</td>\n",
       "      <td>0.609422</td>\n",
       "      <td>0.486900</td>\n",
       "      <td>0.421265</td>\n",
       "      <td>14.473738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.719777</td>\n",
       "      <td>2.372634</td>\n",
       "      <td>2.425497</td>\n",
       "      <td>6.200617</td>\n",
       "      <td>3.282382</td>\n",
       "      <td>3.366875</td>\n",
       "      <td>2.225230</td>\n",
       "      <td>1.859802</td>\n",
       "      <td>2.177071</td>\n",
       "      <td>43.848146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f_body_acc_mean()_X  f_body_acc_mean()_Y  f_body_acc_mean()_Z  \\\n",
       "count         10399.000000         10399.000000         10399.000000   \n",
       "mean              0.745333             0.551104             0.452787   \n",
       "std               0.813909             0.550454             0.453078   \n",
       "min               0.015014             0.019182             0.028569   \n",
       "25%               0.045469             0.057965             0.061821   \n",
       "50%               0.125650             0.167383             0.150461   \n",
       "75%               1.435898             1.051040             0.828692   \n",
       "max               3.719777             2.372634             2.425497   \n",
       "\n",
       "       f_body_acc_std()_X  f_body_acc_std()_Y  f_body_acc_std()_Z  \\\n",
       "count        10399.000000        10399.000000        10399.000000   \n",
       "mean             1.249054            0.799908            0.675420   \n",
       "std              1.358776            0.742929            0.637685   \n",
       "min              0.013632            0.019417            0.025974   \n",
       "25%              0.095906            0.127022            0.120482   \n",
       "50%              0.243477            0.327786            0.308786   \n",
       "75%              2.324872            1.468506            1.171809   \n",
       "max              6.200617            3.282382            3.366875   \n",
       "\n",
       "       f_body_acc_mad()_X  f_body_acc_mad()_Y  f_body_acc_mad()_Z  \\\n",
       "count        10399.000000        10399.000000        10399.000000   \n",
       "mean             0.329930            0.261509            0.240862   \n",
       "std              0.381239            0.290441            0.273881   \n",
       "min              0.006711            0.006004            0.011886   \n",
       "25%              0.019641            0.021335            0.030041   \n",
       "50%              0.062413            0.062228            0.065755   \n",
       "75%              0.609422            0.486900            0.421265   \n",
       "max              2.225230            1.859802            2.177071   \n",
       "\n",
       "       f_body_acc_max()_X  \n",
       "count        10399.000000  \n",
       "mean             7.971712  \n",
       "std              8.898660  \n",
       "min              0.051908  \n",
       "25%              0.677059  \n",
       "50%              1.728940  \n",
       "75%             14.473738  \n",
       "max             43.848146  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Number of windows per user and per each activity:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User 1</th>\n",
       "      <td>95</td>\n",
       "      <td>53</td>\n",
       "      <td>49</td>\n",
       "      <td>47</td>\n",
       "      <td>55</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 2</th>\n",
       "      <td>59</td>\n",
       "      <td>48</td>\n",
       "      <td>47</td>\n",
       "      <td>46</td>\n",
       "      <td>55</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 3</th>\n",
       "      <td>58</td>\n",
       "      <td>59</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 4</th>\n",
       "      <td>60</td>\n",
       "      <td>52</td>\n",
       "      <td>45</td>\n",
       "      <td>48</td>\n",
       "      <td>56</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 5</th>\n",
       "      <td>56</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>43</td>\n",
       "      <td>57</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 6</th>\n",
       "      <td>57</td>\n",
       "      <td>51</td>\n",
       "      <td>48</td>\n",
       "      <td>56</td>\n",
       "      <td>58</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 7</th>\n",
       "      <td>57</td>\n",
       "      <td>51</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>54</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 8</th>\n",
       "      <td>47</td>\n",
       "      <td>41</td>\n",
       "      <td>38</td>\n",
       "      <td>45</td>\n",
       "      <td>57</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 9</th>\n",
       "      <td>52</td>\n",
       "      <td>49</td>\n",
       "      <td>42</td>\n",
       "      <td>53</td>\n",
       "      <td>49</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 10</th>\n",
       "      <td>53</td>\n",
       "      <td>47</td>\n",
       "      <td>38</td>\n",
       "      <td>55</td>\n",
       "      <td>46</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 11</th>\n",
       "      <td>59</td>\n",
       "      <td>54</td>\n",
       "      <td>46</td>\n",
       "      <td>54</td>\n",
       "      <td>50</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 12</th>\n",
       "      <td>50</td>\n",
       "      <td>52</td>\n",
       "      <td>46</td>\n",
       "      <td>56</td>\n",
       "      <td>62</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 13</th>\n",
       "      <td>57</td>\n",
       "      <td>55</td>\n",
       "      <td>47</td>\n",
       "      <td>49</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 14</th>\n",
       "      <td>59</td>\n",
       "      <td>54</td>\n",
       "      <td>45</td>\n",
       "      <td>53</td>\n",
       "      <td>62</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 15</th>\n",
       "      <td>53</td>\n",
       "      <td>48</td>\n",
       "      <td>42</td>\n",
       "      <td>61</td>\n",
       "      <td>55</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 16</th>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>47</td>\n",
       "      <td>67</td>\n",
       "      <td>79</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 17</th>\n",
       "      <td>61</td>\n",
       "      <td>48</td>\n",
       "      <td>47</td>\n",
       "      <td>64</td>\n",
       "      <td>83</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 18</th>\n",
       "      <td>56</td>\n",
       "      <td>57</td>\n",
       "      <td>55</td>\n",
       "      <td>61</td>\n",
       "      <td>79</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 19</th>\n",
       "      <td>52</td>\n",
       "      <td>40</td>\n",
       "      <td>39</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 20</th>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>45</td>\n",
       "      <td>68</td>\n",
       "      <td>78</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 21</th>\n",
       "      <td>52</td>\n",
       "      <td>47</td>\n",
       "      <td>45</td>\n",
       "      <td>85</td>\n",
       "      <td>94</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 22</th>\n",
       "      <td>46</td>\n",
       "      <td>42</td>\n",
       "      <td>36</td>\n",
       "      <td>62</td>\n",
       "      <td>65</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 23</th>\n",
       "      <td>59</td>\n",
       "      <td>51</td>\n",
       "      <td>54</td>\n",
       "      <td>68</td>\n",
       "      <td>70</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 24</th>\n",
       "      <td>58</td>\n",
       "      <td>59</td>\n",
       "      <td>54</td>\n",
       "      <td>71</td>\n",
       "      <td>71</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 25</th>\n",
       "      <td>74</td>\n",
       "      <td>65</td>\n",
       "      <td>58</td>\n",
       "      <td>66</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 26</th>\n",
       "      <td>59</td>\n",
       "      <td>55</td>\n",
       "      <td>50</td>\n",
       "      <td>79</td>\n",
       "      <td>77</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 27</th>\n",
       "      <td>57</td>\n",
       "      <td>51</td>\n",
       "      <td>44</td>\n",
       "      <td>72</td>\n",
       "      <td>82</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 28</th>\n",
       "      <td>54</td>\n",
       "      <td>51</td>\n",
       "      <td>46</td>\n",
       "      <td>74</td>\n",
       "      <td>80</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 29</th>\n",
       "      <td>53</td>\n",
       "      <td>49</td>\n",
       "      <td>48</td>\n",
       "      <td>60</td>\n",
       "      <td>67</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 30</th>\n",
       "      <td>65</td>\n",
       "      <td>64</td>\n",
       "      <td>62</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  \\\n",
       "User 1           95          53          49          47          55   \n",
       "User 2           59          48          47          46          55   \n",
       "User 3           58          59          49          51          63   \n",
       "User 4           60          52          45          48          56   \n",
       "User 5           56          47          47          43          57   \n",
       "User 6           57          51          48          56          58   \n",
       "User 7           57          51          47          47          54   \n",
       "User 8           47          41          38          45          57   \n",
       "User 9           52          49          42          53          49   \n",
       "User 10          53          47          38          55          46   \n",
       "User 11          59          54          46          54          50   \n",
       "User 12          50          52          46          56          62   \n",
       "User 13          57          55          47          49          60   \n",
       "User 14          59          54          45          53          62   \n",
       "User 15          53          48          42          61          55   \n",
       "User 16          51          51          47          67          79   \n",
       "User 17          61          48          47          64          83   \n",
       "User 18          56          57          55          61          79   \n",
       "User 19          52          40          39          72          74   \n",
       "User 20          51          51          45          68          78   \n",
       "User 21          52          47          45          85          94   \n",
       "User 22          46          42          36          62          65   \n",
       "User 23          59          51          54          68          70   \n",
       "User 24          58          59          54          71          71   \n",
       "User 25          74          65          58          66          75   \n",
       "User 26          59          55          50          79          77   \n",
       "User 27          57          51          44          72          82   \n",
       "User 28          54          51          46          74          80   \n",
       "User 29          53          49          48          60          67   \n",
       "User 30          65          64          62          64          64   \n",
       "\n",
       "         Activity 6  \n",
       "User 1           48  \n",
       "User 2           49  \n",
       "User 3           63  \n",
       "User 4           52  \n",
       "User 5           51  \n",
       "User 6           56  \n",
       "User 7           50  \n",
       "User 8           55  \n",
       "User 9           54  \n",
       "User 10          59  \n",
       "User 11          58  \n",
       "User 12          61  \n",
       "User 13          60  \n",
       "User 14          48  \n",
       "User 15          74  \n",
       "User 16          69  \n",
       "User 17          74  \n",
       "User 18          71  \n",
       "User 19          84  \n",
       "User 20          66  \n",
       "User 21          90  \n",
       "User 22          72  \n",
       "User 23          72  \n",
       "User 24          73  \n",
       "User 25          75  \n",
       "User 26          76  \n",
       "User 27          76  \n",
       "User 28          79  \n",
       "User 29          69  \n",
       "User 30          73  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Statistics of table above:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>57.333333</td>\n",
       "      <td>51.400000</td>\n",
       "      <td>46.866667</td>\n",
       "      <td>59.900000</td>\n",
       "      <td>65.900000</td>\n",
       "      <td>65.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.937844</td>\n",
       "      <td>5.769121</td>\n",
       "      <td>5.727931</td>\n",
       "      <td>10.870238</td>\n",
       "      <td>11.998132</td>\n",
       "      <td>11.500175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>52.250000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>51.500000</td>\n",
       "      <td>56.250000</td>\n",
       "      <td>55.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>57.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>60.500000</td>\n",
       "      <td>63.500000</td>\n",
       "      <td>67.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>59.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>48.750000</td>\n",
       "      <td>67.750000</td>\n",
       "      <td>76.500000</td>\n",
       "      <td>73.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  Activity 6\n",
       "count   30.000000   30.000000   30.000000   30.000000   30.000000   30.000000\n",
       "mean    57.333333   51.400000   46.866667   59.900000   65.900000   65.233333\n",
       "std      8.937844    5.769121    5.727931   10.870238   11.998132   11.500175\n",
       "min     46.000000   40.000000   36.000000   43.000000   46.000000   48.000000\n",
       "25%     52.250000   48.000000   45.000000   51.500000   56.250000   55.250000\n",
       "50%     57.000000   51.000000   47.000000   60.500000   63.500000   67.500000\n",
       "75%     59.000000   54.000000   48.750000   67.750000   76.500000   73.750000\n",
       "max     95.000000   65.000000   62.000000   85.000000   94.000000   90.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "_____ The weights of each activity _____\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Weights</th>\n",
       "      <td>0.165401</td>\n",
       "      <td>0.148283</td>\n",
       "      <td>0.135205</td>\n",
       "      <td>0.172805</td>\n",
       "      <td>0.190114</td>\n",
       "      <td>0.188191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  \\\n",
       "Weights    0.165401    0.148283    0.135205    0.172805    0.190114   \n",
       "\n",
       "         Activity 6  \n",
       "Weights    0.188191  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAHFCAYAAAAT5Oa6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABT3klEQVR4nO3dd1QU1/8+8GelLKCwCggLioC9gAqaKJh8BAuKYk/UYLAGE7uCKWiiYBKNJpZEo2kIFiwpdhMUe1RsKCqoWAKWBMSCIBZEuL8//DFfV0BYXOo8r3P2HGbmzp333MXw5M7MrkIIIUBEREQkY9XKuwAiIiKi8sZARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEVUZ4eDgUCgWMjIxw9erVfNs9PDzg5ORUDpUB+/btg0KhwO+//14ux9dWUlISevbsCXNzcygUCkyePLnQtg4ODlAoFFAoFKhWrRpUKhWaNWuGoUOHYufOna9Ux9KlSxEeHv5KfZQVBwcHDB8+vET7rlmzBosWLdJpPVXNy8ZIoVAgODhY6z7z/puRlJRUrONQ1aZf3gUQ6VpWVhY+/fRTrFq1qrxLqbSmTJmCo0ePYvny5VCr1bCxsXlp+w4dOuCbb74BAGRmZiIhIQHr1q1Dt27dMGDAAKxduxYGBgZa17F06VJYWlqWOGiUpY0bN8LMzKxE+65ZswZxcXEvDZ5y97Ixio6ORt26dbXus2fPnoiOjtb4/eZ7IV8MRFTldO/eHWvWrMHUqVPRqlWr8i6nTD169AhGRkZQKBSv1E9cXBxef/119O3bt1jta9asifbt20vLXbp0wbhx4xAcHIyQkBB8+umnmDt37ivVVNG5uLiUdwllLjs7GwqFAvr65fun5PnfPW3Url0btWvX1nE1VFnxkhlVOR999BEsLCzw8ccfv7RdUlISFApFgZdkXpyCDw4OhkKhwJkzZ/D2229DpVLB3NwcAQEBePr0KRISEtC9e3eYmprCwcEB8+bNK/CYjx8/RkBAANRqNYyNjdGxY0ecOnUqX7sTJ06gd+/eMDc3h5GREVxcXPDrr79qtMmb7t+5cydGjhyJ2rVrw8TEBFlZWYWe87Vr1/Duu+/CysoKSqUSzZo1w/z585Gbmwvg/y7tXb58GX/99Zd0Kez5SwraCA4ORosWLbBkyRI8fvxYWh8SEoJ27drB3NwcZmZmcHV1RWhoKJ7/rmkHBwfEx8dj//79Uh0ODg7SOAYGBqJ169bSe+Hm5obNmzcXq668y6d///032rdvD2NjY9SpUwefffYZcnJyNNrevXsXY8eORZ06dWBoaIj69etj+vTp+cb5xUtmeWO5du1aTJ8+Hba2tjAzM0OXLl2QkJCgUcv27dtx9epV6TyfD7TLli1Dq1atUKNGDZiamqJp06aYNm3aS88v73d73rx5+PLLL1GvXj0YGRmhbdu22L17d772ly5dgq+vr8bvxffff6/RJu98Vq1ahcDAQNSpUwdKpRKXL18utI7ivM951qxZAzc3N9SoUQM1atRA69atERoaWqwxev7f6+nTp6FQKKR9n5f3O71lyxYA+S+ZFXYcIQQaNWqEbt265eszMzMTKpUK48aNK3QcqHJgIKIqx9TUFJ9++il27NiBPXv26LTvgQMHolWrVvjjjz/g7++PhQsXYsqUKejbty969uyJjRs3olOnTvj444+xYcOGfPtPmzYN//zzD3755Rf88ssv+O+//+Dh4YF//vlHarN371506NAB9+7dww8//IDNmzejdevWGDRoUIHhbeTIkTAwMMCqVavw+++/F3pp6tatW3B3d8fOnTvx+eefY8uWLejSpQumTp2K8ePHAwBcXV0RHR0NtVqNDh06IDo6Ot8lBW316tULDx8+xIkTJ6R1SUlJeP/99/Hrr79iw4YN6N+/PyZMmIDPP/9carNx40bUr18fLi4uUh0bN24E8Oyy6N27dzF16lRs2rQJa9euxRtvvIH+/ftj5cqVxaorJSUFgwcPxpAhQ7B582a89dZb+OKLLzBp0iSpzePHj+Hp6YmVK1ciICAA27dvx7vvvot58+ahf//+xTrOtGnTcPXqVfzyyy/46aefcOnSJfTq1UsKXkuXLkWHDh2gVqul84yOjgYArFu3DmPHjkXHjh2xceNGbNq0CVOmTMGDBw+KdewlS5YgMjISixYtwurVq1GtWjV4e3tL/QPAuXPn8NprryEuLg7z58/Htm3b0LNnT0ycOBEhISH5+gwKCsK1a9fwww8/YOvWrbCysir0+MV5nwFgxowZGDJkCGxtbREeHo6NGzdi2LBh0r2ALxujF7Vq1QouLi4ICwvLty08PBxWVlbo0aNHgfsWdhyFQoEJEyYgKioKly5d0thn5cqVyMjIYCCqCgRRFREWFiYAiOPHj4usrCxRv3590bZtW5GbmyuEEKJjx46iRYsWUvvExEQBQISFheXrC4CYOXOmtDxz5kwBQMyfP1+jXevWrQUAsWHDBmlddna2qF27tujfv7+0bu/evQKAcHV1leoRQoikpCRhYGAg3nvvPWld06ZNhYuLi8jOztY4lo+Pj7CxsRE5OTka5zt06NBijc8nn3wiAIijR49qrB8zZoxQKBQiISFBWmdvby969uxZrH6Larts2TIBQKxfv77A7Tk5OSI7O1vMmjVLWFhYaIxPixYtRMeOHYus4enTpyI7O1uMGjVKuLi4FNm+Y8eOAoDYvHmzxnp/f39RrVo1cfXqVSGEED/88IMAIH799VeNdnPnzhUAxM6dO6V19vb2YtiwYdJy3nveo0cPjX1//fVXAUBER0dL63r27Cns7e3z1Tl+/HhRs2bNIs/nRXm/27a2tuLRo0fS+oyMDGFubi66dOkirevWrZuoW7euSE9Pz3dsIyMjcffuXY3z+d///qd1PUIU/j7/888/Qk9PTwwZMuSl+xc2RkLk//f63XffCQAav9N3794VSqVSBAYGSuvy/g0lJiYWeZyMjAxhamoqJk2apLG+efPmwtPT86W1U+XAGSKqkgwNDfHFF1/gxIkT+S41vQofHx+N5WbNmkGhUMDb21tap6+vj4YNGxb4pJuvr6/GVL+9vT3c3d2xd+9eAMDly5dx4cIFDBkyBADw9OlT6dWjRw8kJydrXG4BgAEDBhSr9j179qB58+Z4/fXXNdYPHz4cQgidz6blEQVcHtmzZw+6dOkClUoFPT09GBgYYMaMGbhz5w5SU1OL1e9vv/2GDh06oEaNGtDX14eBgQFCQ0Nx/vz5Yu1vamqK3r17a6zz9fVFbm4uDhw4INVZvXp1vPXWWxrt8i6NFXT56UUvHqNly5YAUODvx4tef/113Lt3D++88w42b96M27dvF7nP8/r37w8jIyNp2dTUFL169cKBAweQk5ODx48fY/fu3ejXrx9MTEzy/b49fvwYR44c0eizuL9vQPHe56ioKOTk5Oh0hmXIkCFQKpUaM6pr165FVlYWRowYUaI+TU1NMWLECISHh0szdHv27MG5c+ekGVaq3BiIqMoaPHgwXF1dMX36dGRnZ+ukT3Nzc41lQ0NDmJiYaPzRyVv//D0zedRqdYHr7ty5AwC4efMmAGDq1KkwMDDQeI0dOxYA8v1RLO7lrDt37hTY1tbWVtpeGvL+8Ocd59ixY/Dy8gIA/Pzzzzh06BCOHz+O6dOnA3h2Y3hRNmzYgIEDB6JOnTpYvXo1oqOjcfz4cYwcObLAcS+ItbV1vnV570/eWNy5cwdqtTrfTepWVlbQ19cv1phZWFhoLCuVSgDFO08/Pz8sX74cV69exYABA2BlZYV27dohKiqqyH2fP58X1z158gSZmZm4c+cOnj59isWLF+f7fcu7rFTS37fivs+3bt0CgBI9JVYYc3Nz9O7dGytXrpQuTYaHh+P1119HixYtStzvhAkTcP/+fURERAB4dkmybt266NOnj07qpvLFp8yoylIoFJg7dy66du2Kn376Kd/2vBDz4s2xpRUMgGf3rRS0Lu+PpqWlJYBn92kUdo9KkyZNNJaL+0SZhYUFkpOT863/77//NI6tS0IIbN26FdWrV0fbtm0BPLsvxsDAANu2bdMIkps2bSp2v6tXr4ajoyPWr1+vcf4vu6H8RXnh83l570/e+2FhYYGjR49CCKFxnNTUVDx9+rRUxuxFI0aMwIgRI/DgwQMcOHAAM2fOhI+PDy5evAh7e/uX7lvY75uhoSFq1KgBAwMD6Onpwc/Pr9AZGkdHR43l4v6+Ffd9znvK68aNG7CzsytW38UxYsQI/Pbbb4iKikK9evVw/PhxLFu27JX6bNiwIby9vfH999/D29sbW7ZsQUhICPT09HRUNZUnzhBRldalSxd07doVs2bNQmZmpsY2a2trGBkZ4cyZMxrri/ukUkmsXbtW4xLS1atXcfjwYXh4eAB4FnYaNWqE06dPo23btgW+TE1NS3Tszp0749y5czh58qTG+pUrV0KhUMDT07PE51WYkJAQnDt3DpMmTZL+KOY9pv38H5FHjx4V+LlRSqWywJkUhUIBQ0NDjT/OKSkpWr139+/fl542yrNmzRpUq1YN//vf/wA8G7PMzMx8f8Tzbtzu3LlzsY/3MoWd5/OqV68Ob29vTJ8+HU+ePEF8fHyR/W7YsEFjxuz+/fvYunUr3nzzTejp6cHExASenp44deoUWrZsWeDv24szXMVV3PfZy8sLenp6RYaV4ozRi/3WqVMHYWFhCAsLg5GREd55550i9yvqOJMmTcKZM2cwbNgw6Onpwd/fv9g1UcXGGSKq8ubOnYs2bdogNTVVY7pcoVDg3XffxfLly9GgQQO0atUKx44dw5o1a0qtltTUVPTr1w/+/v5IT0/HzJkzYWRkhKCgIKnNjz/+CG9vb3Tr1g3Dhw9HnTp1cPfuXZw/fx4nT57Eb7/9VqJjT5kyBStXrkTPnj0xa9Ys2NvbY/v27Vi6dCnGjBmDxo0bl/i87t27J91r8uDBA+mDGf/++28MHDhQ42mlnj17YsGCBfD19cXo0aNx584dfPPNN9KlpOc5Oztj3bp1WL9+PerXrw8jIyM4OzvDx8cHGzZswNixY/HWW2/h+vXr+Pzzz2FjY5PvKaDCWFhYYMyYMbh27RoaN26MP//8Ez///DPGjBmDevXqAQCGDh2K77//HsOGDUNSUhKcnZ1x8OBBzJ49Gz169ECXLl1KPGYvnueGDRuwbNkytGnTBtWqVUPbtm3h7+8PY2NjdOjQATY2NkhJScGcOXOgUqnw2muvFdmvnp4eunbtioCAAOTm5mLu3LnIyMjQeD++/fZbvPHGG3jzzTcxZswYODg44P79+7h8+TK2bt1a4nvLivs+Ozg4YNq0afj888/x6NEjvPPOO1CpVDh37hxu374t1VrYGL3s3IcOHYoFCxbAzMwM/fv3h0qlKrLuoo7TtWtXNG/eHHv37pU+woKqiHK9pZtIh55/yuxFvr6+AoDGU2ZCCJGeni7ee+89YW1tLapXry569eolkpKSCn3K7NatWxr7Dxs2TFSvXj3f8V58oi3vCZ1Vq1aJiRMnitq1awulUinefPNNceLEiXz7nz59WgwcOFBYWVkJAwMDoVarRadOncQPP/xQrPMtzNWrV4Wvr6+wsLAQBgYGokmTJuLrr7+WnlzLo+1TZgAEAKFQKESNGjVEkyZNhJ+fn9ixY0eB+yxfvlw0adJEKJVKUb9+fTFnzhwRGhqa74mfpKQk4eXlJUxNTQUAjad/vvrqK+Hg4CCUSqVo1qyZ+Pnnn6X3qSh578++fftE27ZthVKpFDY2NmLatGn5nu67c+eO+OCDD4SNjY3Q19cX9vb2IigoSDx+/DjfOBT0lNlvv/2m0a6gpxvv3r0r3nrrLVGzZk2hUCikc1ixYoXw9PQU1tbWwtDQUNja2oqBAweKM2fOvPT88o4xd+5cERISIurWrSsMDQ2Fi4tLge9JYmKiGDlypKhTp44wMDAQtWvXFu7u7uKLL74o8nxeprjvsxBCrFy5Urz22mvCyMhI1KhRQ7i4uBRrjITI/5RZnosXL0q/m1FRUfm2F/SU2cuOkyc4OFgAEEeOHCn2WFDFpxCigEdAiIiqMA8PD9y+fRtxcXHlXUqpSEpKgqOjI77++mtMnTq1vMupctq2bQuFQoHjx4+XdymkQ7xkRkREVISMjAzExcVh27ZtiImJkT4klKoOBiIiIqIinDx5Ep6enrCwsMDMmTOL/T1/VHnwkhkRERHJHh+7JyIiItljICIiIiLZYyAiIiIi2eNN1cWUm5uL//77D6ampsX+6HoiIiIqX0II3L9/H7a2tqhWrfB5IAaiYvrvv/90+j07REREVHauX7/+0i8RZiAqprzvj7p+/TrMzMzKuRoiIiIqjoyMDNjZ2RX5PZAMRMWUd5nMzMyMgYiIiKiSKep2F95UTURERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREsleugWjOnDl47bXXYGpqCisrK/Tt2xcJCQkabYQQCA4Ohq2tLYyNjeHh4YH4+HiNNllZWZgwYQIsLS1RvXp19O7dGzdu3NBok5aWBj8/P6hUKqhUKvj5+eHevXulfYpERERUCZRrINq/fz/GjRuHI0eOICoqCk+fPoWXlxcePHggtZk3bx4WLFiAJUuW4Pjx41Cr1ejatSvu378vtZk8eTI2btyIdevW4eDBg8jMzISPjw9ycnKkNr6+voiNjUVkZCQiIyMRGxsLPz+/Mj1fIiIiqqBEBZKamioAiP379wshhMjNzRVqtVp89dVXUpvHjx8LlUolfvjhByGEEPfu3RMGBgZi3bp1Upt///1XVKtWTURGRgohhDh37pwAII4cOSK1iY6OFgDEhQsXilVbenq6ACDS09Nf+TyJiIiobBT373eFuocoPT0dAGBubg4ASExMREpKCry8vKQ2SqUSHTt2xOHDhwEAMTExyM7O1mhja2sLJycnqU10dDRUKhXatWsntWnfvj1UKpXUhoiIiOSrwnx1hxACAQEBeOONN+Dk5AQASElJAQBYW1trtLW2tsbVq1elNoaGhqhVq1a+Nnn7p6SkwMrKKt8xrayspDYvysrKQlZWlrSckZFRwjMjIiKiiq7CzBCNHz8eZ86cwdq1a/Nte/H7R4QQRX4nyYttCmr/sn7mzJkj3YCtUqn4TfdERERVWIUIRBMmTMCWLVuwd+9e1K1bV1qvVqsBIN8sTmpqqjRrpFar8eTJE6Slpb20zc2bN/Md99atW/lmn/IEBQUhPT1del2/fr3kJ0hEREQVWrkGIiEExo8fjw0bNmDPnj1wdHTU2O7o6Ai1Wo2oqChp3ZMnT7B//364u7sDANq0aQMDAwONNsnJyYiLi5PauLm5IT09HceOHZPaHD16FOnp6VKbFymVSumb7fkN90RERFVbud5DNG7cOKxZswabN2+GqampNBOkUqlgbGwMhUKByZMnY/bs2WjUqBEaNWqE2bNnw8TEBL6+vlLbUaNGITAwEBYWFjA3N8fUqVPh7OyMLl26AACaNWuG7t27w9/fHz/++CMAYPTo0fDx8UGTJk3K5+SJiIiowijXQLRs2TIAgIeHh8b6sLAwDB8+HADw0Ucf4dGjRxg7dizS0tLQrl077Ny5E6amplL7hQsXQl9fHwMHDsSjR4/QuXNnhIeHQ09PT2oTERGBiRMnSk+j9e7dG0uWLCndEyQikjGHT7aXdwnlIumrnuVdApWAQgghyruIyiAjIwMqlQrp6em8fEZEVAwMRFQRFPfvd4W4qZqIiIioPFWYzyEiIiIizqyVF84QERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkezpl3cBRESVgcMn28u7hHKR9FXP8i6BqExwhoiIiIhkj4GIiIiIZI+BiIiIiGSvXAPRgQMH0KtXL9ja2kKhUGDTpk0a2xUKRYGvr7/+Wmrj4eGRb/vgwYM1+klLS4Ofnx9UKhVUKhX8/Pxw7969MjhDIiIiqgzKNRA9ePAArVq1wpIlSwrcnpycrPFavnw5FAoFBgwYoNHO399fo92PP/6osd3X1xexsbGIjIxEZGQkYmNj4efnV2rnRURERJVLuT5l5u3tDW9v70K3q9VqjeXNmzfD09MT9evX11hvYmKSr22e8+fPIzIyEkeOHEG7du0AAD///DPc3NyQkJCAJk2avOJZEBERUWVXae4hunnzJrZv345Ro0bl2xYREQFLS0u0aNECU6dOxf3796Vt0dHRUKlUUhgCgPbt20OlUuHw4cOFHi8rKwsZGRkaLyIiIqqaKs3nEK1YsQKmpqbo37+/xvohQ4bA0dERarUacXFxCAoKwunTpxEVFQUASElJgZWVVb7+rKyskJKSUujx5syZg5CQEN2eBBEREVVIlSYQLV++HEOGDIGRkZHGen9/f+lnJycnNGrUCG3btsXJkyfh6uoK4NnN2S8SQhS4Pk9QUBACAgKk5YyMDNjZ2b3qaRAREVEFVCkC0d9//42EhASsX7++yLaurq4wMDDApUuX4OrqCrVajZs3b+Zrd+vWLVhbWxfaj1KphFKpfKW6iYiIqHKoFPcQhYaGok2bNmjVqlWRbePj45GdnQ0bGxsAgJubG9LT03Hs2DGpzdGjR5Geng53d/dSq5mIiIgqj3KdIcrMzMTly5el5cTERMTGxsLc3Bz16tUD8OxS1W+//Yb58+fn2//KlSuIiIhAjx49YGlpiXPnziEwMBAuLi7o0KEDAKBZs2bo3r07/P39pcfxR48eDR8fHz5hRkRERADKORCdOHECnp6e0nLePTvDhg1DeHg4AGDdunUQQuCdd97Jt7+hoSF2796Nb7/9FpmZmbCzs0PPnj0xc+ZM6OnpSe0iIiIwceJEeHl5AQB69+5d6GcflQe5fmkkwC+OJCKiiqFcA5GHhweEEC9tM3r0aIwePbrAbXZ2dti/f3+RxzE3N8fq1atLVCMRERFVfZXiHiIiIiKi0sRARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyp1/eBRCVlMMn28u7hHKR9FXP8i6BiKjK4QwRERERyR4DEREREcleuQaiAwcOoFevXrC1tYVCocCmTZs0tg8fPhwKhULj1b59e402WVlZmDBhAiwtLVG9enX07t0bN27c0GiTlpYGPz8/qFQqqFQq+Pn54d69e6V8dkRERFRZlGsgevDgAVq1aoUlS5YU2qZ79+5ITk6WXn/++afG9smTJ2Pjxo1Yt24dDh48iMzMTPj4+CAnJ0dq4+vri9jYWERGRiIyMhKxsbHw8/MrtfMiIiKiyqVcb6r29vaGt7f3S9solUqo1eoCt6WnpyM0NBSrVq1Cly5dAACrV6+GnZ0ddu3ahW7duuH8+fOIjIzEkSNH0K5dOwDAzz//DDc3NyQkJKBJkya6PSkiIiKqdCr8PUT79u2DlZUVGjduDH9/f6SmpkrbYmJikJ2dDS8vL2mdra0tnJyccPjwYQBAdHQ0VCqVFIYAoH379lCpVFIbIiIikrcK/di9t7c33n77bdjb2yMxMRGfffYZOnXqhJiYGCiVSqSkpMDQ0BC1atXS2M/a2hopKSkAgJSUFFhZWeXr28rKSmpTkKysLGRlZUnLGRkZOjorIiIiqmgqdCAaNGiQ9LOTkxPatm0Le3t7bN++Hf379y90PyEEFAqFtPz8z4W1edGcOXMQEhJSwsqJiIioMqnwl8yeZ2NjA3t7e1y6dAkAoFar8eTJE6SlpWm0S01NhbW1tdTm5s2b+fq6deuW1KYgQUFBSE9Pl17Xr1/X4ZkQERFRRVKpAtGdO3dw/fp12NjYAADatGkDAwMDREVFSW2Sk5MRFxcHd3d3AICbmxvS09Nx7Ngxqc3Ro0eRnp4utSmIUqmEmZmZxouIiIiqpnK9ZJaZmYnLly9Ly4mJiYiNjYW5uTnMzc0RHByMAQMGwMbGBklJSZg2bRosLS3Rr18/AIBKpcKoUaMQGBgICwsLmJubY+rUqXB2dpaeOmvWrBm6d+8Of39//PjjjwCA0aNHw8fHh0+YEREREYASzBBFRkbi4MGD0vL333+P1q1bw9fXN9+lq6KcOHECLi4ucHFxAQAEBATAxcUFM2bMgJ6eHs6ePYs+ffqgcePGGDZsGBo3bozo6GiYmppKfSxcuBB9+/bFwIED0aFDB5iYmGDr1q3Q09OT2kRERMDZ2RleXl7w8vJCy5YtsWrVKm1PnYiIiKoorWeIPvzwQ8ydOxcAcPbsWQQGBiIgIAB79uxBQEAAwsLCit2Xh4cHhBCFbt+xY0eRfRgZGWHx4sVYvHhxoW3Mzc2xevXqYtdFRERE8qJ1IEpMTETz5s0BAH/88Qd8fHwwe/ZsnDx5Ej169NB5gURERESlTetLZoaGhnj48CEAYNeuXdKHIpqbm/OzeoiIiKhS0nqG6I033kBAQAA6dOiAY8eOYf369QCAixcvom7dujovkIiIiKi0aT1DtGTJEujr6+P333/HsmXLUKdOHQDAX3/9he7du+u8QCIiIqLSpvUMUb169bBt27Z86xcuXKiTgoiIiIjKmtYzRHp6ehpfsJrnzp07Go+6ExEREVUWWgeiwh6Tz8rKgqGh4SsXRERERFTWin3J7LvvvgPw7ItSf/nlF9SoUUPalpOTgwMHDqBp06a6r5CIiIiolBU7EOXdIySEwA8//KBxeczQ0BAODg744YcfdF8hERERUSkrdiBKTEwEAHh6emLDhg2oVatWqRVFREREVJa0fsps7969pVEHEZURh0+2l3cJ5SLpq57lXQIRVWBaB6KcnByEh4dj9+7dSE1NRW5ursb2PXv26Kw4IiIiorKgdSCaNGkSwsPD0bNnTzg5OUGhUJRGXURERERlRutAtG7dOvz666/8IlciIiKqMkr05a4NGzYsjVqIiIiIyoXWgSgwMBDffvttoR/QSERERFTZaH3J7ODBg9i7dy/++usvtGjRAgYGBhrbN2zYoLPiiIiIiMqC1oGoZs2a6NevX2nUQkRERFQutA5EYWFhpVEHERERUbnR+h4iIiIioqqmWDNErq6u2L17N2rVqgUXF5eXfvbQyZMndVYcERERUVkoViDq06cPlEolAKBv376lWQ8RERFRmStWIJo5c2aBPxMRERFVBVrfVJ0nJiYG58+fh0KhQPPmzeHi4qLLuoiIiIjKjNaBKDU1FYMHD8a+fftQs2ZNCCGQnp4OT09PrFu3DrVr1y6NOomIiIhKjdZPmU2YMAEZGRmIj4/H3bt3kZaWhri4OGRkZGDixImlUSMRERFRqdJ6higyMhK7du1Cs2bNpHXNmzfH999/Dy8vL50WR0RERFQWtJ4hys3Nzfd1HQBgYGCA3NxcnRRFREREVJa0DkSdOnXCpEmT8N9//0nr/v33X0yZMgWdO3fWaXFEREREZUHrQLRkyRLcv38fDg4OaNCgARo2bAhHR0fcv38fixcvLo0aiYiIiEqV1vcQ2dnZ4eTJk4iKisKFCxcghEDz5s3RpUuX0qiPiIiIqNSV+HOIunbtiq5du+qyFiIiIqJyUaIvd929ezd8fHykS2Y+Pj7YtWuXrmsjIiIiKhMluoeoe/fuMDU1xaRJkzBx4kSYmZmhR48eWLJkSWnUSERERFSqtA5Ec+bMwcKFC7F27VpMnDgREydOxJo1a7Bw4ULMnj1bq74OHDiAXr16wdbWFgqFAps2bZK2ZWdn4+OPP4azszOqV68OW1tbDB06VOPpNgDw8PCAQqHQeA0ePFijTVpaGvz8/KBSqaBSqeDn54d79+5pe+pERERURWkdiDIyMtC9e/d86728vJCRkaFVXw8ePECrVq0KnFl6+PAhTp48ic8++wwnT57Ehg0bcPHiRfTu3TtfW39/fyQnJ0uvH3/8UWO7r68vYmNjERkZicjISMTGxsLPz0+rWomIiKjq0vqm6t69e2Pjxo348MMPNdZv3rwZvXr10qovb29veHt7F7hNpVIhKipKY93ixYvx+uuv49q1a6hXr5603sTEBGq1usB+zp8/j8jISBw5cgTt2rUDAPz8889wc3NDQkICmjRpolXNREREVPVoHYiaNWuGL7/8Evv27YObmxsA4MiRIzh06BACAwPx3XffSW11/d1m6enpUCgUqFmzpsb6iIgIrF69GtbW1vD29sbMmTNhamoKAIiOjoZKpZLCEAC0b98eKpUKhw8fLjQQZWVlISsrS1rWdvaLiIiIKg+tA1FoaChq1aqFc+fO4dy5c9L6mjVrIjQ0VFpWKBQ6DUSPHz/GJ598Al9fX5iZmUnrhwwZAkdHR6jVasTFxSEoKAinT5+WZpdSUlJgZWWVrz8rKyukpKQUerw5c+YgJCREZ/UTERFRxaV1IEpMTCyNOl4qOzsbgwcPRm5uLpYuXaqxzd/fX/rZyckJjRo1Qtu2bXHy5Em4uroCeBbOXiSEKHB9nqCgIAQEBEjLGRkZsLOze9VTISIiogqoxB/MWFays7MxcOBAJCYmYs+ePRqzQwVxdXWFgYEBLl26BFdXV6jVaty8eTNfu1u3bsHa2rrQfpRKJZRK5SvXT0RERBVfiT6YsazkhaFLly5h165dsLCwKHKf+Ph4ZGdnw8bGBgDg5uaG9PR0HDt2TGpz9OhRpKenw93dvdRqJyIiosqjXGeIMjMzcfnyZWk5MTERsbGxMDc3h62tLd566y2cPHkS27ZtQ05OjnTPj7m5OQwNDXHlyhVERESgR48esLS0xLlz5xAYGAgXFxd06NABwLObwLt37w5/f3/pcfzRo0fDx8eHT5gRERERgHIORCdOnICnp6e0nHfPzrBhwxAcHIwtW7YAAFq3bq2x3969e+Hh4QFDQ0Ps3r0b3377LTIzM2FnZ4eePXti5syZ0NPTk9pHRERg4sSJ8PLyAvDsowP4qdpERESUp1wDkYeHB4QQhW5/2TYAsLOzw/79+4s8jrm5OVavXq11fURERCQPJQ5EDx8+xLVr1/DkyRON9S1btnzlooiIiIjKktaB6NatWxgxYgT++uuvArfn5OS8clFEREREZUnrp8wmT56MtLQ0HDlyBMbGxoiMjMSKFSvQqFEj6Z4fIiIiospE6xmiPXv2YPPmzXjttddQrVo12Nvbo2vXrjAzM8OcOXPQs2fP0qiTiIiIqNRoPUP04MED6aswzM3NcevWLQCAs7MzTp48qdvqiIiIiMqA1oGoSZMmSEhIAPDscfgff/wR//77L3744QfpwxCJiIiIKhOtL5lNnjwZycnJAICZM2eiW7duiIiIgKGhIcLDw3VdHxEREVGp0zoQDRkyRPrZxcUFSUlJuHDhAurVqwdLS0udFkdERERUFrS+ZDZr1iw8fPhQWjYxMYGrqyuqV6+OWbNm6bQ4IiIiorKgdSAKCQlBZmZmvvUPHz5ESEiITooiIiIiKktaByIhBBQKRb71p0+fhrm5uU6KIiIiIipLxb6HqFatWlAoFFAoFGjcuLFGKMrJyUFmZiY++OCDUimSiIiIqDQVOxAtWrQIQgiMHDkSISEhUKlU0jZDQ0M4ODjAzc2tVIokIiIiKk3FDkTDhg0DADg6OsLd3R0GBgalVhQRERFRWdL6sfuOHTtKPz969AjZ2dka283MzF69KiIiIqIypPVN1Q8fPsT48eNhZWWFGjVqoFatWhovIiIiospG60D04YcfYs+ePVi6dCmUSiV++eUXhISEwNbWFitXriyNGomIiIhKldaXzLZu3YqVK1fCw8MDI0eOxJtvvomGDRvC3t4eERERGp9kTURERFQZaD1DdPfuXTg6OgJ4dr/Q3bt3AQBvvPEGDhw4oNvqiIiIiMqA1oGofv36SEpKAgA0b94cv/76K4BnM0c1a9bUZW1EREREZULrQDRixAicPn0aABAUFCTdSzRlyhR8+OGHOi+QiIiIqLRpfQ/RlClTpJ89PT1x4cIFnDhxAg0aNECrVq10WhwRERFRWdA6EL2oXr16qFevni5qISIiIioXWgWi3NxchIeHY8OGDUhKSoJCoYCjoyPeeust+Pn5Ffilr0REREQVXbHvIRJCoHfv3njvvffw77//wtnZGS1atMDVq1cxfPhw9OvXrzTrJCIiIio1xZ4hCg8Px4EDB7B79254enpqbNuzZw/69u2LlStXYujQoTovkoiIiKg0FXuGaO3atZg2bVq+MAQAnTp1wieffIKIiAidFkdERERUFoodiM6cOYPu3bsXut3b21t6HJ+IiIioMil2ILp79y6sra0L3W5tbY20tDSdFEVERERUloodiHJycqCvX/gtR3p6enj69KlOiiIiIiIqS8W+qVoIgeHDh0OpVBa4PSsrS2dFEREREZWlYgeiYcOGFdmGT5gRERFRZVTsQBQWFlaadRARERGVG62/3FWXDhw4gF69esHW1hYKhQKbNm3S2C6EQHBwMGxtbWFsbAwPDw/Ex8drtMnKysKECRNgaWmJ6tWro3fv3rhx44ZGm7S0NPj5+UGlUkGlUsHPzw/37t0r5bMjIiKiyqJcA9GDBw/QqlUrLFmypMDt8+bNw4IFC7BkyRIcP34carUaXbt2xf3796U2kydPxsaNG7Fu3TocPHgQmZmZ8PHxQU5OjtTG19cXsbGxiIyMRGRkJGJjY+Hn51fq50dERESVwyt/ueur8Pb2hre3d4HbhBBYtGgRpk+fjv79+wMAVqxYAWtra6xZswbvv/8+0tPTERoailWrVqFLly4AgNWrV8POzg67du1Ct27dcP78eURGRuLIkSNo164dAODnn3+Gm5sbEhIS0KRJk7I5WSIiIqqwynWG6GUSExORkpICLy8vaZ1SqUTHjh1x+PBhAEBMTAyys7M12tja2sLJyUlqEx0dDZVKJYUhAGjfvj1UKpXUhoiIiOStWIHI1dVV+tDFWbNm4eHDh6VaFACkpKQAQL4Pg7S2tpa2paSkwNDQELVq1XppGysrq3z9W1lZSW0KkpWVhYyMDI0XERERVU3FCkTnz5/HgwcPAAAhISHIzMws1aKep1AoNJaFEPnWvejFNgW1L6qfOXPmSDdhq1Qq2NnZaVk5ERERVRbFuoeodevWGDFiBN544w0IIfDNN9+gRo0aBbadMWOGTgpTq9UAns3w2NjYSOtTU1OlWSO1Wo0nT54gLS1NY5YoNTUV7u7uUpubN2/m6//WrVsv/SqSoKAgBAQESMsZGRkMRURERFVUsWaIwsPDYWFhgW3btkGhUOCvv/7Cxo0b871efGz+VTg6OkKtViMqKkpa9+TJE+zfv18KO23atIGBgYFGm+TkZMTFxUlt3NzckJ6ejmPHjkltjh49ivT0dKlNQZRKJczMzDReREREVDUVa4aoSZMmWLduHQCgWrVq2L17d4H35WgrMzMTly9flpYTExMRGxsLc3Nz1KtXD5MnT8bs2bPRqFEjNGrUCLNnz4aJiQl8fX0BACqVCqNGjUJgYCAsLCxgbm6OqVOnwtnZWXrqrFmzZujevTv8/f3x448/AgBGjx4NHx8fPmFGREREAErw2H1ubq7ODn7ixAl4enpKy3mXqIYNG4bw8HB89NFHePToEcaOHYu0tDS0a9cOO3fuhKmpqbTPwoULoa+vj4EDB+LRo0fo3LkzwsPDoaenJ7WJiIjAxIkTpafRevfuXehnHxEREZH8lOhziK5cuYJFixbh/PnzUCgUaNasGSZNmoQGDRpo1Y+HhweEEIVuVygUCA4ORnBwcKFtjIyMsHjxYixevLjQNubm5li9erVWtREREZF8aP05RDt27EDz5s1x7NgxtGzZEk5OTjh69ChatGihcS8PERERUWWh9QzRJ598gilTpuCrr77Kt/7jjz9G165ddVYcERERUVnQeobo/PnzGDVqVL71I0eOxLlz53RSFBEREVFZ0joQ1a5dG7GxsfnWx8bG6uTJMyIiIqKypvUlM39/f4wePRr//PMP3N3doVAocPDgQcydOxeBgYGlUSMRERFRqdI6EH322WcwNTXF/PnzERQUBODZF6oGBwdj4sSJOi+QiIiIqLRpHYgUCgWmTJmCKVOm4P79+wCg8blARERERJVNiT6HKA+DEBEREVUFWt9UTURERFTVMBARERGR7DEQERERkexpFYiys7Ph6emJixcvllY9RERERGVOq0BkYGCAuLg4KBSK0qqHiIiIqMxpfcls6NChCA0NLY1aiIiIiMqF1o/dP3nyBL/88guioqLQtm1bVK9eXWP7ggULdFYcERERUVnQOhDFxcXB1dUVAPLdS8RLaURERFQZaR2I9u7dWxp1EBEREZWbEj92f/nyZezYsQOPHj0CAAghdFYUERERUVnSOhDduXMHnTt3RuPGjdGjRw8kJycDAN577z1+2z0RERFVSloHoilTpsDAwADXrl2DiYmJtH7QoEGIjIzUaXFEREREZUHre4h27tyJHTt2oG7duhrrGzVqhKtXr+qsMCIiIqKyovUM0YMHDzRmhvLcvn0bSqVSJ0URERERlSWtA9H//vc/rFy5UlpWKBTIzc3F119/DU9PT50WR0RERFQWtL5k9vXXX8PDwwMnTpzAkydP8NFHHyE+Ph53797FoUOHSqNGIiIiolKl9QxR8+bNcebMGbz++uvo2rUrHjx4gP79++PUqVNo0KBBadRIREREVKq0niECALVajZCQEF3XQkRERFQuShSI0tLSEBoaivPnz0OhUKBZs2YYMWIEzM3NdV0fERERUanT+pLZ/v374ejoiO+++w5paWm4e/cuvvvuOzg6OmL//v2lUSMRERFRqdJ6hmjcuHEYOHAgli1bBj09PQBATk4Oxo4di3HjxiEuLk7nRRIRERGVJq1niK5cuYLAwEApDAGAnp4eAgICcOXKFZ0WR0RERFQWtA5Erq6uOH/+fL7158+fR+vWrXVRExEREVGZKtYlszNnzkg/T5w4EZMmTcLly5fRvn17AMCRI0fw/fff46uvviqdKomIiIhKUbECUevWraFQKCCEkNZ99NFH+dr5+vpi0KBBuquOiIiIqAwUKxAlJiaWdh1ERERE5aZY9xDZ29sX+6VrDg4OUCgU+V7jxo0DAAwfPjzftrxLeXmysrIwYcIEWFpaonr16ujduzdu3Lih81qJiIiocirRBzP++++/OHToEFJTU5Gbm6uxbeLEiTopLM/x48eRk5MjLcfFxaFr1654++23pXXdu3dHWFiYtGxoaKjRx+TJk7F161asW7cOFhYWCAwMhI+PD2JiYjSeliMiIiJ50joQhYWF4YMPPoChoSEsLCygUCikbQqFQueBqHbt2hrLX331FRo0aICOHTtK65RKJdRqdYH7p6enIzQ0FKtWrUKXLl0AAKtXr4adnR127dqFbt266bReIiIiqny0fux+xowZmDFjBtLT05GUlITExETp9c8//5RGjZInT55g9erVGDlypEYQ27dvH6ysrNC4cWP4+/sjNTVV2hYTE4Ps7Gx4eXlJ62xtbeHk5ITDhw8XeqysrCxkZGRovIiIiKhq0joQPXz4EIMHD0a1alrv+so2bdqEe/fuYfjw4dI6b29vREREYM+ePZg/fz6OHz+OTp06ISsrCwCQkpICQ0ND1KpVS6Mva2trpKSkFHqsOXPmQKVSSS87O7tSOSciIiIqf1qnmlGjRuG3334rjVqKFBoaCm9vb9ja2krrBg0ahJ49e8LJyQm9evXCX3/9hYsXL2L79u0v7UsIoTHL9KKgoCCkp6dLr+vXr+vsPIiIiKhi0foeojlz5sDHxweRkZFwdnaGgYGBxvYFCxborLjnXb16Fbt27cKGDRte2s7Gxgb29va4dOkSAECtVuPJkydIS0vTmCVKTU2Fu7t7of0olUoolUrdFE9EREQVmtaBaPbs2dixYweaNGkCAPluqi4tYWFhsLKyQs+ePV/a7s6dO7h+/TpsbGwAAG3atIGBgQGioqIwcOBAAEBycjLi4uIwb968UquXiIiIKg+tA9GCBQuwfPlyjft4Sltubi7CwsIwbNgw6Ov/X8mZmZkIDg7GgAEDYGNjg6SkJEybNg2Wlpbo168fAEClUmHUqFEIDAyEhYUFzM3NMXXqVDg7O0tPnREREZG8aR2IlEolOnToUBq1FGrXrl24du0aRo4cqbFeT08PZ8+excqVK3Hv3j3Y2NjA09MT69evh6mpqdRu4cKF0NfXx8CBA/Ho0SN07twZ4eHh/AwiIiIiAlCCQDRp0iQsXrwY3333XWnUUyAvLy+N71HLY2xsjB07dhS5v5GRERYvXozFixeXRnlERERUyWkdiI4dO4Y9e/Zg27ZtaNGiRb6bqou66ZmIiIiootE6ENWsWRP9+/cvjVqIiIiIykWJvrqDiIiIqCop+4+bJiIiIqpgtJ4hcnR0fOnnDZX295kRERER6ZrWgWjy5Mkay9nZ2Th16hQiIyPx4Ycf6qouIiIiojJTosfuC/L999/jxIkTr1wQERERUVnT2T1E3t7e+OOPP3TVHREREVGZ0Vkg+v3332Fubq6r7oiIiIjKjNaXzFxcXDRuqhZCICUlBbdu3cLSpUt1WhwRERFRWdA6EPXt21djuVq1aqhduzY8PDzQtGlTXdVFREREVGa0DkQzZ84sjTqIiIiIyg0/mJGIiIhkr9gzRNWqVXvpBzICgEKhwNOnT1+5KCIiIqKyVOxAtHHjxkK3HT58GIsXL4YQQidFEREREZWlYgeiPn365Ft34cIFBAUFYevWrRgyZAg+//xznRZHREREVBZKdA/Rf//9B39/f7Rs2RJPnz7FqVOnsGLFCtSrV0/X9RERERGVOq0CUXp6Oj7++GM0bNgQ8fHx2L17N7Zu3QpnZ+fSqo+IiIio1BX7ktm8efMwd+5cqNVqrF27tsBLaERERESVUbED0SeffAJjY2M0bNgQK1aswIoVKwpst2HDBp0VR0RERFQWih2Ihg4dWuRj90RERESVUbEDUXh4eCmWQURERFR++EnVREREJHsMRERERCR7DEREREQkewxEREREJHsMRERERCR7DEREREQkewxEREREJHsMRERERCR7DEREREQkewxEREREJHsMRERERCR7FToQBQcHQ6FQaLzUarW0XQiB4OBg2NrawtjYGB4eHoiPj9foIysrCxMmTIClpSWqV6+O3r1748aNG2V9KkRERFSBVehABAAtWrRAcnKy9Dp79qy0bd68eViwYAGWLFmC48ePQ61Wo2vXrrh//77UZvLkydi4cSPWrVuHgwcPIjMzEz4+PsjJySmP0yEiIqIKqNjfdl9e9PX1NWaF8gghsGjRIkyfPh39+/cHAKxYsQLW1tZYs2YN3n//faSnpyM0NBSrVq1Cly5dAACrV6+GnZ0ddu3ahW7dupXpuRAREVHFVOFniC5dugRbW1s4Ojpi8ODB+OeffwAAiYmJSElJgZeXl9RWqVSiY8eOOHz4MAAgJiYG2dnZGm1sbW3h5OQktSEiIiKq0DNE7dq1w8qVK9G4cWPcvHkTX3zxBdzd3REfH4+UlBQAgLW1tcY+1tbWuHr1KgAgJSUFhoaGqFWrVr42efsXJisrC1lZWdJyRkaGLk6JiIiIKqAKHYi8vb2ln52dneHm5oYGDRpgxYoVaN++PQBAoVBo7COEyLfuRcVpM2fOHISEhJSwciIiIqpMKvwls+dVr14dzs7OuHTpknRf0YszPampqdKskVqtxpMnT5CWllZom8IEBQUhPT1del2/fl2HZ0JEREQVSaUKRFlZWTh//jxsbGzg6OgItVqNqKgoafuTJ0+wf/9+uLu7AwDatGkDAwMDjTbJycmIi4uT2hRGqVTCzMxM40VERERVU4W+ZDZ16lT06tUL9erVQ2pqKr744gtkZGRg2LBhUCgUmDx5MmbPno1GjRqhUaNGmD17NkxMTODr6wsAUKlUGDVqFAIDA2FhYQFzc3NMnToVzs7O0lNnRERERBU6EN24cQPvvPMObt++jdq1a6N9+/Y4cuQI7O3tAQAfffQRHj16hLFjxyItLQ3t2rXDzp07YWpqKvWxcOFC6OvrY+DAgXj06BE6d+6M8PBw6OnplddpERERUQVToQPRunXrXrpdoVAgODgYwcHBhbYxMjLC4sWLsXjxYh1XR0RERFVFpbqHiIiIiKg0MBARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsVehANGfOHLz22mswNTWFlZUV+vbti4SEBI02w4cPh0Kh0Hi1b99eo01WVhYmTJgAS0tLVK9eHb1798aNGzfK8lSIiIioAqvQgWj//v0YN24cjhw5gqioKDx9+hReXl548OCBRrvu3bsjOTlZev35558a2ydPnoyNGzdi3bp1OHjwIDIzM+Hj44OcnJyyPB0iIiKqoPTLu4CXiYyM1FgOCwuDlZUVYmJi8L///U9ar1QqoVarC+wjPT0doaGhWLVqFbp06QIAWL16Nezs7LBr1y5069at9E6AiIiIKoUKPUP0ovT0dACAubm5xvp9+/bBysoKjRs3hr+/P1JTU6VtMTExyM7OhpeXl7TO1tYWTk5OOHz4cKHHysrKQkZGhsaLiIiIqqZKE4iEEAgICMAbb7wBJycnab23tzciIiKwZ88ezJ8/H8ePH0enTp2QlZUFAEhJSYGhoSFq1aql0Z+1tTVSUlIKPd6cOXOgUqmkl52dXemcGBEREZW7Cn3J7Hnjx4/HmTNncPDgQY31gwYNkn52cnJC27ZtYW9vj+3bt6N///6F9ieEgEKhKHR7UFAQAgICpOWMjAyGIiIioiqqUswQTZgwAVu2bMHevXtRt27dl7a1sbGBvb09Ll26BABQq9V48uQJ0tLSNNqlpqbC2tq60H6USiXMzMw0XkRERFQ1VehAJITA+PHjsWHDBuzZsweOjo5F7nPnzh1cv34dNjY2AIA2bdrAwMAAUVFRUpvk5GTExcXB3d291GonIiKiyqNCXzIbN24c1qxZg82bN8PU1FS650elUsHY2BiZmZkIDg7GgAEDYGNjg6SkJEybNg2Wlpbo16+f1HbUqFEIDAyEhYUFzM3NMXXqVDg7O0tPnREREZG8VehAtGzZMgCAh4eHxvqwsDAMHz4cenp6OHv2LFauXIl79+7BxsYGnp6eWL9+PUxNTaX2CxcuhL6+PgYOHIhHjx6hc+fOCA8Ph56eXlmeDhEREVVQFToQCSFeut3Y2Bg7duwosh8jIyMsXrwYixcv1lVpREREVIVU6HuIiIiIiMoCAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyZ6sAtHSpUvh6OgIIyMjtGnTBn///Xd5l0REREQVgGwC0fr16zF58mRMnz4dp06dwptvvglvb29cu3atvEsjIiKiciabQLRgwQKMGjUK7733Hpo1a4ZFixbBzs4Oy5YtK+/SiIiIqJzJIhA9efIEMTEx8PLy0ljv5eWFw4cPl1NVREREVFHol3cBZeH27dvIycmBtbW1xnpra2ukpKQUuE9WVhaysrKk5fT0dABARkaGzuvLzXqo8z4ri1cZT7mO26v+DnLcSobjpj2OWclw3EqnXyHES9vJIhDlUSgUGstCiHzr8syZMwchISH51tvZ2ZVKbXKlWlTeFVQ+HLOS4biVDMdNexyzkintcbt//z5UKlWh22URiCwtLaGnp5dvNig1NTXfrFGeoKAgBAQESMu5ubm4e/cuLCwsCg1RlU1GRgbs7Oxw/fp1mJmZlXc5lQbHrWQ4biXDcdMex6xkquq4CSFw//592NravrSdLAKRoaEh2rRpg6ioKPTr109aHxUVhT59+hS4j1KphFKp1FhXs2bN0iyz3JiZmVWpX/6ywnErGY5byXDctMcxK5mqOG4vmxnKI4tABAABAQHw8/ND27Zt4ebmhp9++gnXrl3DBx98UN6lERERUTmTTSAaNGgQ7ty5g1mzZiE5ORlOTk74888/YW9vX96lERERUTmTTSACgLFjx2Ls2LHlXUaFoVQqMXPmzHyXBunlOG4lw3ErGY6b9jhmJSP3cVOIop5DIyIiIqriZPHBjEREREQvw0BEREREssdARERERLLHQFSFhYeHa/XZSfv27YNCocC9e/dKraaKjmNWMhy3kuG4lQzHTXscs2IQVGEcOnRIVKtWTXTr1k3rfe3t7cXChQs11j18+FDcvHmz2H1kZWWJ5ORkkZubK4QQIiwsTKhUKq1rKcjEiROFq6urMDQ0FK1atdJJn0JU3TGLjY0VgwcPFnXr1hVGRkaiadOmYtGiRa/cb56qOm63b98W3bp1EzY2NsLQ0FDUrVtXjBs3TqSnp79y30JU3XF73u3bt0WdOnUEAJGWlqaTPqvyuAHI91q2bNkr91uVxyyvP2dnZ6FUKoW1tbUYN26czvouKc4QVSDLly/HhAkTcPDgQVy7du2V+zM2NoaVlVWx2xsaGkKtVpfKV5MIITBy5EgMGjRIp/1W1TGLiYlB7dq1sXr1asTHx2P69OkICgrCkiVLdNJ/VR23atWqoU+fPtiyZQsuXryI8PBw7Nq1S2cfwFpVx+15o0aNQsuWLXXaZ1Uft7CwMCQnJ0uvYcOGvXKfVXnMFixYgOnTp+OTTz5BfHw8du/ejW7duun8OFor70RGz2RmZgpTU1Nx4cIFMWjQIBESEpKvzebNm0WbNm2EUqkUFhYWol+/fkIIITp27Jjv/1CE0Ez0Fy5cEADE+fPnNfqcP3++sLe3F7m5uWLv3r3S/xXm/fz8a+bMmSIkJEQ4OTnlq83V1VV89tlnRZ7nzJkzdTZDJJcxyzN27Fjh6elZ7PaFkdu4ffvtt6Ju3brFbl8YOYzb0qVLRceOHcXu3bt1NkNU1ccNgNi4cWMJR6dgVXnM7t69K4yNjcWuXbteZYhKBQNRBREaGiratm0rhBBi69atwsHBQZqqFEKIbdu2CT09PTFjxgxx7tw5ERsbK7788kshhBB37twRdevWFbNmzRLJyckiOTlZCJF/irNNmzbi008/1ThumzZtRFBQkBBCaPwDyMrKEosWLRJmZmZSn/fv3xfXr18X1apVE8eOHZP6OH36tFAoFOLKlStFnqcuA5FcxizPkCFDxIABA7QbpALIadz+/fdf0bFjRzFkyBDtB+oFVX3c4uPjhVqtFlevXtU4zquq6uMGQNSpU0dYWFiItm3bimXLlomcnByOWSFjtn79eqFUKsWKFStE06ZNRZ06dcTbb78trl279kpjpgsMRBWEu7u7dI9Idna2sLS0FFFRUdJ2Nze3l/5HvaBrxi/+A1iwYIGoX7++tJyQkCAAiPj4eCGEyPcfwcKuGXt7e4sxY8ZIy5MnTxYeHh7FOk9dBiK5jJkQQhw+fFgYGBiInTt3Fnufwshh3AYPHiyMjY0FANGrVy/x6NGjIvcpSlUet8ePH4uWLVuKVatWFXicV1GVx00IIT7//HNx+PBhcerUKfHNN98IExMT8fnnn790n6JU5TGbM2eOMDAwEE2aNBGRkZEiOjpadO7cWTRp0kRkZWUVul9Z4D1EFUBCQgKOHTuGwYMHAwD09fUxaNAgLF++XGoTGxuLzp07v9JxBg8ejKtXr+LIkSMAgIiICLRu3RrNmzfXqh9/f3+sXbsWjx8/RnZ2NiIiIjBy5MhXqk1bchqz+Ph49OnTBzNmzEDXrl21PofnyWXcFi5ciJMnT2LTpk24cuUKAgICSnQeear6uAUFBaFZs2Z49913X6n+F1X1cQOATz/9FG5ubmjdujUCAwMxa9YsfP311yU+l6o+Zrm5ucjOzsZ3332Hbt26oX379li7di0uXbqEvXv3vtI5vSpZfZdZRRUaGoqnT5+iTp060johBAwMDJCWloZatWrB2Nj4lY9jY2MDT09PrFmzRvolfP/997Xup1evXlAqldi4cSOUSiWysrIwYMCAV65PG3IZs3PnzqFTp07w9/fHp59+WpJT0CCXcVOr1VCr1WjatCksLCzw5ptv4rPPPoONjU1JTqfKj9uePXtw9uxZ/P777wCenRsAWFpaYvr06QgJCSnR+VT1cStI+/btkZGRgZs3b8La2lrrGqr6mOX9G3w+eNWuXRuWlpY6uXn8VXCGqJw9ffoUK1euxPz58xEbGyu9Tp8+DXt7e0RERAAAWrZsid27dxfaj6GhIXJycoo83pAhQ7B+/XpER0fjypUr0v+FaNOnvr4+hg0bhrCwMISFhWHw4MEwMTEpxtnqhlzGLD4+Hp6enhg2bBi+/PLLIussilzG7UV5f9yzsrK02i+PHMbtjz/+wOnTp6Vz++WXXwAAf//9N8aNG1dkzQWRw7gV5NSpUzAyMtLqM3/yyGHMOnToAODZTFieu3fv4vbt27C3ty+y5lJVflfrSAghNm7cKAwNDcW9e/fybZs2bZpo3bq1EOLZ9dxq1apJN9GdOXNGzJ07V2rbtWtX0bt3b3Hjxg1x69YtIUTB13zT09OFkZGRaNWqlejcubPGthevGR86dEgAELt27RK3bt0SDx48kNpevHhR6OnpCT09PXHkyJEiz/PSpUvi1KlT4v333xeNGzcWp06dEqdOnSrRNWM5jFlcXJyoXbu2GDJkiHQTY3JyskhNTS32OL1IDuO2fft2sXz5cnH27FmRmJgotm/fLlq0aCE6dOhQ7HF6kRzG7UW6uIdIDuO2ZcsW8dNPP4mzZ8+Ky5cvi59//lmYmZmJiRMnFnucnieHMRNCiD59+ogWLVqIQ4cOibNnzwofHx/RvHlz8eTJk2KNU2lhICpnPj4+okePHgVui4mJEQBETEyMEEKIP/74Q7Ru3VoYGhoKS0tL0b9/f6ltdHS0aNmypVAqlQU+Zvm8t99+WwAQy5cv11hf0H8EP/jgA2FhYSE9Zvm8N998UzRv3rxY51nQo6AARGJiYrH2f54cxmzmzJkFjpe9vX2R+xZGDuO2Z88e4ebmJlQqlTAyMhKNGjUSH3/88Sv9YZfDuL1IF4FIDuP2119/idatW4saNWoIExMT4eTkJBYtWiSys7OL3LcgchgzIZ4FsZEjR4qaNWsKc3Nz0a9fvwrxlJlCiP8/n0ykBSEEmjZtivfff/+Vb1iVC45ZyXDcSobjVjIcN+1VlTHjTdWktdTUVKxatQr//vsvRowYUd7lVAocs5LhuJUMx61kOG7aq0pjxkBEWrO2toalpSV++ukn1KpVq7zLqRQ4ZiXDcSsZjlvJcNy0V5XGjJfMiIiISPb42D0RERHJHgMRERERyR4DEREREckeAxERERHJHgMREVVI4eHhWn39wb59+6BQKHDv3r1Sq6mkHBwcsGjRolfqIzg4GK1bt9ZJPUSUHwMREenE4cOHoaenh+7du2u9b0GBYdCgQbh48WKx+3B3d0dycjJUKhUA7QNVYZKSkqBQKBAbG/vKfRFRxcVAREQ6sXz5ckyYMAEHDx7UybdWGxsbw8rKqtjtDQ0NoVaroVAoXvnYRCQ/DERE9MoePHiAX3/9FWPGjIGPjw/Cw8PztdmyZQvatm0LIyMjWFpaon///gAADw8PXL16FVOmTIFCoZACzfMzPAkJCVAoFLhw4YJGnwsWLICDgwOEEBqXzPbt24cRI0YgPT1d6jM4OBizZs2Cs7NzvtratGmDGTNmlOjcr1y5gj59+sDa2ho1atTAa6+9hl27duVrd//+ffj6+qJGjRqwtbXF4sWLNbanp6dj9OjRsLKygpmZGTp16oTTp08Xetx9+/bh9ddfR/Xq1VGzZk106NABV69eLdE5EBEDERHpwPr169GkSRM0adIE7777LsLCwvD8Z75u374d/fv3R8+ePXHq1Cns3r0bbdu2BQBs2LABdevWxaxZs5CcnIzk5OR8/Tdp0gRt2rRBRESExvo1a9bA19c336yQu7s7Fi1aBDMzM6nPqVOnYuTIkTh37hyOHz8utT1z5gxOnTqF4cOHl+jcMzMz0aNHD+zatQunTp1Ct27d0KtXr3yzZF9//TVatmyJkydPIigoCFOmTEFUVBSAZ98F1bNnT6SkpODPP/9ETEwMXF1d0blzZ9y9ezffMZ8+fYq+ffuiY8eOOHPmDKKjozF69GjOjhG9inL5SlkiqlLc3d3FokWLhBBCZGdnC0tLSxEVFSVtd3NzE0OGDCl0f3t7e7Fw4UKNdS9+O/eCBQtE/fr1peWEhAQBQMTHxwsh8n87d2Hf7u3t7S3GjBkjLU+ePFl4eHgUWltiYqIAIE6dOlVomxc1b95cLF68WOP8unfvrtFm0KBBwtvbWwghxO7du4WZmZl4/PixRpsGDRqIH3/8UQghxMyZM0WrVq2EEELcuXNHABD79u0rdk1E9HKcISKiV5KQkIBjx45h8ODBAAB9fX0MGjQIy5cvl9rExsaic+fOr3ScwYMH4+rVqzhy5AgAICIiAq1bt0bz5s216sff3x9r167F48ePkZ2djYiICIwcObLEdT148AAfffQRmjdvjpo1a6JGjRq4cOFCvhkiNze3fMvnz58HAMTExCAzMxMWFhaoUaOG9EpMTMSVK1fyHdPc3BzDhw+XZqO+/fbbAmfWiKj4+OWuRPRKQkND8fTpU9SpU0daJ4SAgYEB0tLSUKtWLRgbG7/ycWxsbODp6Yk1a9agffv2WLt2Ld5//32t++nVqxeUSiU2btwIpVKJrKwsDBgwoMR1ffjhh9ixYwe++eYbNGzYEMbGxnjrrbfw5MmTIvfNu8SVm5sLGxsb7Nu3L1+bwp6UCwsLw8SJExEZGYn169fj008/RVRUFNq3b1/icyGSMwYiIiqxp0+fYuXKlZg/fz68vLw0tg0YMAAREREYP348WrZsid27d2PEiBEF9mNoaIicnJwijzdkyBB8/PHHeOedd3DlyhVpVkqbPvX19TFs2DCEhYVBqVRi8ODBMDExKfLYhfn7778xfPhw9OvXD8Cze4qSkpLytcub2Xp+uWnTpgAAV1dXpKSkQF9fHw4ODsU+touLC1xcXBAUFAQ3NzcpLBKR9hiIiKjEtm3bhrS0NIwaNUr6/J88b731FkJDQzF+/HjMnDkTnTt3RoMGDTB48GA8ffoUf/31Fz766CMAzz6H6MCBAxg8eDCUSiUsLS0LPF7//v0xZswYjBkzBp6enhqzUi9ycHBAZmYmdu/ejVatWsHExEQKPu+99x6aNWsGADh06FCxzjUhISHfuubNm6Nhw4bYsGEDevXqBYVCgc8++wy5ubn52h46dAjz5s1D3759ERUVhd9++w3bt28HAHTp0gVubm7o27cv5s6diyZNmuC///7Dn3/+ib59+0o3oOdJTEzETz/9hN69e8PW1hYJCQm4ePEihg4dWqxzIaIClPdNTERUefn4+IgePXoUuC0mJkYAEDExMUIIIf744w/RunVrYWhoKCwtLUX//v2lttHR0aJly5ZCqVSKvP8sFXZT9Ntvvy0AiOXLl2usf/GmaiGE+OCDD4SFhYUAIGbOnKnR/s033xTNmzcv8hzzbqou6JWYmCgSExOFp6enMDY2FnZ2dmLJkiWiY8eOYtKkSVIf9vb2IiQkRAwcOFCYmJgIa2tr6Sb0PBkZGWLChAnC1tZWGBgYCDs7OzFkyBBx7do1IYTmTdUpKSmib9++wsbGRhgaGgp7e3sxY8YMkZOTU+T5EFHBFEI892wsEZEMCCHQtGlTvP/++wgICCjvcoioAuAlMyKSldTUVKxatQr//vtvofc0EZH8MBARkaxYW1vD0tISP/30E2rVqlXe5RBRBcFARESywrsEiKgg/GBGIiIikj0GIiIiIpI9BiIiIiKSPQYiIiIikj0GIiIiIpI9BiIiIiKSPQYiIiIikj0GIiIiIpI9BiIiIiKSvf8HY258A2a07PIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# apply the data_exploration_pipeline to dataset type 1\n",
    "data_exploration_pipeline(Dataset_type_I,1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset type II has a shape of: 12637 rows and 642 columns\n",
      "\n",
      "\n",
      "\n",
      "The first 3 rows of Dataset type II :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_body_acc_mean()_X</th>\n",
       "      <th>t_body_acc_mean()_Y</th>\n",
       "      <th>t_body_acc_mean()_Z</th>\n",
       "      <th>t_body_acc_std()_X</th>\n",
       "      <th>t_body_acc_std()_Y</th>\n",
       "      <th>t_body_acc_std()_Z</th>\n",
       "      <th>t_body_acc_mad()_X</th>\n",
       "      <th>t_body_acc_mad()_Y</th>\n",
       "      <th>t_body_acc_mad()_Z</th>\n",
       "      <th>t_body_acc_max()_X</th>\n",
       "      <th>...</th>\n",
       "      <th>f_body_gyro_Jerk_Mag_kurtosis()</th>\n",
       "      <th>angle0()</th>\n",
       "      <th>angle1()</th>\n",
       "      <th>angle2()</th>\n",
       "      <th>angle3()</th>\n",
       "      <th>angle4()</th>\n",
       "      <th>angle5()</th>\n",
       "      <th>angle6()</th>\n",
       "      <th>activity_Id</th>\n",
       "      <th>user_Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.004441</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>0.013983</td>\n",
       "      <td>0.027372</td>\n",
       "      <td>0.004725</td>\n",
       "      <td>0.019132</td>\n",
       "      <td>0.025280</td>\n",
       "      <td>0.010209</td>\n",
       "      <td>...</td>\n",
       "      <td>104.954731</td>\n",
       "      <td>1.070749</td>\n",
       "      <td>1.431913</td>\n",
       "      <td>2.116867</td>\n",
       "      <td>1.431211</td>\n",
       "      <td>0.152888</td>\n",
       "      <td>1.692169</td>\n",
       "      <td>1.478284</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000713</td>\n",
       "      <td>-0.003098</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.004491</td>\n",
       "      <td>0.012449</td>\n",
       "      <td>0.022660</td>\n",
       "      <td>0.004168</td>\n",
       "      <td>0.014039</td>\n",
       "      <td>0.022765</td>\n",
       "      <td>0.009030</td>\n",
       "      <td>...</td>\n",
       "      <td>109.749747</td>\n",
       "      <td>1.652580</td>\n",
       "      <td>1.856253</td>\n",
       "      <td>1.210803</td>\n",
       "      <td>1.753009</td>\n",
       "      <td>0.149532</td>\n",
       "      <td>1.687352</td>\n",
       "      <td>1.477548</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000301</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>-0.004280</td>\n",
       "      <td>0.004866</td>\n",
       "      <td>0.009352</td>\n",
       "      <td>0.016821</td>\n",
       "      <td>0.005255</td>\n",
       "      <td>0.010157</td>\n",
       "      <td>0.020681</td>\n",
       "      <td>0.011261</td>\n",
       "      <td>...</td>\n",
       "      <td>110.445137</td>\n",
       "      <td>1.776612</td>\n",
       "      <td>1.159471</td>\n",
       "      <td>1.763958</td>\n",
       "      <td>2.682216</td>\n",
       "      <td>0.157004</td>\n",
       "      <td>1.696158</td>\n",
       "      <td>1.476770</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 642 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   t_body_acc_mean()_X  t_body_acc_mean()_Y  t_body_acc_mean()_Z  \\\n",
       "0             0.002012             0.000431             0.004441   \n",
       "1            -0.000713            -0.003098             0.000823   \n",
       "2            -0.000301             0.004025            -0.004280   \n",
       "\n",
       "   t_body_acc_std()_X  t_body_acc_std()_Y  t_body_acc_std()_Z  \\\n",
       "0            0.004025            0.013983            0.027372   \n",
       "1            0.004491            0.012449            0.022660   \n",
       "2            0.004866            0.009352            0.016821   \n",
       "\n",
       "   t_body_acc_mad()_X  t_body_acc_mad()_Y  t_body_acc_mad()_Z  \\\n",
       "0            0.004725            0.019132            0.025280   \n",
       "1            0.004168            0.014039            0.022765   \n",
       "2            0.005255            0.010157            0.020681   \n",
       "\n",
       "   t_body_acc_max()_X  ...  f_body_gyro_Jerk_Mag_kurtosis()  angle0()  \\\n",
       "0            0.010209  ...                       104.954731  1.070749   \n",
       "1            0.009030  ...                       109.749747  1.652580   \n",
       "2            0.011261  ...                       110.445137  1.776612   \n",
       "\n",
       "   angle1()  angle2()  angle3()  angle4()  angle5()  angle6()  activity_Id  \\\n",
       "0  1.431913  2.116867  1.431211  0.152888  1.692169  1.478284          5.0   \n",
       "1  1.856253  1.210803  1.753009  0.149532  1.687352  1.477548          5.0   \n",
       "2  1.159471  1.763958  2.682216  0.157004  1.696158  1.476770          5.0   \n",
       "\n",
       "   user_Id  \n",
       "0      1.0  \n",
       "1      1.0  \n",
       "2      1.0  \n",
       "\n",
       "[3 rows x 642 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "rows 500, 501, 502 of Dataset type II :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_body_acc_mean()_X</th>\n",
       "      <th>t_body_acc_mean()_Y</th>\n",
       "      <th>t_body_acc_mean()_Z</th>\n",
       "      <th>t_body_acc_std()_X</th>\n",
       "      <th>t_body_acc_std()_Y</th>\n",
       "      <th>t_body_acc_std()_Z</th>\n",
       "      <th>t_body_acc_mad()_X</th>\n",
       "      <th>t_body_acc_mad()_Y</th>\n",
       "      <th>t_body_acc_mad()_Z</th>\n",
       "      <th>t_body_acc_max()_X</th>\n",
       "      <th>...</th>\n",
       "      <th>f_body_gyro_Jerk_Mag_kurtosis()</th>\n",
       "      <th>angle0()</th>\n",
       "      <th>angle1()</th>\n",
       "      <th>angle2()</th>\n",
       "      <th>angle3()</th>\n",
       "      <th>angle4()</th>\n",
       "      <th>angle5()</th>\n",
       "      <th>angle6()</th>\n",
       "      <th>activity_Id</th>\n",
       "      <th>user_Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>-0.002838</td>\n",
       "      <td>0.003938</td>\n",
       "      <td>0.001229</td>\n",
       "      <td>0.007675</td>\n",
       "      <td>0.011710</td>\n",
       "      <td>0.007567</td>\n",
       "      <td>0.008171</td>\n",
       "      <td>0.010390</td>\n",
       "      <td>0.009672</td>\n",
       "      <td>0.014154</td>\n",
       "      <td>...</td>\n",
       "      <td>92.904700</td>\n",
       "      <td>0.595612</td>\n",
       "      <td>0.373307</td>\n",
       "      <td>1.919948</td>\n",
       "      <td>1.408653</td>\n",
       "      <td>1.741841</td>\n",
       "      <td>0.767171</td>\n",
       "      <td>0.832664</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.000645</td>\n",
       "      <td>-0.000686</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>0.010840</td>\n",
       "      <td>0.014041</td>\n",
       "      <td>0.008008</td>\n",
       "      <td>0.012480</td>\n",
       "      <td>0.022424</td>\n",
       "      <td>0.009438</td>\n",
       "      <td>0.021118</td>\n",
       "      <td>...</td>\n",
       "      <td>102.903039</td>\n",
       "      <td>1.512744</td>\n",
       "      <td>2.908417</td>\n",
       "      <td>1.321577</td>\n",
       "      <td>1.450209</td>\n",
       "      <td>1.744285</td>\n",
       "      <td>0.766016</td>\n",
       "      <td>0.834653</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.002999</td>\n",
       "      <td>-0.003556</td>\n",
       "      <td>-0.002519</td>\n",
       "      <td>0.010914</td>\n",
       "      <td>0.013154</td>\n",
       "      <td>0.007891</td>\n",
       "      <td>0.012220</td>\n",
       "      <td>0.014542</td>\n",
       "      <td>0.007651</td>\n",
       "      <td>0.021118</td>\n",
       "      <td>...</td>\n",
       "      <td>106.129338</td>\n",
       "      <td>2.696368</td>\n",
       "      <td>0.700894</td>\n",
       "      <td>1.778412</td>\n",
       "      <td>1.796154</td>\n",
       "      <td>1.745504</td>\n",
       "      <td>0.766503</td>\n",
       "      <td>0.834582</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 642 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     t_body_acc_mean()_X  t_body_acc_mean()_Y  t_body_acc_mean()_Z  \\\n",
       "500            -0.002838             0.003938             0.001229   \n",
       "501             0.000645            -0.000686             0.001023   \n",
       "502             0.002999            -0.003556            -0.002519   \n",
       "\n",
       "     t_body_acc_std()_X  t_body_acc_std()_Y  t_body_acc_std()_Z  \\\n",
       "500            0.007675            0.011710            0.007567   \n",
       "501            0.010840            0.014041            0.008008   \n",
       "502            0.010914            0.013154            0.007891   \n",
       "\n",
       "     t_body_acc_mad()_X  t_body_acc_mad()_Y  t_body_acc_mad()_Z  \\\n",
       "500            0.008171            0.010390            0.009672   \n",
       "501            0.012480            0.022424            0.009438   \n",
       "502            0.012220            0.014542            0.007651   \n",
       "\n",
       "     t_body_acc_max()_X  ...  f_body_gyro_Jerk_Mag_kurtosis()  angle0()  \\\n",
       "500            0.014154  ...                        92.904700  0.595612   \n",
       "501            0.021118  ...                       102.903039  1.512744   \n",
       "502            0.021118  ...                       106.129338  2.696368   \n",
       "\n",
       "     angle1()  angle2()  angle3()  angle4()  angle5()  angle6()  activity_Id  \\\n",
       "500  0.373307  1.919948  1.408653  1.741841  0.767171  0.832664          6.0   \n",
       "501  2.908417  1.321577  1.450209  1.744285  0.766016  0.834653          6.0   \n",
       "502  0.700894  1.778412  1.796154  1.745504  0.766503  0.834582          6.0   \n",
       "\n",
       "     user_Id  \n",
       "500      2.0  \n",
       "501      2.0  \n",
       "502      2.0  \n",
       "\n",
       "[3 rows x 642 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Description of the 10 first features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_body_acc_mean()_X</th>\n",
       "      <th>t_body_acc_mean()_Y</th>\n",
       "      <th>t_body_acc_mean()_Z</th>\n",
       "      <th>t_body_acc_std()_X</th>\n",
       "      <th>t_body_acc_std()_Y</th>\n",
       "      <th>t_body_acc_std()_Z</th>\n",
       "      <th>t_body_acc_mad()_X</th>\n",
       "      <th>t_body_acc_mad()_Y</th>\n",
       "      <th>t_body_acc_mad()_Z</th>\n",
       "      <th>t_body_acc_max()_X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12637.000000</td>\n",
       "      <td>12637.000000</td>\n",
       "      <td>12637.000000</td>\n",
       "      <td>12637.000000</td>\n",
       "      <td>12637.000000</td>\n",
       "      <td>12637.000000</td>\n",
       "      <td>12637.000000</td>\n",
       "      <td>12637.000000</td>\n",
       "      <td>12637.000000</td>\n",
       "      <td>12637.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.129527</td>\n",
       "      <td>0.091432</td>\n",
       "      <td>0.077082</td>\n",
       "      <td>0.117569</td>\n",
       "      <td>0.082015</td>\n",
       "      <td>0.069997</td>\n",
       "      <td>0.325529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.009201</td>\n",
       "      <td>0.007817</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.132270</td>\n",
       "      <td>0.077842</td>\n",
       "      <td>0.066147</td>\n",
       "      <td>0.124176</td>\n",
       "      <td>0.070374</td>\n",
       "      <td>0.059358</td>\n",
       "      <td>0.334534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.046247</td>\n",
       "      <td>-0.053277</td>\n",
       "      <td>-0.042451</td>\n",
       "      <td>0.001815</td>\n",
       "      <td>0.002371</td>\n",
       "      <td>0.003535</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>0.002615</td>\n",
       "      <td>0.003151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.003742</td>\n",
       "      <td>-0.003890</td>\n",
       "      <td>-0.003715</td>\n",
       "      <td>0.010734</td>\n",
       "      <td>0.014096</td>\n",
       "      <td>0.013458</td>\n",
       "      <td>0.011465</td>\n",
       "      <td>0.015104</td>\n",
       "      <td>0.014450</td>\n",
       "      <td>0.021017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.000032</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>0.070663</td>\n",
       "      <td>0.083293</td>\n",
       "      <td>0.070395</td>\n",
       "      <td>0.049695</td>\n",
       "      <td>0.066805</td>\n",
       "      <td>0.057120</td>\n",
       "      <td>0.165403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.003711</td>\n",
       "      <td>0.003810</td>\n",
       "      <td>0.003636</td>\n",
       "      <td>0.233780</td>\n",
       "      <td>0.157675</td>\n",
       "      <td>0.128477</td>\n",
       "      <td>0.214532</td>\n",
       "      <td>0.139145</td>\n",
       "      <td>0.116226</td>\n",
       "      <td>0.603124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.045010</td>\n",
       "      <td>0.059873</td>\n",
       "      <td>0.054561</td>\n",
       "      <td>0.661947</td>\n",
       "      <td>0.344200</td>\n",
       "      <td>0.347364</td>\n",
       "      <td>0.754020</td>\n",
       "      <td>0.360647</td>\n",
       "      <td>0.413934</td>\n",
       "      <td>1.226526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       t_body_acc_mean()_X  t_body_acc_mean()_Y  t_body_acc_mean()_Z  \\\n",
       "count         12637.000000         12637.000000         12637.000000   \n",
       "mean             -0.000021            -0.000012             0.000025   \n",
       "std               0.009201             0.007817             0.007812   \n",
       "min              -0.046247            -0.053277            -0.042451   \n",
       "25%              -0.003742            -0.003890            -0.003715   \n",
       "50%              -0.000032             0.000007            -0.000092   \n",
       "75%               0.003711             0.003810             0.003636   \n",
       "max               0.045010             0.059873             0.054561   \n",
       "\n",
       "       t_body_acc_std()_X  t_body_acc_std()_Y  t_body_acc_std()_Z  \\\n",
       "count        12637.000000        12637.000000        12637.000000   \n",
       "mean             0.129527            0.091432            0.077082   \n",
       "std              0.132270            0.077842            0.066147   \n",
       "min              0.001815            0.002371            0.003535   \n",
       "25%              0.010734            0.014096            0.013458   \n",
       "50%              0.070663            0.083293            0.070395   \n",
       "75%              0.233780            0.157675            0.128477   \n",
       "max              0.661947            0.344200            0.347364   \n",
       "\n",
       "       t_body_acc_mad()_X  t_body_acc_mad()_Y  t_body_acc_mad()_Z  \\\n",
       "count        12637.000000        12637.000000        12637.000000   \n",
       "mean             0.117569            0.082015            0.069997   \n",
       "std              0.124176            0.070374            0.059358   \n",
       "min              0.001536            0.001921            0.002615   \n",
       "25%              0.011465            0.015104            0.014450   \n",
       "50%              0.049695            0.066805            0.057120   \n",
       "75%              0.214532            0.139145            0.116226   \n",
       "max              0.754020            0.360647            0.413934   \n",
       "\n",
       "       t_body_acc_max()_X  \n",
       "count        12637.000000  \n",
       "mean             0.325529  \n",
       "std              0.334534  \n",
       "min              0.003151  \n",
       "25%              0.021017  \n",
       "50%              0.165403  \n",
       "75%              0.603124  \n",
       "max              1.226526  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Description of the 10 first frequency features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_body_acc_mean()_X</th>\n",
       "      <th>f_body_acc_mean()_Y</th>\n",
       "      <th>f_body_acc_mean()_Z</th>\n",
       "      <th>f_body_acc_std()_X</th>\n",
       "      <th>f_body_acc_std()_Y</th>\n",
       "      <th>f_body_acc_std()_Z</th>\n",
       "      <th>f_body_acc_mad()_X</th>\n",
       "      <th>f_body_acc_mad()_Y</th>\n",
       "      <th>f_body_acc_mad()_Z</th>\n",
       "      <th>f_body_acc_max()_X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12637.000000</td>\n",
       "      <td>12637.000000</td>\n",
       "      <td>12637.000000</td>\n",
       "      <td>12637.000000</td>\n",
       "      <td>12637.000000</td>\n",
       "      <td>12637.000000</td>\n",
       "      <td>12637.000000</td>\n",
       "      <td>12637.000000</td>\n",
       "      <td>12637.000000</td>\n",
       "      <td>12637.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.754216</td>\n",
       "      <td>0.578450</td>\n",
       "      <td>0.476064</td>\n",
       "      <td>1.256014</td>\n",
       "      <td>0.857476</td>\n",
       "      <td>0.729452</td>\n",
       "      <td>0.334269</td>\n",
       "      <td>0.268586</td>\n",
       "      <td>0.245777</td>\n",
       "      <td>7.879666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.771683</td>\n",
       "      <td>0.521954</td>\n",
       "      <td>0.432056</td>\n",
       "      <td>1.286780</td>\n",
       "      <td>0.714961</td>\n",
       "      <td>0.618852</td>\n",
       "      <td>0.365928</td>\n",
       "      <td>0.276620</td>\n",
       "      <td>0.263781</td>\n",
       "      <td>8.381218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.015014</td>\n",
       "      <td>0.018181</td>\n",
       "      <td>0.027632</td>\n",
       "      <td>0.013632</td>\n",
       "      <td>0.019648</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>0.006759</td>\n",
       "      <td>0.011345</td>\n",
       "      <td>0.051908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.051858</td>\n",
       "      <td>0.066700</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>0.112203</td>\n",
       "      <td>0.148888</td>\n",
       "      <td>0.140199</td>\n",
       "      <td>0.021935</td>\n",
       "      <td>0.023864</td>\n",
       "      <td>0.032403</td>\n",
       "      <td>0.792914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.417748</td>\n",
       "      <td>0.472710</td>\n",
       "      <td>0.398896</td>\n",
       "      <td>0.676724</td>\n",
       "      <td>0.808277</td>\n",
       "      <td>0.671380</td>\n",
       "      <td>0.162565</td>\n",
       "      <td>0.156868</td>\n",
       "      <td>0.135418</td>\n",
       "      <td>3.851823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.389058</td>\n",
       "      <td>1.026513</td>\n",
       "      <td>0.811101</td>\n",
       "      <td>2.241535</td>\n",
       "      <td>1.456542</td>\n",
       "      <td>1.185756</td>\n",
       "      <td>0.584636</td>\n",
       "      <td>0.472082</td>\n",
       "      <td>0.402812</td>\n",
       "      <td>13.706088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.984992</td>\n",
       "      <td>2.311382</td>\n",
       "      <td>2.350887</td>\n",
       "      <td>6.535638</td>\n",
       "      <td>3.602431</td>\n",
       "      <td>3.410963</td>\n",
       "      <td>2.287889</td>\n",
       "      <td>1.855915</td>\n",
       "      <td>2.356723</td>\n",
       "      <td>48.681795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f_body_acc_mean()_X  f_body_acc_mean()_Y  f_body_acc_mean()_Z  \\\n",
       "count         12637.000000         12637.000000         12637.000000   \n",
       "mean              0.754216             0.578450             0.476064   \n",
       "std               0.771683             0.521954             0.432056   \n",
       "min               0.015014             0.018181             0.027632   \n",
       "25%               0.051858             0.066700             0.068472   \n",
       "50%               0.417748             0.472710             0.398896   \n",
       "75%               1.389058             1.026513             0.811101   \n",
       "max               3.984992             2.311382             2.350887   \n",
       "\n",
       "       f_body_acc_std()_X  f_body_acc_std()_Y  f_body_acc_std()_Z  \\\n",
       "count        12637.000000        12637.000000        12637.000000   \n",
       "mean             1.256014            0.857476            0.729452   \n",
       "std              1.286780            0.714961            0.618852   \n",
       "min              0.013632            0.019648            0.027300   \n",
       "25%              0.112203            0.148888            0.140199   \n",
       "50%              0.676724            0.808277            0.671380   \n",
       "75%              2.241535            1.456542            1.185756   \n",
       "max              6.535638            3.602431            3.410963   \n",
       "\n",
       "       f_body_acc_mad()_X  f_body_acc_mad()_Y  f_body_acc_mad()_Z  \\\n",
       "count        12637.000000        12637.000000        12637.000000   \n",
       "mean             0.334269            0.268586            0.245777   \n",
       "std              0.365928            0.276620            0.263781   \n",
       "min              0.006298            0.006759            0.011345   \n",
       "25%              0.021935            0.023864            0.032403   \n",
       "50%              0.162565            0.156868            0.135418   \n",
       "75%              0.584636            0.472082            0.402812   \n",
       "max              2.287889            1.855915            2.356723   \n",
       "\n",
       "       f_body_acc_max()_X  \n",
       "count        12637.000000  \n",
       "mean             7.879666  \n",
       "std              8.381218  \n",
       "min              0.051908  \n",
       "25%              0.792914  \n",
       "50%              3.851823  \n",
       "75%             13.706088  \n",
       "max             48.681795  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Number of windows per user and per each activity:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "      <th>Activity 7</th>\n",
       "      <th>Activity 8</th>\n",
       "      <th>Activity 9</th>\n",
       "      <th>Activity 10</th>\n",
       "      <th>Activity 11</th>\n",
       "      <th>Activity 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User 1</th>\n",
       "      <td>108</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>52</td>\n",
       "      <td>60</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 2</th>\n",
       "      <td>65</td>\n",
       "      <td>57</td>\n",
       "      <td>55</td>\n",
       "      <td>52</td>\n",
       "      <td>60</td>\n",
       "      <td>55</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 3</th>\n",
       "      <td>64</td>\n",
       "      <td>69</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 4</th>\n",
       "      <td>65</td>\n",
       "      <td>58</td>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>61</td>\n",
       "      <td>58</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 5</th>\n",
       "      <td>62</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>50</td>\n",
       "      <td>61</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 6</th>\n",
       "      <td>62</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>61</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 7</th>\n",
       "      <td>63</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>53</td>\n",
       "      <td>60</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 8</th>\n",
       "      <td>55</td>\n",
       "      <td>49</td>\n",
       "      <td>48</td>\n",
       "      <td>52</td>\n",
       "      <td>61</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 9</th>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>53</td>\n",
       "      <td>60</td>\n",
       "      <td>53</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 10</th>\n",
       "      <td>57</td>\n",
       "      <td>54</td>\n",
       "      <td>49</td>\n",
       "      <td>61</td>\n",
       "      <td>51</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 11</th>\n",
       "      <td>66</td>\n",
       "      <td>60</td>\n",
       "      <td>56</td>\n",
       "      <td>59</td>\n",
       "      <td>55</td>\n",
       "      <td>62</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 12</th>\n",
       "      <td>58</td>\n",
       "      <td>61</td>\n",
       "      <td>55</td>\n",
       "      <td>60</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 13</th>\n",
       "      <td>63</td>\n",
       "      <td>62</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>65</td>\n",
       "      <td>68</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 14</th>\n",
       "      <td>67</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>60</td>\n",
       "      <td>66</td>\n",
       "      <td>53</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 15</th>\n",
       "      <td>60</td>\n",
       "      <td>53</td>\n",
       "      <td>50</td>\n",
       "      <td>67</td>\n",
       "      <td>61</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 16</th>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>55</td>\n",
       "      <td>74</td>\n",
       "      <td>84</td>\n",
       "      <td>76</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 17</th>\n",
       "      <td>67</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>70</td>\n",
       "      <td>88</td>\n",
       "      <td>81</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 18</th>\n",
       "      <td>62</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>67</td>\n",
       "      <td>85</td>\n",
       "      <td>76</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 19</th>\n",
       "      <td>56</td>\n",
       "      <td>48</td>\n",
       "      <td>47</td>\n",
       "      <td>78</td>\n",
       "      <td>80</td>\n",
       "      <td>91</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 20</th>\n",
       "      <td>57</td>\n",
       "      <td>59</td>\n",
       "      <td>54</td>\n",
       "      <td>73</td>\n",
       "      <td>83</td>\n",
       "      <td>73</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 21</th>\n",
       "      <td>59</td>\n",
       "      <td>54</td>\n",
       "      <td>55</td>\n",
       "      <td>90</td>\n",
       "      <td>99</td>\n",
       "      <td>96</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 22</th>\n",
       "      <td>52</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>69</td>\n",
       "      <td>71</td>\n",
       "      <td>79</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 23</th>\n",
       "      <td>65</td>\n",
       "      <td>57</td>\n",
       "      <td>62</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "      <td>77</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 24</th>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 25</th>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>66</td>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 26</th>\n",
       "      <td>65</td>\n",
       "      <td>61</td>\n",
       "      <td>60</td>\n",
       "      <td>85</td>\n",
       "      <td>81</td>\n",
       "      <td>82</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 27</th>\n",
       "      <td>63</td>\n",
       "      <td>59</td>\n",
       "      <td>56</td>\n",
       "      <td>79</td>\n",
       "      <td>88</td>\n",
       "      <td>83</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 28</th>\n",
       "      <td>63</td>\n",
       "      <td>59</td>\n",
       "      <td>55</td>\n",
       "      <td>81</td>\n",
       "      <td>85</td>\n",
       "      <td>84</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 29</th>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>56</td>\n",
       "      <td>67</td>\n",
       "      <td>73</td>\n",
       "      <td>75</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 30</th>\n",
       "      <td>71</td>\n",
       "      <td>72</td>\n",
       "      <td>71</td>\n",
       "      <td>72</td>\n",
       "      <td>69</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  \\\n",
       "User 1          108          61          61          52          60   \n",
       "User 2           65          57          55          52          60   \n",
       "User 3           64          69          58          58          69   \n",
       "User 4           65          58          56          55          61   \n",
       "User 5           62          55          56          50          61   \n",
       "User 6           62          60          54          61          63   \n",
       "User 7           63          57          57          53          60   \n",
       "User 8           55          49          48          52          61   \n",
       "User 9           56          56          53          60          53   \n",
       "User 10          57          54          49          61          51   \n",
       "User 11          66          60          56          59          55   \n",
       "User 12          58          61          55          60          67   \n",
       "User 13          63          62          55          55          65   \n",
       "User 14          67          60          54          60          66   \n",
       "User 15          60          53          50          67          61   \n",
       "User 16          57          57          55          74          84   \n",
       "User 17          67          56          56          70          88   \n",
       "User 18          62          65          65          67          85   \n",
       "User 19          56          48          47          78          80   \n",
       "User 20          57          59          54          73          83   \n",
       "User 21          59          54          55          90          99   \n",
       "User 22          52          48          46          69          71   \n",
       "User 23          65          57          62          74          76   \n",
       "User 24          65          65          65          76          76   \n",
       "User 25          80          72          66          70          80   \n",
       "User 26          65          61          60          85          81   \n",
       "User 27          63          59          56          79          88   \n",
       "User 28          63          59          55          81          85   \n",
       "User 29          58          58          56          67          73   \n",
       "User 30          71          72          71          72          69   \n",
       "\n",
       "         Activity 6  Activity 7  Activity 8  Activity 9  Activity 10  \\\n",
       "User 1           56           5           5           6            6   \n",
       "User 2           55           5           5           6            7   \n",
       "User 3           69           5           3           6            6   \n",
       "User 4           58           6           4           7            7   \n",
       "User 5           57           7           4           8            7   \n",
       "User 6           63           6           4           5            5   \n",
       "User 7           56           2           0           7            5   \n",
       "User 8           60           4           6           4            7   \n",
       "User 9           60           4           2           5            5   \n",
       "User 10          65           4           2           5            5   \n",
       "User 11          62           6           4           6            7   \n",
       "User 12          67           6           4           5            6   \n",
       "User 13          68           7           4           6            6   \n",
       "User 14          53           6           5           7            7   \n",
       "User 15          80           4           2           7            5   \n",
       "User 16          76           4           4           6            6   \n",
       "User 17          81           5           5           8            7   \n",
       "User 18          76           8           6           7            7   \n",
       "User 19          91           6           4           5            6   \n",
       "User 20          73           6           5           9            6   \n",
       "User 21          96           5           4           7            6   \n",
       "User 22          79           5           2           4            8   \n",
       "User 23          77           5           5           6            6   \n",
       "User 24          78           5           2           8            6   \n",
       "User 25          80           7           5           6            9   \n",
       "User 26          82           5           5           6            5   \n",
       "User 27          83           6           0           6            5   \n",
       "User 28          84           6           2           6            0   \n",
       "User 29          75           4           4           8            7   \n",
       "User 30          80           3           5           7            6   \n",
       "\n",
       "         Activity 11  Activity 12  \n",
       "User 1             9            6  \n",
       "User 2            10            5  \n",
       "User 3             7            5  \n",
       "User 4            10            5  \n",
       "User 5            11            5  \n",
       "User 6             9            7  \n",
       "User 7             6            5  \n",
       "User 8             6            3  \n",
       "User 9             7            5  \n",
       "User 10            6            2  \n",
       "User 11            6            5  \n",
       "User 12            7            7  \n",
       "User 13            6            7  \n",
       "User 14           10            8  \n",
       "User 15            7            6  \n",
       "User 16            7            4  \n",
       "User 17            8            6  \n",
       "User 18            8            6  \n",
       "User 19            9            4  \n",
       "User 20           12            5  \n",
       "User 21           10            6  \n",
       "User 22            4            4  \n",
       "User 23            8            6  \n",
       "User 24           12            8  \n",
       "User 25            7            8  \n",
       "User 26            6            7  \n",
       "User 27            5            4  \n",
       "User 28            0            5  \n",
       "User 29            6            5  \n",
       "User 30            6            4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Statistics of table above:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "      <th>Activity 7</th>\n",
       "      <th>Activity 8</th>\n",
       "      <th>Activity 9</th>\n",
       "      <th>Activity 10</th>\n",
       "      <th>Activity 11</th>\n",
       "      <th>Activity 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>63.700000</td>\n",
       "      <td>58.733333</td>\n",
       "      <td>56.200000</td>\n",
       "      <td>66.00000</td>\n",
       "      <td>71.033333</td>\n",
       "      <td>71.333333</td>\n",
       "      <td>5.233333</td>\n",
       "      <td>3.733333</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>6.033333</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>5.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.990168</td>\n",
       "      <td>5.906941</td>\n",
       "      <td>5.647093</td>\n",
       "      <td>10.76072</td>\n",
       "      <td>12.141361</td>\n",
       "      <td>11.544019</td>\n",
       "      <td>1.278019</td>\n",
       "      <td>1.574218</td>\n",
       "      <td>1.207734</td>\n",
       "      <td>1.496740</td>\n",
       "      <td>2.487902</td>\n",
       "      <td>1.454679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>58.25000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>60.500000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>63.000000</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>67.00000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>65.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>57.750000</td>\n",
       "      <td>73.75000</td>\n",
       "      <td>80.750000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>108.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>90.00000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  Activity 6  \\\n",
       "count   30.000000   30.000000   30.000000    30.00000   30.000000   30.000000   \n",
       "mean    63.700000   58.733333   56.200000    66.00000   71.033333   71.333333   \n",
       "std      9.990168    5.906941    5.647093    10.76072   12.141361   11.544019   \n",
       "min     52.000000   48.000000   46.000000    50.00000   51.000000   53.000000   \n",
       "25%     58.000000   56.000000   54.000000    58.25000   61.000000   60.500000   \n",
       "50%     63.000000   58.500000   55.500000    67.00000   69.000000   74.000000   \n",
       "75%     65.000000   61.000000   57.750000    73.75000   80.750000   80.000000   \n",
       "max    108.000000   72.000000   71.000000    90.00000   99.000000   96.000000   \n",
       "\n",
       "       Activity 7  Activity 8  Activity 9  Activity 10  Activity 11  \\\n",
       "count   30.000000   30.000000   30.000000    30.000000    30.000000   \n",
       "mean     5.233333    3.733333    6.300000     6.033333     7.500000   \n",
       "std      1.278019    1.574218    1.207734     1.496740     2.487902   \n",
       "min      2.000000    0.000000    4.000000     0.000000     0.000000   \n",
       "25%      4.250000    2.250000    6.000000     5.250000     6.000000   \n",
       "50%      5.000000    4.000000    6.000000     6.000000     7.000000   \n",
       "75%      6.000000    5.000000    7.000000     7.000000     9.000000   \n",
       "max      8.000000    6.000000    9.000000     9.000000    12.000000   \n",
       "\n",
       "       Activity 12  \n",
       "count    30.000000  \n",
       "mean      5.433333  \n",
       "std       1.454679  \n",
       "min       2.000000  \n",
       "25%       5.000000  \n",
       "50%       5.000000  \n",
       "75%       6.000000  \n",
       "max       8.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "_____ The weights of each activity _____\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "      <th>Activity 7</th>\n",
       "      <th>Activity 8</th>\n",
       "      <th>Activity 9</th>\n",
       "      <th>Activity 10</th>\n",
       "      <th>Activity 11</th>\n",
       "      <th>Activity 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Weights</th>\n",
       "      <td>0.151223</td>\n",
       "      <td>0.139432</td>\n",
       "      <td>0.133418</td>\n",
       "      <td>0.156683</td>\n",
       "      <td>0.168632</td>\n",
       "      <td>0.169344</td>\n",
       "      <td>0.012424</td>\n",
       "      <td>0.008863</td>\n",
       "      <td>0.014956</td>\n",
       "      <td>0.014323</td>\n",
       "      <td>0.017805</td>\n",
       "      <td>0.012899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  \\\n",
       "Weights    0.151223    0.139432    0.133418    0.156683    0.168632   \n",
       "\n",
       "         Activity 6  Activity 7  Activity 8  Activity 9  Activity 10  \\\n",
       "Weights    0.169344    0.012424    0.008863    0.014956     0.014323   \n",
       "\n",
       "         Activity 11  Activity 12  \n",
       "Weights     0.017805     0.012899  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# apply the data exploration pipe line to dataset type II\n",
    "data_exploration_pipeline(Dataset_type_II,2,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Data Preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.1 Handling Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "def extract_drop_outliers(Df,threshold,typ):\n",
    "    #Df: pandas dataframe (Dataset type I or Dataset type II)\n",
    "    # Threshold: integer : if the number of features detected as ouliers in row exceeds the threshold \n",
    "    #                      therow will be considered as \"outlier row\"\n",
    "    \n",
    "    max_range=len(Df[\"activity_Id\"].unique()) # number of unique activities in Df\n",
    "    \n",
    "    columns=Df.columns # column names of the dataset\n",
    "    \n",
    "    outliers={} # dictionary will contain number of outliers per row . keys are rows' indexes\n",
    "    for i in range(1,max_range+1):# iterate throw each activity type in the dataset\n",
    "        \n",
    "        Df_A=Df[Df['activity_Id']==i] # select rows related to this activity\n",
    "        \n",
    "        for column in columns[:-2]:# iterate throw features columns only in Df_A\n",
    "            \n",
    "            q1= Df_A[column].describe()['25%'] # the value of the first quartile of a column in Df_A\n",
    "            \n",
    "            q3= Df_A[column].describe()['75%'] # the value of the third quartile of a column in Df_A\n",
    "            \n",
    "            low_threshold=q1-1.5*(q3-q1) # define low threshold to detect bottom outliers of a column\n",
    "            high_threshold=q3+1.5*(q3-q1) # define high threshold to detect top outliers of a column\n",
    "            \n",
    "            for e in Df_A.index :# iterate throw Df_A indexes\n",
    "                \n",
    "                if (Df[column].iloc[e]>high_threshold or Df[column].iloc[e]<low_threshold) :# if value is an outlier\n",
    "                    \n",
    "                    if e in outliers.keys(): # if the row index is alread exist in outliers dictionary\n",
    "                        outliers[e]=outliers[e]+1 # increse the number of ouliers for this row\n",
    "                    else:# if the row index does not exist yet in  outliers dic keys\n",
    "                        outliers[e]=1 # add the key with outlier number =1\n",
    "    \n",
    "    indexs=np.array(sorted(outliers.keys())) # rows indexes contain outlier values sorted from low to high\n",
    "    values=np.array([outliers[indexs[i]] for i in range(len(indexs))]) # number of outliers related to each row\n",
    "\n",
    "    indexs_droped=indexs[values>threshold]# store indexes having number of outliers exceeding the threshold in a list\n",
    "    \n",
    "    # Build outliers dataframe using row's indexes\n",
    "    outliers_data=np.array([list(Df.iloc[indexs_droped[i]]) for i in range(len(indexs_droped))])\n",
    "    outliers_Df= pd.DataFrame(data=outliers_data,columns= columns)\n",
    "    \n",
    "    # generate the clean dataframe by droping outliers from the original dataframe\n",
    "    clean_Df=Df.drop(indexs_droped,0,)\n",
    "    \n",
    "    # adapting the name of the dataset switch the case\n",
    "    if typ==1:\n",
    "        dataset_name='Dataset type I'\n",
    "    if typ==2:\n",
    "        dataset_name=\"Dataset type II\"\n",
    "    \n",
    "    #### report\n",
    "    print(\"\")\n",
    "    print(\"_______________________________ Original Data Frame info...____________________________________\")\n",
    "    print('Number of rows in the original dataframe '+dataset_name+':',len(Df) ) # original dataset lenght\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    visualize_column(Df,'activity_Id') # activity distribution of the original dataset\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"________________________________ Outliers info...________________________________________________\")\n",
    "    print(\"A row is considered as outlier if the number of its outliers exceeds: \"+str(threshold)) # threshold info\n",
    "    print('Number of rows droped :',len(indexs_droped) ) # number of rows considered as outliers\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    data_exploration_pipeline(outliers_Df,typ,True) # Apply the data exploration pipeline to outliers dataframe\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print (\"________________________________ Cleaned+\" +dataset_name+\" Dataframe info...________________________________________\")\n",
    "    print ('Number of rows in the clean dataframe '+dataset_name+':',len(clean_Df)) # clean dataframe info\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    data_exploration_pipeline(clean_Df,typ,False)# apply the data exploration pipeline to the clean dataframe\n",
    "    return clean_Df # return the clean dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "_______________________________ Original Data Frame info...____________________________________\n",
      "Number of rows in the original dataframe Dataset type I: 10399\n",
      "\n",
      "\n",
      "_____ The weights of each activity _____\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\AppData\\Local\\Temp\\ipykernel_4080\\2017075652.py:44: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  clean_Df=Df.drop(indexs_droped,0,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Weights</th>\n",
       "      <td>0.165401</td>\n",
       "      <td>0.148283</td>\n",
       "      <td>0.135205</td>\n",
       "      <td>0.172805</td>\n",
       "      <td>0.190114</td>\n",
       "      <td>0.188191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  \\\n",
       "Weights    0.165401    0.148283    0.135205    0.172805    0.190114   \n",
       "\n",
       "         Activity 6  \n",
       "Weights    0.188191  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAHFCAYAAAAT5Oa6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABT3klEQVR4nO3dd1QU1/8+8GelLKCwCggLioC9gAqaKJh8BAuKYk/UYLAGE7uCKWiiYBKNJpZEo2kIFiwpdhMUe1RsKCqoWAKWBMSCIBZEuL8//DFfV0BYXOo8r3P2HGbmzp333MXw5M7MrkIIIUBEREQkY9XKuwAiIiKi8sZARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEVUZ4eDgUCgWMjIxw9erVfNs9PDzg5ORUDpUB+/btg0KhwO+//14ux9dWUlISevbsCXNzcygUCkyePLnQtg4ODlAoFFAoFKhWrRpUKhWaNWuGoUOHYufOna9Ux9KlSxEeHv5KfZQVBwcHDB8+vET7rlmzBosWLdJpPVXNy8ZIoVAgODhY6z7z/puRlJRUrONQ1aZf3gUQ6VpWVhY+/fRTrFq1qrxLqbSmTJmCo0ePYvny5VCr1bCxsXlp+w4dOuCbb74BAGRmZiIhIQHr1q1Dt27dMGDAAKxduxYGBgZa17F06VJYWlqWOGiUpY0bN8LMzKxE+65ZswZxcXEvDZ5y97Ixio6ORt26dbXus2fPnoiOjtb4/eZ7IV8MRFTldO/eHWvWrMHUqVPRqlWr8i6nTD169AhGRkZQKBSv1E9cXBxef/119O3bt1jta9asifbt20vLXbp0wbhx4xAcHIyQkBB8+umnmDt37ivVVNG5uLiUdwllLjs7GwqFAvr65fun5PnfPW3Url0btWvX1nE1VFnxkhlVOR999BEsLCzw8ccfv7RdUlISFApFgZdkXpyCDw4OhkKhwJkzZ/D2229DpVLB3NwcAQEBePr0KRISEtC9e3eYmprCwcEB8+bNK/CYjx8/RkBAANRqNYyNjdGxY0ecOnUqX7sTJ06gd+/eMDc3h5GREVxcXPDrr79qtMmb7t+5cydGjhyJ2rVrw8TEBFlZWYWe87Vr1/Duu+/CysoKSqUSzZo1w/z585Gbmwvg/y7tXb58GX/99Zd0Kez5SwraCA4ORosWLbBkyRI8fvxYWh8SEoJ27drB3NwcZmZmcHV1RWhoKJ7/rmkHBwfEx8dj//79Uh0ODg7SOAYGBqJ169bSe+Hm5obNmzcXq668y6d///032rdvD2NjY9SpUwefffYZcnJyNNrevXsXY8eORZ06dWBoaIj69etj+vTp+cb5xUtmeWO5du1aTJ8+Hba2tjAzM0OXLl2QkJCgUcv27dtx9epV6TyfD7TLli1Dq1atUKNGDZiamqJp06aYNm3aS88v73d73rx5+PLLL1GvXj0YGRmhbdu22L17d772ly5dgq+vr8bvxffff6/RJu98Vq1ahcDAQNSpUwdKpRKXL18utI7ivM951qxZAzc3N9SoUQM1atRA69atERoaWqwxev7f6+nTp6FQKKR9n5f3O71lyxYA+S+ZFXYcIQQaNWqEbt265eszMzMTKpUK48aNK3QcqHJgIKIqx9TUFJ9++il27NiBPXv26LTvgQMHolWrVvjjjz/g7++PhQsXYsqUKejbty969uyJjRs3olOnTvj444+xYcOGfPtPmzYN//zzD3755Rf88ssv+O+//+Dh4YF//vlHarN371506NAB9+7dww8//IDNmzejdevWGDRoUIHhbeTIkTAwMMCqVavw+++/F3pp6tatW3B3d8fOnTvx+eefY8uWLejSpQumTp2K8ePHAwBcXV0RHR0NtVqNDh06IDo6Ot8lBW316tULDx8+xIkTJ6R1SUlJeP/99/Hrr79iw4YN6N+/PyZMmIDPP/9carNx40bUr18fLi4uUh0bN24E8Oyy6N27dzF16lRs2rQJa9euxRtvvIH+/ftj5cqVxaorJSUFgwcPxpAhQ7B582a89dZb+OKLLzBp0iSpzePHj+Hp6YmVK1ciICAA27dvx7vvvot58+ahf//+xTrOtGnTcPXqVfzyyy/46aefcOnSJfTq1UsKXkuXLkWHDh2gVqul84yOjgYArFu3DmPHjkXHjh2xceNGbNq0CVOmTMGDBw+KdewlS5YgMjISixYtwurVq1GtWjV4e3tL/QPAuXPn8NprryEuLg7z58/Htm3b0LNnT0ycOBEhISH5+gwKCsK1a9fwww8/YOvWrbCysir0+MV5nwFgxowZGDJkCGxtbREeHo6NGzdi2LBh0r2ALxujF7Vq1QouLi4ICwvLty08PBxWVlbo0aNHgfsWdhyFQoEJEyYgKioKly5d0thn5cqVyMjIYCCqCgRRFREWFiYAiOPHj4usrCxRv3590bZtW5GbmyuEEKJjx46iRYsWUvvExEQBQISFheXrC4CYOXOmtDxz5kwBQMyfP1+jXevWrQUAsWHDBmlddna2qF27tujfv7+0bu/evQKAcHV1leoRQoikpCRhYGAg3nvvPWld06ZNhYuLi8jOztY4lo+Pj7CxsRE5OTka5zt06NBijc8nn3wiAIijR49qrB8zZoxQKBQiISFBWmdvby969uxZrH6Larts2TIBQKxfv77A7Tk5OSI7O1vMmjVLWFhYaIxPixYtRMeOHYus4enTpyI7O1uMGjVKuLi4FNm+Y8eOAoDYvHmzxnp/f39RrVo1cfXqVSGEED/88IMAIH799VeNdnPnzhUAxM6dO6V19vb2YtiwYdJy3nveo0cPjX1//fVXAUBER0dL63r27Cns7e3z1Tl+/HhRs2bNIs/nRXm/27a2tuLRo0fS+oyMDGFubi66dOkirevWrZuoW7euSE9Pz3dsIyMjcffuXY3z+d///qd1PUIU/j7/888/Qk9PTwwZMuSl+xc2RkLk//f63XffCQAav9N3794VSqVSBAYGSuvy/g0lJiYWeZyMjAxhamoqJk2apLG+efPmwtPT86W1U+XAGSKqkgwNDfHFF1/gxIkT+S41vQofHx+N5WbNmkGhUMDb21tap6+vj4YNGxb4pJuvr6/GVL+9vT3c3d2xd+9eAMDly5dx4cIFDBkyBADw9OlT6dWjRw8kJydrXG4BgAEDBhSr9j179qB58+Z4/fXXNdYPHz4cQgidz6blEQVcHtmzZw+6dOkClUoFPT09GBgYYMaMGbhz5w5SU1OL1e9vv/2GDh06oEaNGtDX14eBgQFCQ0Nx/vz5Yu1vamqK3r17a6zz9fVFbm4uDhw4INVZvXp1vPXWWxrt8i6NFXT56UUvHqNly5YAUODvx4tef/113Lt3D++88w42b96M27dvF7nP8/r37w8jIyNp2dTUFL169cKBAweQk5ODx48fY/fu3ejXrx9MTEzy/b49fvwYR44c0eizuL9vQPHe56ioKOTk5Oh0hmXIkCFQKpUaM6pr165FVlYWRowYUaI+TU1NMWLECISHh0szdHv27MG5c+ekGVaq3BiIqMoaPHgwXF1dMX36dGRnZ+ukT3Nzc41lQ0NDmJiYaPzRyVv//D0zedRqdYHr7ty5AwC4efMmAGDq1KkwMDDQeI0dOxYA8v1RLO7lrDt37hTY1tbWVtpeGvL+8Ocd59ixY/Dy8gIA/Pzzzzh06BCOHz+O6dOnA3h2Y3hRNmzYgIEDB6JOnTpYvXo1oqOjcfz4cYwcObLAcS+ItbV1vnV570/eWNy5cwdqtTrfTepWVlbQ19cv1phZWFhoLCuVSgDFO08/Pz8sX74cV69exYABA2BlZYV27dohKiqqyH2fP58X1z158gSZmZm4c+cOnj59isWLF+f7fcu7rFTS37fivs+3bt0CgBI9JVYYc3Nz9O7dGytXrpQuTYaHh+P1119HixYtStzvhAkTcP/+fURERAB4dkmybt266NOnj07qpvLFp8yoylIoFJg7dy66du2Kn376Kd/2vBDz4s2xpRUMgGf3rRS0Lu+PpqWlJYBn92kUdo9KkyZNNJaL+0SZhYUFkpOT863/77//NI6tS0IIbN26FdWrV0fbtm0BPLsvxsDAANu2bdMIkps2bSp2v6tXr4ajoyPWr1+vcf4vu6H8RXnh83l570/e+2FhYYGjR49CCKFxnNTUVDx9+rRUxuxFI0aMwIgRI/DgwQMcOHAAM2fOhI+PDy5evAh7e/uX7lvY75uhoSFq1KgBAwMD6Onpwc/Pr9AZGkdHR43l4v6+Ffd9znvK68aNG7CzsytW38UxYsQI/Pbbb4iKikK9evVw/PhxLFu27JX6bNiwIby9vfH999/D29sbW7ZsQUhICPT09HRUNZUnzhBRldalSxd07doVs2bNQmZmpsY2a2trGBkZ4cyZMxrri/ukUkmsXbtW4xLS1atXcfjwYXh4eAB4FnYaNWqE06dPo23btgW+TE1NS3Tszp0749y5czh58qTG+pUrV0KhUMDT07PE51WYkJAQnDt3DpMmTZL+KOY9pv38H5FHjx4V+LlRSqWywJkUhUIBQ0NDjT/OKSkpWr139+/fl542yrNmzRpUq1YN//vf/wA8G7PMzMx8f8Tzbtzu3LlzsY/3MoWd5/OqV68Ob29vTJ8+HU+ePEF8fHyR/W7YsEFjxuz+/fvYunUr3nzzTejp6cHExASenp44deoUWrZsWeDv24szXMVV3PfZy8sLenp6RYaV4ozRi/3WqVMHYWFhCAsLg5GREd55550i9yvqOJMmTcKZM2cwbNgw6Onpwd/fv9g1UcXGGSKq8ubOnYs2bdogNTVVY7pcoVDg3XffxfLly9GgQQO0atUKx44dw5o1a0qtltTUVPTr1w/+/v5IT0/HzJkzYWRkhKCgIKnNjz/+CG9vb3Tr1g3Dhw9HnTp1cPfuXZw/fx4nT57Eb7/9VqJjT5kyBStXrkTPnj0xa9Ys2NvbY/v27Vi6dCnGjBmDxo0bl/i87t27J91r8uDBA+mDGf/++28MHDhQ42mlnj17YsGCBfD19cXo0aNx584dfPPNN9KlpOc5Oztj3bp1WL9+PerXrw8jIyM4OzvDx8cHGzZswNixY/HWW2/h+vXr+Pzzz2FjY5PvKaDCWFhYYMyYMbh27RoaN26MP//8Ez///DPGjBmDevXqAQCGDh2K77//HsOGDUNSUhKcnZ1x8OBBzJ49Gz169ECXLl1KPGYvnueGDRuwbNkytGnTBtWqVUPbtm3h7+8PY2NjdOjQATY2NkhJScGcOXOgUqnw2muvFdmvnp4eunbtioCAAOTm5mLu3LnIyMjQeD++/fZbvPHGG3jzzTcxZswYODg44P79+7h8+TK2bt1a4nvLivs+Ozg4YNq0afj888/x6NEjvPPOO1CpVDh37hxu374t1VrYGL3s3IcOHYoFCxbAzMwM/fv3h0qlKrLuoo7TtWtXNG/eHHv37pU+woKqiHK9pZtIh55/yuxFvr6+AoDGU2ZCCJGeni7ee+89YW1tLapXry569eolkpKSCn3K7NatWxr7Dxs2TFSvXj3f8V58oi3vCZ1Vq1aJiRMnitq1awulUinefPNNceLEiXz7nz59WgwcOFBYWVkJAwMDoVarRadOncQPP/xQrPMtzNWrV4Wvr6+wsLAQBgYGokmTJuLrr7+WnlzLo+1TZgAEAKFQKESNGjVEkyZNhJ+fn9ixY0eB+yxfvlw0adJEKJVKUb9+fTFnzhwRGhqa74mfpKQk4eXlJUxNTQUAjad/vvrqK+Hg4CCUSqVo1qyZ+Pnnn6X3qSh578++fftE27ZthVKpFDY2NmLatGn5nu67c+eO+OCDD4SNjY3Q19cX9vb2IigoSDx+/DjfOBT0lNlvv/2m0a6gpxvv3r0r3nrrLVGzZk2hUCikc1ixYoXw9PQU1tbWwtDQUNja2oqBAweKM2fOvPT88o4xd+5cERISIurWrSsMDQ2Fi4tLge9JYmKiGDlypKhTp44wMDAQtWvXFu7u7uKLL74o8nxeprjvsxBCrFy5Urz22mvCyMhI1KhRQ7i4uBRrjITI/5RZnosXL0q/m1FRUfm2F/SU2cuOkyc4OFgAEEeOHCn2WFDFpxCigEdAiIiqMA8PD9y+fRtxcXHlXUqpSEpKgqOjI77++mtMnTq1vMupctq2bQuFQoHjx4+XdymkQ7xkRkREVISMjAzExcVh27ZtiImJkT4klKoOBiIiIqIinDx5Ep6enrCwsMDMmTOL/T1/VHnwkhkRERHJHh+7JyIiItljICIiIiLZYyAiIiIi2eNN1cWUm5uL//77D6ampsX+6HoiIiIqX0II3L9/H7a2tqhWrfB5IAaiYvrvv/90+j07REREVHauX7/+0i8RZiAqprzvj7p+/TrMzMzKuRoiIiIqjoyMDNjZ2RX5PZAMRMWUd5nMzMyMgYiIiKiSKep2F95UTURERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREsleugWjOnDl47bXXYGpqCisrK/Tt2xcJCQkabYQQCA4Ohq2tLYyNjeHh4YH4+HiNNllZWZgwYQIsLS1RvXp19O7dGzdu3NBok5aWBj8/P6hUKqhUKvj5+eHevXulfYpERERUCZRrINq/fz/GjRuHI0eOICoqCk+fPoWXlxcePHggtZk3bx4WLFiAJUuW4Pjx41Cr1ejatSvu378vtZk8eTI2btyIdevW4eDBg8jMzISPjw9ycnKkNr6+voiNjUVkZCQiIyMRGxsLPz+/Mj1fIiIiqqBEBZKamioAiP379wshhMjNzRVqtVp89dVXUpvHjx8LlUolfvjhByGEEPfu3RMGBgZi3bp1Upt///1XVKtWTURGRgohhDh37pwAII4cOSK1iY6OFgDEhQsXilVbenq6ACDS09Nf+TyJiIiobBT373eFuocoPT0dAGBubg4ASExMREpKCry8vKQ2SqUSHTt2xOHDhwEAMTExyM7O1mhja2sLJycnqU10dDRUKhXatWsntWnfvj1UKpXUhoiIiOSrwnx1hxACAQEBeOONN+Dk5AQASElJAQBYW1trtLW2tsbVq1elNoaGhqhVq1a+Nnn7p6SkwMrKKt8xrayspDYvysrKQlZWlrSckZFRwjMjIiKiiq7CzBCNHz8eZ86cwdq1a/Nte/H7R4QQRX4nyYttCmr/sn7mzJkj3YCtUqn4TfdERERVWIUIRBMmTMCWLVuwd+9e1K1bV1qvVqsBIN8sTmpqqjRrpFar8eTJE6Slpb20zc2bN/Md99atW/lmn/IEBQUhPT1del2/fr3kJ0hEREQVWrkGIiEExo8fjw0bNmDPnj1wdHTU2O7o6Ai1Wo2oqChp3ZMnT7B//364u7sDANq0aQMDAwONNsnJyYiLi5PauLm5IT09HceOHZPaHD16FOnp6VKbFymVSumb7fkN90RERFVbud5DNG7cOKxZswabN2+GqampNBOkUqlgbGwMhUKByZMnY/bs2WjUqBEaNWqE2bNnw8TEBL6+vlLbUaNGITAwEBYWFjA3N8fUqVPh7OyMLl26AACaNWuG7t27w9/fHz/++CMAYPTo0fDx8UGTJk3K5+SJiIiowijXQLRs2TIAgIeHh8b6sLAwDB8+HADw0Ucf4dGjRxg7dizS0tLQrl077Ny5E6amplL7hQsXQl9fHwMHDsSjR4/QuXNnhIeHQ09PT2oTERGBiRMnSk+j9e7dG0uWLCndEyQikjGHT7aXdwnlIumrnuVdApWAQgghyruIyiAjIwMqlQrp6em8fEZEVAwMRFQRFPfvd4W4qZqIiIioPFWYzyEiIiIizqyVF84QERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkezpl3cBRESVgcMn28u7hHKR9FXP8i6BqExwhoiIiIhkj4GIiIiIZI+BiIiIiGSvXAPRgQMH0KtXL9ja2kKhUGDTpk0a2xUKRYGvr7/+Wmrj4eGRb/vgwYM1+klLS4Ofnx9UKhVUKhX8/Pxw7969MjhDIiIiqgzKNRA9ePAArVq1wpIlSwrcnpycrPFavnw5FAoFBgwYoNHO399fo92PP/6osd3X1xexsbGIjIxEZGQkYmNj4efnV2rnRURERJVLuT5l5u3tDW9v70K3q9VqjeXNmzfD09MT9evX11hvYmKSr22e8+fPIzIyEkeOHEG7du0AAD///DPc3NyQkJCAJk2avOJZEBERUWVXae4hunnzJrZv345Ro0bl2xYREQFLS0u0aNECU6dOxf3796Vt0dHRUKlUUhgCgPbt20OlUuHw4cOFHi8rKwsZGRkaLyIiIqqaKs3nEK1YsQKmpqbo37+/xvohQ4bA0dERarUacXFxCAoKwunTpxEVFQUASElJgZWVVb7+rKyskJKSUujx5syZg5CQEN2eBBEREVVIlSYQLV++HEOGDIGRkZHGen9/f+lnJycnNGrUCG3btsXJkyfh6uoK4NnN2S8SQhS4Pk9QUBACAgKk5YyMDNjZ2b3qaRAREVEFVCkC0d9//42EhASsX7++yLaurq4wMDDApUuX4OrqCrVajZs3b+Zrd+vWLVhbWxfaj1KphFKpfKW6iYiIqHKoFPcQhYaGok2bNmjVqlWRbePj45GdnQ0bGxsAgJubG9LT03Hs2DGpzdGjR5Geng53d/dSq5mIiIgqj3KdIcrMzMTly5el5cTERMTGxsLc3Bz16tUD8OxS1W+//Yb58+fn2//KlSuIiIhAjx49YGlpiXPnziEwMBAuLi7o0KEDAKBZs2bo3r07/P39pcfxR48eDR8fHz5hRkRERADKORCdOHECnp6e0nLePTvDhg1DeHg4AGDdunUQQuCdd97Jt7+hoSF2796Nb7/9FpmZmbCzs0PPnj0xc+ZM6OnpSe0iIiIwceJEeHl5AQB69+5d6GcflQe5fmkkwC+OJCKiiqFcA5GHhweEEC9tM3r0aIwePbrAbXZ2dti/f3+RxzE3N8fq1atLVCMRERFVfZXiHiIiIiKi0sRARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyp1/eBRCVlMMn28u7hHKR9FXP8i6BiKjK4QwRERERyR4DEREREcleuQaiAwcOoFevXrC1tYVCocCmTZs0tg8fPhwKhULj1b59e402WVlZmDBhAiwtLVG9enX07t0bN27c0GiTlpYGPz8/qFQqqFQq+Pn54d69e6V8dkRERFRZlGsgevDgAVq1aoUlS5YU2qZ79+5ITk6WXn/++afG9smTJ2Pjxo1Yt24dDh48iMzMTPj4+CAnJ0dq4+vri9jYWERGRiIyMhKxsbHw8/MrtfMiIiKiyqVcb6r29vaGt7f3S9solUqo1eoCt6WnpyM0NBSrVq1Cly5dAACrV6+GnZ0ddu3ahW7duuH8+fOIjIzEkSNH0K5dOwDAzz//DDc3NyQkJKBJkya6PSkiIiKqdCr8PUT79u2DlZUVGjduDH9/f6SmpkrbYmJikJ2dDS8vL2mdra0tnJyccPjwYQBAdHQ0VCqVFIYAoH379lCpVFIbIiIikrcK/di9t7c33n77bdjb2yMxMRGfffYZOnXqhJiYGCiVSqSkpMDQ0BC1atXS2M/a2hopKSkAgJSUFFhZWeXr28rKSmpTkKysLGRlZUnLGRkZOjorIiIiqmgqdCAaNGiQ9LOTkxPatm0Le3t7bN++Hf379y90PyEEFAqFtPz8z4W1edGcOXMQEhJSwsqJiIioMqnwl8yeZ2NjA3t7e1y6dAkAoFar8eTJE6SlpWm0S01NhbW1tdTm5s2b+fq6deuW1KYgQUFBSE9Pl17Xr1/X4ZkQERFRRVKpAtGdO3dw/fp12NjYAADatGkDAwMDREVFSW2Sk5MRFxcHd3d3AICbmxvS09Nx7Ngxqc3Ro0eRnp4utSmIUqmEmZmZxouIiIiqpnK9ZJaZmYnLly9Ly4mJiYiNjYW5uTnMzc0RHByMAQMGwMbGBklJSZg2bRosLS3Rr18/AIBKpcKoUaMQGBgICwsLmJubY+rUqXB2dpaeOmvWrBm6d+8Of39//PjjjwCA0aNHw8fHh0+YEREREYASzBBFRkbi4MGD0vL333+P1q1bw9fXN9+lq6KcOHECLi4ucHFxAQAEBATAxcUFM2bMgJ6eHs6ePYs+ffqgcePGGDZsGBo3bozo6GiYmppKfSxcuBB9+/bFwIED0aFDB5iYmGDr1q3Q09OT2kRERMDZ2RleXl7w8vJCy5YtsWrVKm1PnYiIiKoorWeIPvzwQ8ydOxcAcPbsWQQGBiIgIAB79uxBQEAAwsLCit2Xh4cHhBCFbt+xY0eRfRgZGWHx4sVYvHhxoW3Mzc2xevXqYtdFRERE8qJ1IEpMTETz5s0BAH/88Qd8fHwwe/ZsnDx5Ej169NB5gURERESlTetLZoaGhnj48CEAYNeuXdKHIpqbm/OzeoiIiKhS0nqG6I033kBAQAA6dOiAY8eOYf369QCAixcvom7dujovkIiIiKi0aT1DtGTJEujr6+P333/HsmXLUKdOHQDAX3/9he7du+u8QCIiIqLSpvUMUb169bBt27Z86xcuXKiTgoiIiIjKmtYzRHp6ehpfsJrnzp07Go+6ExEREVUWWgeiwh6Tz8rKgqGh4SsXRERERFTWin3J7LvvvgPw7ItSf/nlF9SoUUPalpOTgwMHDqBp06a6r5CIiIiolBU7EOXdIySEwA8//KBxeczQ0BAODg744YcfdF8hERERUSkrdiBKTEwEAHh6emLDhg2oVatWqRVFREREVJa0fsps7969pVEHEZURh0+2l3cJ5SLpq57lXQIRVWBaB6KcnByEh4dj9+7dSE1NRW5ursb2PXv26Kw4IiIiorKgdSCaNGkSwsPD0bNnTzg5OUGhUJRGXURERERlRutAtG7dOvz666/8IlciIiKqMkr05a4NGzYsjVqIiIiIyoXWgSgwMBDffvttoR/QSERERFTZaH3J7ODBg9i7dy/++usvtGjRAgYGBhrbN2zYoLPiiIiIiMqC1oGoZs2a6NevX2nUQkRERFQutA5EYWFhpVEHERERUbnR+h4iIiIioqqmWDNErq6u2L17N2rVqgUXF5eXfvbQyZMndVYcERERUVkoViDq06cPlEolAKBv376lWQ8RERFRmStWIJo5c2aBPxMRERFVBVrfVJ0nJiYG58+fh0KhQPPmzeHi4qLLuoiIiIjKjNaBKDU1FYMHD8a+fftQs2ZNCCGQnp4OT09PrFu3DrVr1y6NOomIiIhKjdZPmU2YMAEZGRmIj4/H3bt3kZaWhri4OGRkZGDixImlUSMRERFRqdJ6higyMhK7du1Cs2bNpHXNmzfH999/Dy8vL50WR0RERFQWtJ4hys3Nzfd1HQBgYGCA3NxcnRRFREREVJa0DkSdOnXCpEmT8N9//0nr/v33X0yZMgWdO3fWaXFEREREZUHrQLRkyRLcv38fDg4OaNCgARo2bAhHR0fcv38fixcvLo0aiYiIiEqV1vcQ2dnZ4eTJk4iKisKFCxcghEDz5s3RpUuX0qiPiIiIqNSV+HOIunbtiq5du+qyFiIiIqJyUaIvd929ezd8fHykS2Y+Pj7YtWuXrmsjIiIiKhMluoeoe/fuMDU1xaRJkzBx4kSYmZmhR48eWLJkSWnUSERERFSqtA5Ec+bMwcKFC7F27VpMnDgREydOxJo1a7Bw4ULMnj1bq74OHDiAXr16wdbWFgqFAps2bZK2ZWdn4+OPP4azszOqV68OW1tbDB06VOPpNgDw8PCAQqHQeA0ePFijTVpaGvz8/KBSqaBSqeDn54d79+5pe+pERERURWkdiDIyMtC9e/d86728vJCRkaFVXw8ePECrVq0KnFl6+PAhTp48ic8++wwnT57Ehg0bcPHiRfTu3TtfW39/fyQnJ0uvH3/8UWO7r68vYmNjERkZicjISMTGxsLPz0+rWomIiKjq0vqm6t69e2Pjxo348MMPNdZv3rwZvXr10qovb29veHt7F7hNpVIhKipKY93ixYvx+uuv49q1a6hXr5603sTEBGq1usB+zp8/j8jISBw5cgTt2rUDAPz8889wc3NDQkICmjRpolXNREREVPVoHYiaNWuGL7/8Evv27YObmxsA4MiRIzh06BACAwPx3XffSW11/d1m6enpUCgUqFmzpsb6iIgIrF69GtbW1vD29sbMmTNhamoKAIiOjoZKpZLCEAC0b98eKpUKhw8fLjQQZWVlISsrS1rWdvaLiIiIKg+tA1FoaChq1aqFc+fO4dy5c9L6mjVrIjQ0VFpWKBQ6DUSPHz/GJ598Al9fX5iZmUnrhwwZAkdHR6jVasTFxSEoKAinT5+WZpdSUlJgZWWVrz8rKyukpKQUerw5c+YgJCREZ/UTERFRxaV1IEpMTCyNOl4qOzsbgwcPRm5uLpYuXaqxzd/fX/rZyckJjRo1Qtu2bXHy5Em4uroCeBbOXiSEKHB9nqCgIAQEBEjLGRkZsLOze9VTISIiogqoxB/MWFays7MxcOBAJCYmYs+ePRqzQwVxdXWFgYEBLl26BFdXV6jVaty8eTNfu1u3bsHa2rrQfpRKJZRK5SvXT0RERBVfiT6YsazkhaFLly5h165dsLCwKHKf+Ph4ZGdnw8bGBgDg5uaG9PR0HDt2TGpz9OhRpKenw93dvdRqJyIiosqjXGeIMjMzcfnyZWk5MTERsbGxMDc3h62tLd566y2cPHkS27ZtQ05OjnTPj7m5OQwNDXHlyhVERESgR48esLS0xLlz5xAYGAgXFxd06NABwLObwLt37w5/f3/pcfzRo0fDx8eHT5gRERERgHIORCdOnICnp6e0nHfPzrBhwxAcHIwtW7YAAFq3bq2x3969e+Hh4QFDQ0Ps3r0b3377LTIzM2FnZ4eePXti5syZ0NPTk9pHRERg4sSJ8PLyAvDsowP4qdpERESUp1wDkYeHB4QQhW5/2TYAsLOzw/79+4s8jrm5OVavXq11fURERCQPJQ5EDx8+xLVr1/DkyRON9S1btnzlooiIiIjKktaB6NatWxgxYgT++uuvArfn5OS8clFEREREZUnrp8wmT56MtLQ0HDlyBMbGxoiMjMSKFSvQqFEj6Z4fIiIiospE6xmiPXv2YPPmzXjttddQrVo12Nvbo2vXrjAzM8OcOXPQs2fP0qiTiIiIqNRoPUP04MED6aswzM3NcevWLQCAs7MzTp48qdvqiIiIiMqA1oGoSZMmSEhIAPDscfgff/wR//77L3744QfpwxCJiIiIKhOtL5lNnjwZycnJAICZM2eiW7duiIiIgKGhIcLDw3VdHxEREVGp0zoQDRkyRPrZxcUFSUlJuHDhAurVqwdLS0udFkdERERUFrS+ZDZr1iw8fPhQWjYxMYGrqyuqV6+OWbNm6bQ4IiIiorKgdSAKCQlBZmZmvvUPHz5ESEiITooiIiIiKktaByIhBBQKRb71p0+fhrm5uU6KIiIiIipLxb6HqFatWlAoFFAoFGjcuLFGKMrJyUFmZiY++OCDUimSiIiIqDQVOxAtWrQIQgiMHDkSISEhUKlU0jZDQ0M4ODjAzc2tVIokIiIiKk3FDkTDhg0DADg6OsLd3R0GBgalVhQRERFRWdL6sfuOHTtKPz969AjZ2dka283MzF69KiIiIqIypPVN1Q8fPsT48eNhZWWFGjVqoFatWhovIiIiospG60D04YcfYs+ePVi6dCmUSiV++eUXhISEwNbWFitXriyNGomIiIhKldaXzLZu3YqVK1fCw8MDI0eOxJtvvomGDRvC3t4eERERGp9kTURERFQZaD1DdPfuXTg6OgJ4dr/Q3bt3AQBvvPEGDhw4oNvqiIiIiMqA1oGofv36SEpKAgA0b94cv/76K4BnM0c1a9bUZW1EREREZULrQDRixAicPn0aABAUFCTdSzRlyhR8+OGHOi+QiIiIqLRpfQ/RlClTpJ89PT1x4cIFnDhxAg0aNECrVq10WhwRERFRWdA6EL2oXr16qFevni5qISIiIioXWgWi3NxchIeHY8OGDUhKSoJCoYCjoyPeeust+Pn5Ffilr0REREQVXbHvIRJCoHfv3njvvffw77//wtnZGS1atMDVq1cxfPhw9OvXrzTrJCIiIio1xZ4hCg8Px4EDB7B79254enpqbNuzZw/69u2LlStXYujQoTovkoiIiKg0FXuGaO3atZg2bVq+MAQAnTp1wieffIKIiAidFkdERERUFoodiM6cOYPu3bsXut3b21t6HJ+IiIioMil2ILp79y6sra0L3W5tbY20tDSdFEVERERUloodiHJycqCvX/gtR3p6enj69KlOiiIiIiIqS8W+qVoIgeHDh0OpVBa4PSsrS2dFEREREZWlYgeiYcOGFdmGT5gRERFRZVTsQBQWFlaadRARERGVG62/3FWXDhw4gF69esHW1hYKhQKbNm3S2C6EQHBwMGxtbWFsbAwPDw/Ex8drtMnKysKECRNgaWmJ6tWro3fv3rhx44ZGm7S0NPj5+UGlUkGlUsHPzw/37t0r5bMjIiKiyqJcA9GDBw/QqlUrLFmypMDt8+bNw4IFC7BkyRIcP34carUaXbt2xf3796U2kydPxsaNG7Fu3TocPHgQmZmZ8PHxQU5OjtTG19cXsbGxiIyMRGRkJGJjY+Hn51fq50dERESVwyt/ueur8Pb2hre3d4HbhBBYtGgRpk+fjv79+wMAVqxYAWtra6xZswbvv/8+0tPTERoailWrVqFLly4AgNWrV8POzg67du1Ct27dcP78eURGRuLIkSNo164dAODnn3+Gm5sbEhIS0KRJk7I5WSIiIqqwynWG6GUSExORkpICLy8vaZ1SqUTHjh1x+PBhAEBMTAyys7M12tja2sLJyUlqEx0dDZVKJYUhAGjfvj1UKpXUhoiIiOStWIHI1dVV+tDFWbNm4eHDh6VaFACkpKQAQL4Pg7S2tpa2paSkwNDQELVq1XppGysrq3z9W1lZSW0KkpWVhYyMDI0XERERVU3FCkTnz5/HgwcPAAAhISHIzMws1aKep1AoNJaFEPnWvejFNgW1L6qfOXPmSDdhq1Qq2NnZaVk5ERERVRbFuoeodevWGDFiBN544w0IIfDNN9+gRo0aBbadMWOGTgpTq9UAns3w2NjYSOtTU1OlWSO1Wo0nT54gLS1NY5YoNTUV7u7uUpubN2/m6//WrVsv/SqSoKAgBAQESMsZGRkMRURERFVUsWaIwsPDYWFhgW3btkGhUOCvv/7Cxo0b871efGz+VTg6OkKtViMqKkpa9+TJE+zfv18KO23atIGBgYFGm+TkZMTFxUlt3NzckJ6ejmPHjkltjh49ivT0dKlNQZRKJczMzDReREREVDUVa4aoSZMmWLduHQCgWrVq2L17d4H35WgrMzMTly9flpYTExMRGxsLc3Nz1KtXD5MnT8bs2bPRqFEjNGrUCLNnz4aJiQl8fX0BACqVCqNGjUJgYCAsLCxgbm6OqVOnwtnZWXrqrFmzZujevTv8/f3x448/AgBGjx4NHx8fPmFGREREAErw2H1ubq7ODn7ixAl4enpKy3mXqIYNG4bw8HB89NFHePToEcaOHYu0tDS0a9cOO3fuhKmpqbTPwoULoa+vj4EDB+LRo0fo3LkzwsPDoaenJ7WJiIjAxIkTpafRevfuXehnHxEREZH8lOhziK5cuYJFixbh/PnzUCgUaNasGSZNmoQGDRpo1Y+HhweEEIVuVygUCA4ORnBwcKFtjIyMsHjxYixevLjQNubm5li9erVWtREREZF8aP05RDt27EDz5s1x7NgxtGzZEk5OTjh69ChatGihcS8PERERUWWh9QzRJ598gilTpuCrr77Kt/7jjz9G165ddVYcERERUVnQeobo/PnzGDVqVL71I0eOxLlz53RSFBEREVFZ0joQ1a5dG7GxsfnWx8bG6uTJMyIiIqKypvUlM39/f4wePRr//PMP3N3doVAocPDgQcydOxeBgYGlUSMRERFRqdI6EH322WcwNTXF/PnzERQUBODZF6oGBwdj4sSJOi+QiIiIqLRpHYgUCgWmTJmCKVOm4P79+wCg8blARERERJVNiT6HKA+DEBEREVUFWt9UTURERFTVMBARERGR7DEQERERkexpFYiys7Ph6emJixcvllY9RERERGVOq0BkYGCAuLg4KBSK0qqHiIiIqMxpfcls6NChCA0NLY1aiIiIiMqF1o/dP3nyBL/88guioqLQtm1bVK9eXWP7ggULdFYcERERUVnQOhDFxcXB1dUVAPLdS8RLaURERFQZaR2I9u7dWxp1EBEREZWbEj92f/nyZezYsQOPHj0CAAghdFYUERERUVnSOhDduXMHnTt3RuPGjdGjRw8kJycDAN577z1+2z0RERFVSloHoilTpsDAwADXrl2DiYmJtH7QoEGIjIzUaXFEREREZUHre4h27tyJHTt2oG7duhrrGzVqhKtXr+qsMCIiIqKyovUM0YMHDzRmhvLcvn0bSqVSJ0URERERlSWtA9H//vc/rFy5UlpWKBTIzc3F119/DU9PT50WR0RERFQWtL5k9vXXX8PDwwMnTpzAkydP8NFHHyE+Ph53797FoUOHSqNGIiIiolKl9QxR8+bNcebMGbz++uvo2rUrHjx4gP79++PUqVNo0KBBadRIREREVKq0niECALVajZCQEF3XQkRERFQuShSI0tLSEBoaivPnz0OhUKBZs2YYMWIEzM3NdV0fERERUanT+pLZ/v374ejoiO+++w5paWm4e/cuvvvuOzg6OmL//v2lUSMRERFRqdJ6hmjcuHEYOHAgli1bBj09PQBATk4Oxo4di3HjxiEuLk7nRRIRERGVJq1niK5cuYLAwEApDAGAnp4eAgICcOXKFZ0WR0RERFQWtA5Erq6uOH/+fL7158+fR+vWrXVRExEREVGZKtYlszNnzkg/T5w4EZMmTcLly5fRvn17AMCRI0fw/fff46uvviqdKomIiIhKUbECUevWraFQKCCEkNZ99NFH+dr5+vpi0KBBuquOiIiIqAwUKxAlJiaWdh1ERERE5aZY9xDZ29sX+6VrDg4OUCgU+V7jxo0DAAwfPjzftrxLeXmysrIwYcIEWFpaonr16ujduzdu3Lih81qJiIiocirRBzP++++/OHToEFJTU5Gbm6uxbeLEiTopLM/x48eRk5MjLcfFxaFr1654++23pXXdu3dHWFiYtGxoaKjRx+TJk7F161asW7cOFhYWCAwMhI+PD2JiYjSeliMiIiJ50joQhYWF4YMPPoChoSEsLCygUCikbQqFQueBqHbt2hrLX331FRo0aICOHTtK65RKJdRqdYH7p6enIzQ0FKtWrUKXLl0AAKtXr4adnR127dqFbt266bReIiIiqny0fux+xowZmDFjBtLT05GUlITExETp9c8//5RGjZInT55g9erVGDlypEYQ27dvH6ysrNC4cWP4+/sjNTVV2hYTE4Ps7Gx4eXlJ62xtbeHk5ITDhw8XeqysrCxkZGRovIiIiKhq0joQPXz4EIMHD0a1alrv+so2bdqEe/fuYfjw4dI6b29vREREYM+ePZg/fz6OHz+OTp06ISsrCwCQkpICQ0ND1KpVS6Mva2trpKSkFHqsOXPmQKVSSS87O7tSOSciIiIqf1qnmlGjRuG3334rjVqKFBoaCm9vb9ja2krrBg0ahJ49e8LJyQm9evXCX3/9hYsXL2L79u0v7UsIoTHL9KKgoCCkp6dLr+vXr+vsPIiIiKhi0foeojlz5sDHxweRkZFwdnaGgYGBxvYFCxborLjnXb16Fbt27cKGDRte2s7Gxgb29va4dOkSAECtVuPJkydIS0vTmCVKTU2Fu7t7of0olUoolUrdFE9EREQVmtaBaPbs2dixYweaNGkCAPluqi4tYWFhsLKyQs+ePV/a7s6dO7h+/TpsbGwAAG3atIGBgQGioqIwcOBAAEBycjLi4uIwb968UquXiIiIKg+tA9GCBQuwfPlyjft4Sltubi7CwsIwbNgw6Ov/X8mZmZkIDg7GgAEDYGNjg6SkJEybNg2Wlpbo168fAEClUmHUqFEIDAyEhYUFzM3NMXXqVDg7O0tPnREREZG8aR2IlEolOnToUBq1FGrXrl24du0aRo4cqbFeT08PZ8+excqVK3Hv3j3Y2NjA09MT69evh6mpqdRu4cKF0NfXx8CBA/Ho0SN07twZ4eHh/AwiIiIiAlCCQDRp0iQsXrwY3333XWnUUyAvLy+N71HLY2xsjB07dhS5v5GRERYvXozFixeXRnlERERUyWkdiI4dO4Y9e/Zg27ZtaNGiRb6bqou66ZmIiIiootE6ENWsWRP9+/cvjVqIiIiIykWJvrqDiIiIqCop+4+bJiIiIqpgtJ4hcnR0fOnnDZX295kRERER6ZrWgWjy5Mkay9nZ2Th16hQiIyPx4Ycf6qouIiIiojJTosfuC/L999/jxIkTr1wQERERUVnT2T1E3t7e+OOPP3TVHREREVGZ0Vkg+v3332Fubq6r7oiIiIjKjNaXzFxcXDRuqhZCICUlBbdu3cLSpUt1WhwRERFRWdA6EPXt21djuVq1aqhduzY8PDzQtGlTXdVFREREVGa0DkQzZ84sjTqIiIiIyg0/mJGIiIhkr9gzRNWqVXvpBzICgEKhwNOnT1+5KCIiIqKyVOxAtHHjxkK3HT58GIsXL4YQQidFEREREZWlYgeiPn365Ft34cIFBAUFYevWrRgyZAg+//xznRZHREREVBZKdA/Rf//9B39/f7Rs2RJPnz7FqVOnsGLFCtSrV0/X9RERERGVOq0CUXp6Oj7++GM0bNgQ8fHx2L17N7Zu3QpnZ+fSqo+IiIio1BX7ktm8efMwd+5cqNVqrF27tsBLaERERESVUbED0SeffAJjY2M0bNgQK1aswIoVKwpst2HDBp0VR0RERFQWih2Ihg4dWuRj90RERESVUbEDUXh4eCmWQURERFR++EnVREREJHsMRERERCR7DEREREQkewxEREREJHsMRERERCR7DEREREQkewxEREREJHsMRERERCR7DEREREQkewxEREREJHsMRERERCR7FToQBQcHQ6FQaLzUarW0XQiB4OBg2NrawtjYGB4eHoiPj9foIysrCxMmTIClpSWqV6+O3r1748aNG2V9KkRERFSBVehABAAtWrRAcnKy9Dp79qy0bd68eViwYAGWLFmC48ePQ61Wo2vXrrh//77UZvLkydi4cSPWrVuHgwcPIjMzEz4+PsjJySmP0yEiIqIKqNjfdl9e9PX1NWaF8gghsGjRIkyfPh39+/cHAKxYsQLW1tZYs2YN3n//faSnpyM0NBSrVq1Cly5dAACrV6+GnZ0ddu3ahW7dupXpuRAREVHFVOFniC5dugRbW1s4Ojpi8ODB+OeffwAAiYmJSElJgZeXl9RWqVSiY8eOOHz4MAAgJiYG2dnZGm1sbW3h5OQktSEiIiKq0DNE7dq1w8qVK9G4cWPcvHkTX3zxBdzd3REfH4+UlBQAgLW1tcY+1tbWuHr1KgAgJSUFhoaGqFWrVr42efsXJisrC1lZWdJyRkaGLk6JiIiIKqAKHYi8vb2ln52dneHm5oYGDRpgxYoVaN++PQBAoVBo7COEyLfuRcVpM2fOHISEhJSwciIiIqpMKvwls+dVr14dzs7OuHTpknRf0YszPampqdKskVqtxpMnT5CWllZom8IEBQUhPT1del2/fl2HZ0JEREQVSaUKRFlZWTh//jxsbGzg6OgItVqNqKgoafuTJ0+wf/9+uLu7AwDatGkDAwMDjTbJycmIi4uT2hRGqVTCzMxM40VERERVU4W+ZDZ16lT06tUL9erVQ2pqKr744gtkZGRg2LBhUCgUmDx5MmbPno1GjRqhUaNGmD17NkxMTODr6wsAUKlUGDVqFAIDA2FhYQFzc3NMnToVzs7O0lNnRERERBU6EN24cQPvvPMObt++jdq1a6N9+/Y4cuQI7O3tAQAfffQRHj16hLFjxyItLQ3t2rXDzp07YWpqKvWxcOFC6OvrY+DAgXj06BE6d+6M8PBw6OnplddpERERUQVToQPRunXrXrpdoVAgODgYwcHBhbYxMjLC4sWLsXjxYh1XR0RERFVFpbqHiIiIiKg0MBARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsMRARERGR7DEQERERkewxEBEREZHsVehANGfOHLz22mswNTWFlZUV+vbti4SEBI02w4cPh0Kh0Hi1b99eo01WVhYmTJgAS0tLVK9eHb1798aNGzfK8lSIiIioAqvQgWj//v0YN24cjhw5gqioKDx9+hReXl548OCBRrvu3bsjOTlZev35558a2ydPnoyNGzdi3bp1OHjwIDIzM+Hj44OcnJyyPB0iIiKqoPTLu4CXiYyM1FgOCwuDlZUVYmJi8L///U9ar1QqoVarC+wjPT0doaGhWLVqFbp06QIAWL16Nezs7LBr1y5069at9E6AiIiIKoUKPUP0ovT0dACAubm5xvp9+/bBysoKjRs3hr+/P1JTU6VtMTExyM7OhpeXl7TO1tYWTk5OOHz4cKHHysrKQkZGhsaLiIiIqqZKE4iEEAgICMAbb7wBJycnab23tzciIiKwZ88ezJ8/H8ePH0enTp2QlZUFAEhJSYGhoSFq1aql0Z+1tTVSUlIKPd6cOXOgUqmkl52dXemcGBEREZW7Cn3J7Hnjx4/HmTNncPDgQY31gwYNkn52cnJC27ZtYW9vj+3bt6N///6F9ieEgEKhKHR7UFAQAgICpOWMjAyGIiIioiqqUswQTZgwAVu2bMHevXtRt27dl7a1sbGBvb09Ll26BABQq9V48uQJ0tLSNNqlpqbC2tq60H6USiXMzMw0XkRERFQ1VehAJITA+PHjsWHDBuzZsweOjo5F7nPnzh1cv34dNjY2AIA2bdrAwMAAUVFRUpvk5GTExcXB3d291GonIiKiyqNCXzIbN24c1qxZg82bN8PU1FS650elUsHY2BiZmZkIDg7GgAEDYGNjg6SkJEybNg2Wlpbo16+f1HbUqFEIDAyEhYUFzM3NMXXqVDg7O0tPnREREZG8VehAtGzZMgCAh4eHxvqwsDAMHz4cenp6OHv2LFauXIl79+7BxsYGnp6eWL9+PUxNTaX2CxcuhL6+PgYOHIhHjx6hc+fOCA8Ph56eXlmeDhEREVVQFToQCSFeut3Y2Bg7duwosh8jIyMsXrwYixcv1lVpREREVIVU6HuIiIiIiMoCAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyZ6sAtHSpUvh6OgIIyMjtGnTBn///Xd5l0REREQVgGwC0fr16zF58mRMnz4dp06dwptvvglvb29cu3atvEsjIiKiciabQLRgwQKMGjUK7733Hpo1a4ZFixbBzs4Oy5YtK+/SiIiIqJzJIhA9efIEMTEx8PLy0ljv5eWFw4cPl1NVREREVFHol3cBZeH27dvIycmBtbW1xnpra2ukpKQUuE9WVhaysrKk5fT0dABARkaGzuvLzXqo8z4ri1cZT7mO26v+DnLcSobjpj2OWclw3EqnXyHES9vJIhDlUSgUGstCiHzr8syZMwchISH51tvZ2ZVKbXKlWlTeFVQ+HLOS4biVDMdNexyzkintcbt//z5UKlWh22URiCwtLaGnp5dvNig1NTXfrFGeoKAgBAQESMu5ubm4e/cuLCwsCg1RlU1GRgbs7Oxw/fp1mJmZlXc5lQbHrWQ4biXDcdMex6xkquq4CSFw//592NravrSdLAKRoaEh2rRpg6ioKPTr109aHxUVhT59+hS4j1KphFKp1FhXs2bN0iyz3JiZmVWpX/6ywnErGY5byXDctMcxK5mqOG4vmxnKI4tABAABAQHw8/ND27Zt4ebmhp9++gnXrl3DBx98UN6lERERUTmTTSAaNGgQ7ty5g1mzZiE5ORlOTk74888/YW9vX96lERERUTmTTSACgLFjx2Ls2LHlXUaFoVQqMXPmzHyXBunlOG4lw3ErGY6b9jhmJSP3cVOIop5DIyIiIqriZPHBjEREREQvw0BEREREssdARERERLLHQFSFhYeHa/XZSfv27YNCocC9e/dKraaKjmNWMhy3kuG4lQzHTXscs2IQVGEcOnRIVKtWTXTr1k3rfe3t7cXChQs11j18+FDcvHmz2H1kZWWJ5ORkkZubK4QQIiwsTKhUKq1rKcjEiROFq6urMDQ0FK1atdJJn0JU3TGLjY0VgwcPFnXr1hVGRkaiadOmYtGiRa/cb56qOm63b98W3bp1EzY2NsLQ0FDUrVtXjBs3TqSnp79y30JU3XF73u3bt0WdOnUEAJGWlqaTPqvyuAHI91q2bNkr91uVxyyvP2dnZ6FUKoW1tbUYN26czvouKc4QVSDLly/HhAkTcPDgQVy7du2V+zM2NoaVlVWx2xsaGkKtVpfKV5MIITBy5EgMGjRIp/1W1TGLiYlB7dq1sXr1asTHx2P69OkICgrCkiVLdNJ/VR23atWqoU+fPtiyZQsuXryI8PBw7Nq1S2cfwFpVx+15o0aNQsuWLXXaZ1Uft7CwMCQnJ0uvYcOGvXKfVXnMFixYgOnTp+OTTz5BfHw8du/ejW7duun8OFor70RGz2RmZgpTU1Nx4cIFMWjQIBESEpKvzebNm0WbNm2EUqkUFhYWol+/fkIIITp27Jjv/1CE0Ez0Fy5cEADE+fPnNfqcP3++sLe3F7m5uWLv3r3S/xXm/fz8a+bMmSIkJEQ4OTnlq83V1VV89tlnRZ7nzJkzdTZDJJcxyzN27Fjh6elZ7PaFkdu4ffvtt6Ju3brFbl8YOYzb0qVLRceOHcXu3bt1NkNU1ccNgNi4cWMJR6dgVXnM7t69K4yNjcWuXbteZYhKBQNRBREaGiratm0rhBBi69atwsHBQZqqFEKIbdu2CT09PTFjxgxx7tw5ERsbK7788kshhBB37twRdevWFbNmzRLJyckiOTlZCJF/irNNmzbi008/1ThumzZtRFBQkBBCaPwDyMrKEosWLRJmZmZSn/fv3xfXr18X1apVE8eOHZP6OH36tFAoFOLKlStFnqcuA5FcxizPkCFDxIABA7QbpALIadz+/fdf0bFjRzFkyBDtB+oFVX3c4uPjhVqtFlevXtU4zquq6uMGQNSpU0dYWFiItm3bimXLlomcnByOWSFjtn79eqFUKsWKFStE06ZNRZ06dcTbb78trl279kpjpgsMRBWEu7u7dI9Idna2sLS0FFFRUdJ2Nze3l/5HvaBrxi/+A1iwYIGoX7++tJyQkCAAiPj4eCGEyPcfwcKuGXt7e4sxY8ZIy5MnTxYeHh7FOk9dBiK5jJkQQhw+fFgYGBiInTt3Fnufwshh3AYPHiyMjY0FANGrVy/x6NGjIvcpSlUet8ePH4uWLVuKVatWFXicV1GVx00IIT7//HNx+PBhcerUKfHNN98IExMT8fnnn790n6JU5TGbM2eOMDAwEE2aNBGRkZEiOjpadO7cWTRp0kRkZWUVul9Z4D1EFUBCQgKOHTuGwYMHAwD09fUxaNAgLF++XGoTGxuLzp07v9JxBg8ejKtXr+LIkSMAgIiICLRu3RrNmzfXqh9/f3+sXbsWjx8/RnZ2NiIiIjBy5MhXqk1bchqz+Ph49OnTBzNmzEDXrl21PofnyWXcFi5ciJMnT2LTpk24cuUKAgICSnQeear6uAUFBaFZs2Z49913X6n+F1X1cQOATz/9FG5ubmjdujUCAwMxa9YsfP311yU+l6o+Zrm5ucjOzsZ3332Hbt26oX379li7di0uXbqEvXv3vtI5vSpZfZdZRRUaGoqnT5+iTp060johBAwMDJCWloZatWrB2Nj4lY9jY2MDT09PrFmzRvolfP/997Xup1evXlAqldi4cSOUSiWysrIwYMCAV65PG3IZs3PnzqFTp07w9/fHp59+WpJT0CCXcVOr1VCr1WjatCksLCzw5ptv4rPPPoONjU1JTqfKj9uePXtw9uxZ/P777wCenRsAWFpaYvr06QgJCSnR+VT1cStI+/btkZGRgZs3b8La2lrrGqr6mOX9G3w+eNWuXRuWlpY6uXn8VXCGqJw9ffoUK1euxPz58xEbGyu9Tp8+DXt7e0RERAAAWrZsid27dxfaj6GhIXJycoo83pAhQ7B+/XpER0fjypUr0v+FaNOnvr4+hg0bhrCwMISFhWHw4MEwMTEpxtnqhlzGLD4+Hp6enhg2bBi+/PLLIussilzG7UV5f9yzsrK02i+PHMbtjz/+wOnTp6Vz++WXXwAAf//9N8aNG1dkzQWRw7gV5NSpUzAyMtLqM3/yyGHMOnToAODZTFieu3fv4vbt27C3ty+y5lJVflfrSAghNm7cKAwNDcW9e/fybZs2bZpo3bq1EOLZ9dxq1apJN9GdOXNGzJ07V2rbtWtX0bt3b3Hjxg1x69YtIUTB13zT09OFkZGRaNWqlejcubPGthevGR86dEgAELt27RK3bt0SDx48kNpevHhR6OnpCT09PXHkyJEiz/PSpUvi1KlT4v333xeNGzcWp06dEqdOnSrRNWM5jFlcXJyoXbu2GDJkiHQTY3JyskhNTS32OL1IDuO2fft2sXz5cnH27FmRmJgotm/fLlq0aCE6dOhQ7HF6kRzG7UW6uIdIDuO2ZcsW8dNPP4mzZ8+Ky5cvi59//lmYmZmJiRMnFnucnieHMRNCiD59+ogWLVqIQ4cOibNnzwofHx/RvHlz8eTJk2KNU2lhICpnPj4+okePHgVui4mJEQBETEyMEEKIP/74Q7Ru3VoYGhoKS0tL0b9/f6ltdHS0aNmypVAqlQU+Zvm8t99+WwAQy5cv11hf0H8EP/jgA2FhYSE9Zvm8N998UzRv3rxY51nQo6AARGJiYrH2f54cxmzmzJkFjpe9vX2R+xZGDuO2Z88e4ebmJlQqlTAyMhKNGjUSH3/88Sv9YZfDuL1IF4FIDuP2119/idatW4saNWoIExMT4eTkJBYtWiSys7OL3LcgchgzIZ4FsZEjR4qaNWsKc3Nz0a9fvwrxlJlCiP8/n0ykBSEEmjZtivfff/+Vb1iVC45ZyXDcSobjVjIcN+1VlTHjTdWktdTUVKxatQr//vsvRowYUd7lVAocs5LhuJUMx61kOG7aq0pjxkBEWrO2toalpSV++ukn1KpVq7zLqRQ4ZiXDcSsZjlvJcNy0V5XGjJfMiIiISPb42D0RERHJHgMRERERyR4DEREREckeAxERERHJHgMREVVI4eHhWn39wb59+6BQKHDv3r1Sq6mkHBwcsGjRolfqIzg4GK1bt9ZJPUSUHwMREenE4cOHoaenh+7du2u9b0GBYdCgQbh48WKx+3B3d0dycjJUKhUA7QNVYZKSkqBQKBAbG/vKfRFRxcVAREQ6sXz5ckyYMAEHDx7UybdWGxsbw8rKqtjtDQ0NoVaroVAoXvnYRCQ/DERE9MoePHiAX3/9FWPGjIGPjw/Cw8PztdmyZQvatm0LIyMjWFpaon///gAADw8PXL16FVOmTIFCoZACzfMzPAkJCVAoFLhw4YJGnwsWLICDgwOEEBqXzPbt24cRI0YgPT1d6jM4OBizZs2Cs7NzvtratGmDGTNmlOjcr1y5gj59+sDa2ho1atTAa6+9hl27duVrd//+ffj6+qJGjRqwtbXF4sWLNbanp6dj9OjRsLKygpmZGTp16oTTp08Xetx9+/bh9ddfR/Xq1VGzZk106NABV69eLdE5EBEDERHpwPr169GkSRM0adIE7777LsLCwvD8Z75u374d/fv3R8+ePXHq1Cns3r0bbdu2BQBs2LABdevWxaxZs5CcnIzk5OR8/Tdp0gRt2rRBRESExvo1a9bA19c336yQu7s7Fi1aBDMzM6nPqVOnYuTIkTh37hyOHz8utT1z5gxOnTqF4cOHl+jcMzMz0aNHD+zatQunTp1Ct27d0KtXr3yzZF9//TVatmyJkydPIigoCFOmTEFUVBSAZ98F1bNnT6SkpODPP/9ETEwMXF1d0blzZ9y9ezffMZ8+fYq+ffuiY8eOOHPmDKKjozF69GjOjhG9inL5SlkiqlLc3d3FokWLhBBCZGdnC0tLSxEVFSVtd3NzE0OGDCl0f3t7e7Fw4UKNdS9+O/eCBQtE/fr1peWEhAQBQMTHxwsh8n87d2Hf7u3t7S3GjBkjLU+ePFl4eHgUWltiYqIAIE6dOlVomxc1b95cLF68WOP8unfvrtFm0KBBwtvbWwghxO7du4WZmZl4/PixRpsGDRqIH3/8UQghxMyZM0WrVq2EEELcuXNHABD79u0rdk1E9HKcISKiV5KQkIBjx45h8ODBAAB9fX0MGjQIy5cvl9rExsaic+fOr3ScwYMH4+rVqzhy5AgAICIiAq1bt0bz5s216sff3x9r167F48ePkZ2djYiICIwcObLEdT148AAfffQRmjdvjpo1a6JGjRq4cOFCvhkiNze3fMvnz58HAMTExCAzMxMWFhaoUaOG9EpMTMSVK1fyHdPc3BzDhw+XZqO+/fbbAmfWiKj4+OWuRPRKQkND8fTpU9SpU0daJ4SAgYEB0tLSUKtWLRgbG7/ycWxsbODp6Yk1a9agffv2WLt2Ld5//32t++nVqxeUSiU2btwIpVKJrKwsDBgwoMR1ffjhh9ixYwe++eYbNGzYEMbGxnjrrbfw5MmTIvfNu8SVm5sLGxsb7Nu3L1+bwp6UCwsLw8SJExEZGYn169fj008/RVRUFNq3b1/icyGSMwYiIiqxp0+fYuXKlZg/fz68vLw0tg0YMAAREREYP348WrZsid27d2PEiBEF9mNoaIicnJwijzdkyBB8/PHHeOedd3DlyhVpVkqbPvX19TFs2DCEhYVBqVRi8ODBMDExKfLYhfn7778xfPhw9OvXD8Cze4qSkpLytcub2Xp+uWnTpgAAV1dXpKSkQF9fHw4ODsU+touLC1xcXBAUFAQ3NzcpLBKR9hiIiKjEtm3bhrS0NIwaNUr6/J88b731FkJDQzF+/HjMnDkTnTt3RoMGDTB48GA8ffoUf/31Fz766CMAzz6H6MCBAxg8eDCUSiUsLS0LPF7//v0xZswYjBkzBp6enhqzUi9ycHBAZmYmdu/ejVatWsHExEQKPu+99x6aNWsGADh06FCxzjUhISHfuubNm6Nhw4bYsGEDevXqBYVCgc8++wy5ubn52h46dAjz5s1D3759ERUVhd9++w3bt28HAHTp0gVubm7o27cv5s6diyZNmuC///7Dn3/+ib59+0o3oOdJTEzETz/9hN69e8PW1hYJCQm4ePEihg4dWqxzIaIClPdNTERUefn4+IgePXoUuC0mJkYAEDExMUIIIf744w/RunVrYWhoKCwtLUX//v2lttHR0aJly5ZCqVSKvP8sFXZT9Ntvvy0AiOXLl2usf/GmaiGE+OCDD4SFhYUAIGbOnKnR/s033xTNmzcv8hzzbqou6JWYmCgSExOFp6enMDY2FnZ2dmLJkiWiY8eOYtKkSVIf9vb2IiQkRAwcOFCYmJgIa2tr6Sb0PBkZGWLChAnC1tZWGBgYCDs7OzFkyBBx7do1IYTmTdUpKSmib9++wsbGRhgaGgp7e3sxY8YMkZOTU+T5EFHBFEI892wsEZEMCCHQtGlTvP/++wgICCjvcoioAuAlMyKSldTUVKxatQr//vtvofc0EZH8MBARkaxYW1vD0tISP/30E2rVqlXe5RBRBcFARESywrsEiKgg/GBGIiIikj0GIiIiIpI9BiIiIiKSPQYiIiIikj0GIiIiIpI9BiIiIiKSPQYiIiIikj0GIiIiIpI9BiIiIiKSvf8HY258A2a07PIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "________________________________ Outliers info...________________________________________________\n",
      "A row is considered as outlier if the number of its outliers exceeds: 100\n",
      "Number of rows droped : 1166\n",
      "\n",
      "\n",
      "Outliers of Dataset type I has a shape of: 1166 rows and 642 columns\n",
      "\n",
      "\n",
      "\n",
      "Number of windows per user and per each activity:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User 1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 6</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 8</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 14</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 19</th>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 20</th>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 21</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 22</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 23</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  \\\n",
       "User 1            0           0           0           3           2   \n",
       "User 2            0           1           2           3           7   \n",
       "User 3            0           0           0          17          23   \n",
       "User 4            0           0           0          15          13   \n",
       "User 5            0           0           0          16          24   \n",
       "User 6            1          12          14          27          16   \n",
       "User 7            8           0           0          14           9   \n",
       "User 8            0          12           9           6           7   \n",
       "User 9            0           0           0          20          11   \n",
       "User 10           0           1           0           8          12   \n",
       "User 11           0           0           0          13           3   \n",
       "User 12           0           0           2          19          16   \n",
       "User 13           0           0           0           4          11   \n",
       "User 14           0          20           7          10          13   \n",
       "User 15           0           0           0           7           8   \n",
       "User 16           0           0           0           5           2   \n",
       "User 17           0           0           0           5           6   \n",
       "User 18           0           0           0           4           2   \n",
       "User 19          21          14          24           6           6   \n",
       "User 20          13           6           0          18          34   \n",
       "User 21           0           1           0           7          15   \n",
       "User 22           0          10           0          15          13   \n",
       "User 23          22           0          16          13          10   \n",
       "User 24           0           0           0           4          11   \n",
       "User 25           0           0           0           3           5   \n",
       "User 26           0           0           0           5           4   \n",
       "User 27           0           0           0           5           7   \n",
       "User 28           0           0           0          21          21   \n",
       "User 29           0           0           0           3           0   \n",
       "User 30           0           0           0           6          18   \n",
       "\n",
       "         Activity 6  \n",
       "User 1           11  \n",
       "User 2            4  \n",
       "User 3           10  \n",
       "User 4            9  \n",
       "User 5            8  \n",
       "User 6           17  \n",
       "User 7            7  \n",
       "User 8           13  \n",
       "User 9           27  \n",
       "User 10          16  \n",
       "User 11           8  \n",
       "User 12          17  \n",
       "User 13           4  \n",
       "User 14          14  \n",
       "User 15          15  \n",
       "User 16           2  \n",
       "User 17          14  \n",
       "User 18           6  \n",
       "User 19           7  \n",
       "User 20           4  \n",
       "User 21           8  \n",
       "User 22          14  \n",
       "User 23           6  \n",
       "User 24           7  \n",
       "User 25          31  \n",
       "User 26           4  \n",
       "User 27           6  \n",
       "User 28          16  \n",
       "User 29           1  \n",
       "User 30          13  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Statistics of table above:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.166667</td>\n",
       "      <td>2.566667</td>\n",
       "      <td>2.466667</td>\n",
       "      <td>10.066667</td>\n",
       "      <td>10.966667</td>\n",
       "      <td>10.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.925301</td>\n",
       "      <td>5.334878</td>\n",
       "      <td>5.823456</td>\n",
       "      <td>6.689845</td>\n",
       "      <td>7.645072</td>\n",
       "      <td>6.840464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>8.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  Activity 6\n",
       "count   30.000000   30.000000   30.000000   30.000000   30.000000   30.000000\n",
       "mean     2.166667    2.566667    2.466667   10.066667   10.966667   10.633333\n",
       "std      5.925301    5.334878    5.823456    6.689845    7.645072    6.840464\n",
       "min      0.000000    0.000000    0.000000    3.000000    0.000000    1.000000\n",
       "25%      0.000000    0.000000    0.000000    5.000000    6.000000    6.000000\n",
       "50%      0.000000    0.000000    0.000000    7.000000   10.500000    8.500000\n",
       "75%      0.000000    1.000000    0.000000   15.000000   14.500000   14.000000\n",
       "max     22.000000   20.000000   24.000000   27.000000   34.000000   31.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "_____ The weights of each activity _____\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Weights</th>\n",
       "      <td>0.055746</td>\n",
       "      <td>0.066038</td>\n",
       "      <td>0.063465</td>\n",
       "      <td>0.259005</td>\n",
       "      <td>0.282161</td>\n",
       "      <td>0.273585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  \\\n",
       "Weights    0.055746    0.066038    0.063465    0.259005    0.282161   \n",
       "\n",
       "         Activity 6  \n",
       "Weights    0.273585  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "________________________________ Cleaned+Dataset type I Dataframe info...________________________________________\n",
      "Number of rows in the clean dataframe Dataset type I: 9233\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Dataset type I has a shape of: 9233 rows and 642 columns\n",
      "\n",
      "\n",
      "\n",
      "The first 3 rows of Dataset type I :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_body_acc_mean()_X</th>\n",
       "      <th>t_body_acc_mean()_Y</th>\n",
       "      <th>t_body_acc_mean()_Z</th>\n",
       "      <th>t_body_acc_std()_X</th>\n",
       "      <th>t_body_acc_std()_Y</th>\n",
       "      <th>t_body_acc_std()_Z</th>\n",
       "      <th>t_body_acc_mad()_X</th>\n",
       "      <th>t_body_acc_mad()_Y</th>\n",
       "      <th>t_body_acc_mad()_Z</th>\n",
       "      <th>t_body_acc_max()_X</th>\n",
       "      <th>...</th>\n",
       "      <th>f_body_gyro_Jerk_Mag_kurtosis()</th>\n",
       "      <th>angle0()</th>\n",
       "      <th>angle1()</th>\n",
       "      <th>angle2()</th>\n",
       "      <th>angle3()</th>\n",
       "      <th>angle4()</th>\n",
       "      <th>angle5()</th>\n",
       "      <th>angle6()</th>\n",
       "      <th>activity_Id</th>\n",
       "      <th>user_Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.004441</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>0.013983</td>\n",
       "      <td>0.027372</td>\n",
       "      <td>0.004725</td>\n",
       "      <td>0.019132</td>\n",
       "      <td>0.025280</td>\n",
       "      <td>0.010209</td>\n",
       "      <td>...</td>\n",
       "      <td>104.954731</td>\n",
       "      <td>1.070749</td>\n",
       "      <td>1.431913</td>\n",
       "      <td>2.116867</td>\n",
       "      <td>1.431211</td>\n",
       "      <td>0.152888</td>\n",
       "      <td>1.692169</td>\n",
       "      <td>1.478284</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000713</td>\n",
       "      <td>-0.003098</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.004491</td>\n",
       "      <td>0.012449</td>\n",
       "      <td>0.022660</td>\n",
       "      <td>0.004168</td>\n",
       "      <td>0.014039</td>\n",
       "      <td>0.022765</td>\n",
       "      <td>0.009030</td>\n",
       "      <td>...</td>\n",
       "      <td>109.749747</td>\n",
       "      <td>1.652580</td>\n",
       "      <td>1.856253</td>\n",
       "      <td>1.210803</td>\n",
       "      <td>1.753009</td>\n",
       "      <td>0.149532</td>\n",
       "      <td>1.687352</td>\n",
       "      <td>1.477548</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000301</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>-0.004280</td>\n",
       "      <td>0.004866</td>\n",
       "      <td>0.009352</td>\n",
       "      <td>0.016821</td>\n",
       "      <td>0.005255</td>\n",
       "      <td>0.010157</td>\n",
       "      <td>0.020681</td>\n",
       "      <td>0.011261</td>\n",
       "      <td>...</td>\n",
       "      <td>110.445137</td>\n",
       "      <td>1.776612</td>\n",
       "      <td>1.159471</td>\n",
       "      <td>1.763958</td>\n",
       "      <td>2.682216</td>\n",
       "      <td>0.157004</td>\n",
       "      <td>1.696158</td>\n",
       "      <td>1.476770</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 642 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   t_body_acc_mean()_X  t_body_acc_mean()_Y  t_body_acc_mean()_Z  \\\n",
       "0             0.002012             0.000431             0.004441   \n",
       "1            -0.000713            -0.003098             0.000823   \n",
       "2            -0.000301             0.004025            -0.004280   \n",
       "\n",
       "   t_body_acc_std()_X  t_body_acc_std()_Y  t_body_acc_std()_Z  \\\n",
       "0            0.004025            0.013983            0.027372   \n",
       "1            0.004491            0.012449            0.022660   \n",
       "2            0.004866            0.009352            0.016821   \n",
       "\n",
       "   t_body_acc_mad()_X  t_body_acc_mad()_Y  t_body_acc_mad()_Z  \\\n",
       "0            0.004725            0.019132            0.025280   \n",
       "1            0.004168            0.014039            0.022765   \n",
       "2            0.005255            0.010157            0.020681   \n",
       "\n",
       "   t_body_acc_max()_X  ...  f_body_gyro_Jerk_Mag_kurtosis()  angle0()  \\\n",
       "0            0.010209  ...                       104.954731  1.070749   \n",
       "1            0.009030  ...                       109.749747  1.652580   \n",
       "2            0.011261  ...                       110.445137  1.776612   \n",
       "\n",
       "   angle1()  angle2()  angle3()  angle4()  angle5()  angle6()  activity_Id  \\\n",
       "0  1.431913  2.116867  1.431211  0.152888  1.692169  1.478284          5.0   \n",
       "1  1.856253  1.210803  1.753009  0.149532  1.687352  1.477548          5.0   \n",
       "2  1.159471  1.763958  2.682216  0.157004  1.696158  1.476770          5.0   \n",
       "\n",
       "   user_Id  \n",
       "0      1.0  \n",
       "1      1.0  \n",
       "2      1.0  \n",
       "\n",
       "[3 rows x 642 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "rows 500, 501, 502 of Dataset type I :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_body_acc_mean()_X</th>\n",
       "      <th>t_body_acc_mean()_Y</th>\n",
       "      <th>t_body_acc_mean()_Z</th>\n",
       "      <th>t_body_acc_std()_X</th>\n",
       "      <th>t_body_acc_std()_Y</th>\n",
       "      <th>t_body_acc_std()_Z</th>\n",
       "      <th>t_body_acc_mad()_X</th>\n",
       "      <th>t_body_acc_mad()_Y</th>\n",
       "      <th>t_body_acc_mad()_Z</th>\n",
       "      <th>t_body_acc_max()_X</th>\n",
       "      <th>...</th>\n",
       "      <th>f_body_gyro_Jerk_Mag_kurtosis()</th>\n",
       "      <th>angle0()</th>\n",
       "      <th>angle1()</th>\n",
       "      <th>angle2()</th>\n",
       "      <th>angle3()</th>\n",
       "      <th>angle4()</th>\n",
       "      <th>angle5()</th>\n",
       "      <th>angle6()</th>\n",
       "      <th>activity_Id</th>\n",
       "      <th>user_Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>-0.002944</td>\n",
       "      <td>-0.012426</td>\n",
       "      <td>-0.012190</td>\n",
       "      <td>0.005728</td>\n",
       "      <td>0.027819</td>\n",
       "      <td>0.024724</td>\n",
       "      <td>0.005834</td>\n",
       "      <td>0.033920</td>\n",
       "      <td>0.032150</td>\n",
       "      <td>0.009813</td>\n",
       "      <td>...</td>\n",
       "      <td>69.992433</td>\n",
       "      <td>2.003585</td>\n",
       "      <td>1.804211</td>\n",
       "      <td>1.587629</td>\n",
       "      <td>1.637262</td>\n",
       "      <td>0.356367</td>\n",
       "      <td>1.537628</td>\n",
       "      <td>1.216114</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>-0.002311</td>\n",
       "      <td>-0.006785</td>\n",
       "      <td>-0.010121</td>\n",
       "      <td>0.008558</td>\n",
       "      <td>0.015155</td>\n",
       "      <td>0.014312</td>\n",
       "      <td>0.008051</td>\n",
       "      <td>0.016058</td>\n",
       "      <td>0.010291</td>\n",
       "      <td>0.034658</td>\n",
       "      <td>...</td>\n",
       "      <td>92.157613</td>\n",
       "      <td>1.685352</td>\n",
       "      <td>2.100664</td>\n",
       "      <td>1.109655</td>\n",
       "      <td>1.597797</td>\n",
       "      <td>0.411527</td>\n",
       "      <td>1.939950</td>\n",
       "      <td>1.397265</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.004908</td>\n",
       "      <td>0.004283</td>\n",
       "      <td>0.007848</td>\n",
       "      <td>0.011278</td>\n",
       "      <td>0.011842</td>\n",
       "      <td>0.008465</td>\n",
       "      <td>0.015903</td>\n",
       "      <td>0.009328</td>\n",
       "      <td>0.012532</td>\n",
       "      <td>...</td>\n",
       "      <td>103.666230</td>\n",
       "      <td>1.679729</td>\n",
       "      <td>0.671063</td>\n",
       "      <td>2.198287</td>\n",
       "      <td>1.904642</td>\n",
       "      <td>0.413992</td>\n",
       "      <td>1.951394</td>\n",
       "      <td>1.415822</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 642 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     t_body_acc_mean()_X  t_body_acc_mean()_Y  t_body_acc_mean()_Z  \\\n",
       "527            -0.002944            -0.012426            -0.012190   \n",
       "528            -0.002311            -0.006785            -0.010121   \n",
       "529             0.000493             0.004908             0.004283   \n",
       "\n",
       "     t_body_acc_std()_X  t_body_acc_std()_Y  t_body_acc_std()_Z  \\\n",
       "527            0.005728            0.027819            0.024724   \n",
       "528            0.008558            0.015155            0.014312   \n",
       "529            0.007848            0.011278            0.011842   \n",
       "\n",
       "     t_body_acc_mad()_X  t_body_acc_mad()_Y  t_body_acc_mad()_Z  \\\n",
       "527            0.005834            0.033920            0.032150   \n",
       "528            0.008051            0.016058            0.010291   \n",
       "529            0.008465            0.015903            0.009328   \n",
       "\n",
       "     t_body_acc_max()_X  ...  f_body_gyro_Jerk_Mag_kurtosis()  angle0()  \\\n",
       "527            0.009813  ...                        69.992433  2.003585   \n",
       "528            0.034658  ...                        92.157613  1.685352   \n",
       "529            0.012532  ...                       103.666230  1.679729   \n",
       "\n",
       "     angle1()  angle2()  angle3()  angle4()  angle5()  angle6()  activity_Id  \\\n",
       "527  1.804211  1.587629  1.637262  0.356367  1.537628  1.216114          4.0   \n",
       "528  2.100664  1.109655  1.597797  0.411527  1.939950  1.397265          5.0   \n",
       "529  0.671063  2.198287  1.904642  0.413992  1.951394  1.415822          5.0   \n",
       "\n",
       "     user_Id  \n",
       "527      2.0  \n",
       "528      2.0  \n",
       "529      2.0  \n",
       "\n",
       "[3 rows x 642 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Description of the 10 first features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_body_acc_mean()_X</th>\n",
       "      <th>t_body_acc_mean()_Y</th>\n",
       "      <th>t_body_acc_mean()_Z</th>\n",
       "      <th>t_body_acc_std()_X</th>\n",
       "      <th>t_body_acc_std()_Y</th>\n",
       "      <th>t_body_acc_std()_Z</th>\n",
       "      <th>t_body_acc_mad()_X</th>\n",
       "      <th>t_body_acc_mad()_Y</th>\n",
       "      <th>t_body_acc_mad()_Z</th>\n",
       "      <th>t_body_acc_max()_X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000106</td>\n",
       "      <td>-0.000229</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.134419</td>\n",
       "      <td>0.087805</td>\n",
       "      <td>0.072849</td>\n",
       "      <td>0.126136</td>\n",
       "      <td>0.079964</td>\n",
       "      <td>0.067166</td>\n",
       "      <td>0.330723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.009234</td>\n",
       "      <td>0.006799</td>\n",
       "      <td>0.006837</td>\n",
       "      <td>0.139805</td>\n",
       "      <td>0.081400</td>\n",
       "      <td>0.067965</td>\n",
       "      <td>0.131496</td>\n",
       "      <td>0.072914</td>\n",
       "      <td>0.060304</td>\n",
       "      <td>0.348167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.047488</td>\n",
       "      <td>-0.038424</td>\n",
       "      <td>-0.047545</td>\n",
       "      <td>0.001815</td>\n",
       "      <td>0.002281</td>\n",
       "      <td>0.003507</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.002089</td>\n",
       "      <td>0.002521</td>\n",
       "      <td>0.003151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.003194</td>\n",
       "      <td>-0.003549</td>\n",
       "      <td>-0.003240</td>\n",
       "      <td>0.008573</td>\n",
       "      <td>0.011343</td>\n",
       "      <td>0.011020</td>\n",
       "      <td>0.009443</td>\n",
       "      <td>0.012313</td>\n",
       "      <td>0.011954</td>\n",
       "      <td>0.016929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000054</td>\n",
       "      <td>-0.000123</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>0.022836</td>\n",
       "      <td>0.030034</td>\n",
       "      <td>0.027372</td>\n",
       "      <td>0.028085</td>\n",
       "      <td>0.036344</td>\n",
       "      <td>0.032554</td>\n",
       "      <td>0.042353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.003248</td>\n",
       "      <td>0.003184</td>\n",
       "      <td>0.003262</td>\n",
       "      <td>0.246710</td>\n",
       "      <td>0.161034</td>\n",
       "      <td>0.129855</td>\n",
       "      <td>0.233766</td>\n",
       "      <td>0.143443</td>\n",
       "      <td>0.117874</td>\n",
       "      <td>0.627481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.046679</td>\n",
       "      <td>0.036071</td>\n",
       "      <td>0.045893</td>\n",
       "      <td>0.555511</td>\n",
       "      <td>0.338746</td>\n",
       "      <td>0.317958</td>\n",
       "      <td>0.601142</td>\n",
       "      <td>0.299577</td>\n",
       "      <td>0.282855</td>\n",
       "      <td>1.113230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       t_body_acc_mean()_X  t_body_acc_mean()_Y  t_body_acc_mean()_Z  \\\n",
       "count          9233.000000          9233.000000          9233.000000   \n",
       "mean              0.000106            -0.000229             0.000109   \n",
       "std               0.009234             0.006799             0.006837   \n",
       "min              -0.047488            -0.038424            -0.047545   \n",
       "25%              -0.003194            -0.003549            -0.003240   \n",
       "50%               0.000054            -0.000123            -0.000027   \n",
       "75%               0.003248             0.003184             0.003262   \n",
       "max               0.046679             0.036071             0.045893   \n",
       "\n",
       "       t_body_acc_std()_X  t_body_acc_std()_Y  t_body_acc_std()_Z  \\\n",
       "count         9233.000000         9233.000000         9233.000000   \n",
       "mean             0.134419            0.087805            0.072849   \n",
       "std              0.139805            0.081400            0.067965   \n",
       "min              0.001815            0.002281            0.003507   \n",
       "25%              0.008573            0.011343            0.011020   \n",
       "50%              0.022836            0.030034            0.027372   \n",
       "75%              0.246710            0.161034            0.129855   \n",
       "max              0.555511            0.338746            0.317958   \n",
       "\n",
       "       t_body_acc_mad()_X  t_body_acc_mad()_Y  t_body_acc_mad()_Z  \\\n",
       "count         9233.000000         9233.000000         9233.000000   \n",
       "mean             0.126136            0.079964            0.067166   \n",
       "std              0.131496            0.072914            0.060304   \n",
       "min              0.001536            0.002089            0.002521   \n",
       "25%              0.009443            0.012313            0.011954   \n",
       "50%              0.028085            0.036344            0.032554   \n",
       "75%              0.233766            0.143443            0.117874   \n",
       "max              0.601142            0.299577            0.282855   \n",
       "\n",
       "       t_body_acc_max()_X  \n",
       "count         9233.000000  \n",
       "mean             0.330723  \n",
       "std              0.348167  \n",
       "min              0.003151  \n",
       "25%              0.016929  \n",
       "50%              0.042353  \n",
       "75%              0.627481  \n",
       "max              1.113230  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Description of the 10 first frequency features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_body_acc_mean()_X</th>\n",
       "      <th>f_body_acc_mean()_Y</th>\n",
       "      <th>f_body_acc_mean()_Z</th>\n",
       "      <th>f_body_acc_std()_X</th>\n",
       "      <th>f_body_acc_std()_Y</th>\n",
       "      <th>f_body_acc_std()_Z</th>\n",
       "      <th>f_body_acc_mad()_X</th>\n",
       "      <th>f_body_acc_mad()_Y</th>\n",
       "      <th>f_body_acc_mad()_Z</th>\n",
       "      <th>f_body_acc_max()_X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.774885</td>\n",
       "      <td>0.564345</td>\n",
       "      <td>0.457214</td>\n",
       "      <td>1.308013</td>\n",
       "      <td>0.817656</td>\n",
       "      <td>0.685013</td>\n",
       "      <td>0.339979</td>\n",
       "      <td>0.268215</td>\n",
       "      <td>0.242385</td>\n",
       "      <td>8.370037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.811851</td>\n",
       "      <td>0.549616</td>\n",
       "      <td>0.442992</td>\n",
       "      <td>1.361990</td>\n",
       "      <td>0.742803</td>\n",
       "      <td>0.634053</td>\n",
       "      <td>0.378119</td>\n",
       "      <td>0.288406</td>\n",
       "      <td>0.262074</td>\n",
       "      <td>8.940847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.015014</td>\n",
       "      <td>0.019182</td>\n",
       "      <td>0.028569</td>\n",
       "      <td>0.013632</td>\n",
       "      <td>0.019417</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.006711</td>\n",
       "      <td>0.006004</td>\n",
       "      <td>0.011886</td>\n",
       "      <td>0.051908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.042714</td>\n",
       "      <td>0.054223</td>\n",
       "      <td>0.058634</td>\n",
       "      <td>0.089610</td>\n",
       "      <td>0.119609</td>\n",
       "      <td>0.113962</td>\n",
       "      <td>0.018544</td>\n",
       "      <td>0.020268</td>\n",
       "      <td>0.029038</td>\n",
       "      <td>0.654762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.096350</td>\n",
       "      <td>0.133185</td>\n",
       "      <td>0.119858</td>\n",
       "      <td>0.248422</td>\n",
       "      <td>0.322917</td>\n",
       "      <td>0.298298</td>\n",
       "      <td>0.043612</td>\n",
       "      <td>0.047309</td>\n",
       "      <td>0.051015</td>\n",
       "      <td>1.944103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.460796</td>\n",
       "      <td>1.060396</td>\n",
       "      <td>0.839105</td>\n",
       "      <td>2.370136</td>\n",
       "      <td>1.482731</td>\n",
       "      <td>1.189677</td>\n",
       "      <td>0.624989</td>\n",
       "      <td>0.497541</td>\n",
       "      <td>0.430384</td>\n",
       "      <td>14.904714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.099702</td>\n",
       "      <td>2.277406</td>\n",
       "      <td>2.104386</td>\n",
       "      <td>5.491817</td>\n",
       "      <td>3.198097</td>\n",
       "      <td>3.203614</td>\n",
       "      <td>1.795844</td>\n",
       "      <td>1.360118</td>\n",
       "      <td>1.441752</td>\n",
       "      <td>38.437992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f_body_acc_mean()_X  f_body_acc_mean()_Y  f_body_acc_mean()_Z  \\\n",
       "count          9233.000000          9233.000000          9233.000000   \n",
       "mean              0.774885             0.564345             0.457214   \n",
       "std               0.811851             0.549616             0.442992   \n",
       "min               0.015014             0.019182             0.028569   \n",
       "25%               0.042714             0.054223             0.058634   \n",
       "50%               0.096350             0.133185             0.119858   \n",
       "75%               1.460796             1.060396             0.839105   \n",
       "max               3.099702             2.277406             2.104386   \n",
       "\n",
       "       f_body_acc_std()_X  f_body_acc_std()_Y  f_body_acc_std()_Z  \\\n",
       "count         9233.000000         9233.000000         9233.000000   \n",
       "mean             1.308013            0.817656            0.685013   \n",
       "std              1.361990            0.742803            0.634053   \n",
       "min              0.013632            0.019417            0.025974   \n",
       "25%              0.089610            0.119609            0.113962   \n",
       "50%              0.248422            0.322917            0.298298   \n",
       "75%              2.370136            1.482731            1.189677   \n",
       "max              5.491817            3.198097            3.203614   \n",
       "\n",
       "       f_body_acc_mad()_X  f_body_acc_mad()_Y  f_body_acc_mad()_Z  \\\n",
       "count         9233.000000         9233.000000         9233.000000   \n",
       "mean             0.339979            0.268215            0.242385   \n",
       "std              0.378119            0.288406            0.262074   \n",
       "min              0.006711            0.006004            0.011886   \n",
       "25%              0.018544            0.020268            0.029038   \n",
       "50%              0.043612            0.047309            0.051015   \n",
       "75%              0.624989            0.497541            0.430384   \n",
       "max              1.795844            1.360118            1.441752   \n",
       "\n",
       "       f_body_acc_max()_X  \n",
       "count         9233.000000  \n",
       "mean             8.370037  \n",
       "std              8.940847  \n",
       "min              0.051908  \n",
       "25%              0.654762  \n",
       "50%              1.944103  \n",
       "75%             14.904714  \n",
       "max             38.437992  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Number of windows per user and per each activity:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User 1</th>\n",
       "      <td>95</td>\n",
       "      <td>53</td>\n",
       "      <td>49</td>\n",
       "      <td>44</td>\n",
       "      <td>53</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 2</th>\n",
       "      <td>59</td>\n",
       "      <td>47</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "      <td>48</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 3</th>\n",
       "      <td>58</td>\n",
       "      <td>59</td>\n",
       "      <td>49</td>\n",
       "      <td>34</td>\n",
       "      <td>40</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 4</th>\n",
       "      <td>60</td>\n",
       "      <td>52</td>\n",
       "      <td>45</td>\n",
       "      <td>33</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 5</th>\n",
       "      <td>56</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>27</td>\n",
       "      <td>33</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 6</th>\n",
       "      <td>56</td>\n",
       "      <td>39</td>\n",
       "      <td>34</td>\n",
       "      <td>29</td>\n",
       "      <td>42</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 7</th>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "      <td>47</td>\n",
       "      <td>33</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 8</th>\n",
       "      <td>47</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>39</td>\n",
       "      <td>50</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 9</th>\n",
       "      <td>52</td>\n",
       "      <td>49</td>\n",
       "      <td>42</td>\n",
       "      <td>33</td>\n",
       "      <td>38</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 10</th>\n",
       "      <td>53</td>\n",
       "      <td>46</td>\n",
       "      <td>38</td>\n",
       "      <td>47</td>\n",
       "      <td>34</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 11</th>\n",
       "      <td>59</td>\n",
       "      <td>54</td>\n",
       "      <td>46</td>\n",
       "      <td>41</td>\n",
       "      <td>47</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 12</th>\n",
       "      <td>50</td>\n",
       "      <td>52</td>\n",
       "      <td>44</td>\n",
       "      <td>37</td>\n",
       "      <td>46</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 13</th>\n",
       "      <td>57</td>\n",
       "      <td>55</td>\n",
       "      <td>47</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 14</th>\n",
       "      <td>59</td>\n",
       "      <td>34</td>\n",
       "      <td>38</td>\n",
       "      <td>43</td>\n",
       "      <td>49</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 15</th>\n",
       "      <td>53</td>\n",
       "      <td>48</td>\n",
       "      <td>42</td>\n",
       "      <td>54</td>\n",
       "      <td>47</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 16</th>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>47</td>\n",
       "      <td>62</td>\n",
       "      <td>77</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 17</th>\n",
       "      <td>61</td>\n",
       "      <td>48</td>\n",
       "      <td>47</td>\n",
       "      <td>59</td>\n",
       "      <td>77</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 18</th>\n",
       "      <td>56</td>\n",
       "      <td>57</td>\n",
       "      <td>55</td>\n",
       "      <td>57</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 19</th>\n",
       "      <td>31</td>\n",
       "      <td>26</td>\n",
       "      <td>15</td>\n",
       "      <td>66</td>\n",
       "      <td>68</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 20</th>\n",
       "      <td>38</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "      <td>44</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 21</th>\n",
       "      <td>52</td>\n",
       "      <td>46</td>\n",
       "      <td>45</td>\n",
       "      <td>78</td>\n",
       "      <td>79</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 22</th>\n",
       "      <td>46</td>\n",
       "      <td>32</td>\n",
       "      <td>36</td>\n",
       "      <td>47</td>\n",
       "      <td>52</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 23</th>\n",
       "      <td>37</td>\n",
       "      <td>51</td>\n",
       "      <td>38</td>\n",
       "      <td>55</td>\n",
       "      <td>60</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 24</th>\n",
       "      <td>58</td>\n",
       "      <td>59</td>\n",
       "      <td>54</td>\n",
       "      <td>67</td>\n",
       "      <td>60</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 25</th>\n",
       "      <td>74</td>\n",
       "      <td>65</td>\n",
       "      <td>58</td>\n",
       "      <td>63</td>\n",
       "      <td>70</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 26</th>\n",
       "      <td>59</td>\n",
       "      <td>55</td>\n",
       "      <td>50</td>\n",
       "      <td>74</td>\n",
       "      <td>73</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 27</th>\n",
       "      <td>57</td>\n",
       "      <td>51</td>\n",
       "      <td>44</td>\n",
       "      <td>67</td>\n",
       "      <td>75</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 28</th>\n",
       "      <td>54</td>\n",
       "      <td>51</td>\n",
       "      <td>46</td>\n",
       "      <td>53</td>\n",
       "      <td>59</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 29</th>\n",
       "      <td>53</td>\n",
       "      <td>49</td>\n",
       "      <td>48</td>\n",
       "      <td>57</td>\n",
       "      <td>67</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 30</th>\n",
       "      <td>65</td>\n",
       "      <td>64</td>\n",
       "      <td>62</td>\n",
       "      <td>58</td>\n",
       "      <td>46</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  \\\n",
       "User 1           95          53          49          44          53   \n",
       "User 2           59          47          45          43          48   \n",
       "User 3           58          59          49          34          40   \n",
       "User 4           60          52          45          33          43   \n",
       "User 5           56          47          47          27          33   \n",
       "User 6           56          39          34          29          42   \n",
       "User 7           49          51          47          33          45   \n",
       "User 8           47          29          29          39          50   \n",
       "User 9           52          49          42          33          38   \n",
       "User 10          53          46          38          47          34   \n",
       "User 11          59          54          46          41          47   \n",
       "User 12          50          52          44          37          46   \n",
       "User 13          57          55          47          45          49   \n",
       "User 14          59          34          38          43          49   \n",
       "User 15          53          48          42          54          47   \n",
       "User 16          51          51          47          62          77   \n",
       "User 17          61          48          47          59          77   \n",
       "User 18          56          57          55          57          77   \n",
       "User 19          31          26          15          66          68   \n",
       "User 20          38          45          45          50          44   \n",
       "User 21          52          46          45          78          79   \n",
       "User 22          46          32          36          47          52   \n",
       "User 23          37          51          38          55          60   \n",
       "User 24          58          59          54          67          60   \n",
       "User 25          74          65          58          63          70   \n",
       "User 26          59          55          50          74          73   \n",
       "User 27          57          51          44          67          75   \n",
       "User 28          54          51          46          53          59   \n",
       "User 29          53          49          48          57          67   \n",
       "User 30          65          64          62          58          46   \n",
       "\n",
       "         Activity 6  \n",
       "User 1           37  \n",
       "User 2           45  \n",
       "User 3           53  \n",
       "User 4           43  \n",
       "User 5           43  \n",
       "User 6           39  \n",
       "User 7           43  \n",
       "User 8           42  \n",
       "User 9           27  \n",
       "User 10          43  \n",
       "User 11          50  \n",
       "User 12          44  \n",
       "User 13          56  \n",
       "User 14          34  \n",
       "User 15          59  \n",
       "User 16          67  \n",
       "User 17          60  \n",
       "User 18          65  \n",
       "User 19          77  \n",
       "User 20          62  \n",
       "User 21          82  \n",
       "User 22          58  \n",
       "User 23          66  \n",
       "User 24          66  \n",
       "User 25          44  \n",
       "User 26          72  \n",
       "User 27          70  \n",
       "User 28          63  \n",
       "User 29          68  \n",
       "User 30          60  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Statistics of table above:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>55.166667</td>\n",
       "      <td>48.833333</td>\n",
       "      <td>44.400000</td>\n",
       "      <td>49.833333</td>\n",
       "      <td>54.933333</td>\n",
       "      <td>54.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.228300</td>\n",
       "      <td>9.251592</td>\n",
       "      <td>8.791061</td>\n",
       "      <td>13.696421</td>\n",
       "      <td>14.115126</td>\n",
       "      <td>13.7555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>27.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>51.250000</td>\n",
       "      <td>46.250000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>39.500000</td>\n",
       "      <td>45.250000</td>\n",
       "      <td>43.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>45.500000</td>\n",
       "      <td>48.500000</td>\n",
       "      <td>49.500000</td>\n",
       "      <td>57.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>59.000000</td>\n",
       "      <td>53.750000</td>\n",
       "      <td>47.750000</td>\n",
       "      <td>58.750000</td>\n",
       "      <td>67.750000</td>\n",
       "      <td>65.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>82.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  Activity 6\n",
       "count   30.000000   30.000000   30.000000   30.000000   30.000000     30.0000\n",
       "mean    55.166667   48.833333   44.400000   49.833333   54.933333     54.6000\n",
       "std     11.228300    9.251592    8.791061   13.696421   14.115126     13.7555\n",
       "min     31.000000   26.000000   15.000000   27.000000   33.000000     27.0000\n",
       "25%     51.250000   46.250000   42.000000   39.500000   45.250000     43.0000\n",
       "50%     56.000000   51.000000   45.500000   48.500000   49.500000     57.0000\n",
       "75%     59.000000   53.750000   47.750000   58.750000   67.750000     65.7500\n",
       "max     95.000000   65.000000   62.000000   78.000000   79.000000     82.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "_____ The weights of each activity _____\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Weights</th>\n",
       "      <td>0.179248</td>\n",
       "      <td>0.15867</td>\n",
       "      <td>0.144265</td>\n",
       "      <td>0.161919</td>\n",
       "      <td>0.17849</td>\n",
       "      <td>0.177407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  \\\n",
       "Weights    0.179248     0.15867    0.144265    0.161919     0.17849   \n",
       "\n",
       "         Activity 6  \n",
       "Weights    0.177407  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# apply extract drop outliers to dataset type I\n",
    "clean_Dataset_type_I= extract_drop_outliers(Dataset_type_I,100,1)# store the clean dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "_______________________________ Original Data Frame info...____________________________________\n",
      "Number of rows in the original dataframe Dataset type II: 12637\n",
      "\n",
      "\n",
      "_____ The weights of each activity _____\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\AppData\\Local\\Temp\\ipykernel_4080\\2017075652.py:44: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  clean_Df=Df.drop(indexs_droped,0,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "      <th>Activity 7</th>\n",
       "      <th>Activity 8</th>\n",
       "      <th>Activity 9</th>\n",
       "      <th>Activity 10</th>\n",
       "      <th>Activity 11</th>\n",
       "      <th>Activity 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Weights</th>\n",
       "      <td>0.151223</td>\n",
       "      <td>0.139432</td>\n",
       "      <td>0.133418</td>\n",
       "      <td>0.156683</td>\n",
       "      <td>0.168632</td>\n",
       "      <td>0.169344</td>\n",
       "      <td>0.012424</td>\n",
       "      <td>0.008863</td>\n",
       "      <td>0.014956</td>\n",
       "      <td>0.014323</td>\n",
       "      <td>0.017805</td>\n",
       "      <td>0.012899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  \\\n",
       "Weights    0.151223    0.139432    0.133418    0.156683    0.168632   \n",
       "\n",
       "         Activity 6  Activity 7  Activity 8  Activity 9  Activity 10  \\\n",
       "Weights    0.169344    0.012424    0.008863    0.014956     0.014323   \n",
       "\n",
       "         Activity 11  Activity 12  \n",
       "Weights     0.017805     0.012899  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "________________________________ Outliers info...________________________________________________\n",
      "A row is considered as outlier if the number of its outliers exceeds: 100\n",
      "Number of rows droped : 1475\n",
      "\n",
      "\n",
      "Outliers ofDataset type II has a shape of: 1475 rows and 642 columns\n",
      "\n",
      "\n",
      "\n",
      "Number of windows per user and per each activity:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "      <th>Activity 7</th>\n",
       "      <th>Activity 8</th>\n",
       "      <th>Activity 9</th>\n",
       "      <th>Activity 10</th>\n",
       "      <th>Activity 11</th>\n",
       "      <th>Activity 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User 1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 6</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 7</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 8</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>11</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 14</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 19</th>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 20</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 21</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 22</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 23</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  \\\n",
       "User 1            0           0           0           8           6   \n",
       "User 2            0           3           2           7          13   \n",
       "User 3            0           0           0          18          26   \n",
       "User 4            0           0           0          17          14   \n",
       "User 5            0           0           0          15          22   \n",
       "User 6            2          16          21          21          17   \n",
       "User 7            5           0           0          11          11   \n",
       "User 8            1          14          10          12           9   \n",
       "User 9            0           0           0          21          11   \n",
       "User 10           0           1           0          14          15   \n",
       "User 11           0           0           0          13           5   \n",
       "User 12           0           0           2          16          16   \n",
       "User 13           0           0           0           9          12   \n",
       "User 14           0          16           8          10          14   \n",
       "User 15           0           0           0           8          10   \n",
       "User 16           0           0           0          11           5   \n",
       "User 17           0           0           0           7           9   \n",
       "User 18           0           0           0           7           8   \n",
       "User 19          26          19          32           8          10   \n",
       "User 20          13           7           0          15          26   \n",
       "User 21           0           1           0          10          14   \n",
       "User 22           0           8           0          16          14   \n",
       "User 23          27           1          20          12          13   \n",
       "User 24           0           0           0           9          13   \n",
       "User 25           0           0           0           6           8   \n",
       "User 26           0           0           0           9           8   \n",
       "User 27           0           0           0           9           7   \n",
       "User 28           0           0           0          22          21   \n",
       "User 29           0           0           0           7           5   \n",
       "User 30           0           0           0          11          17   \n",
       "\n",
       "         Activity 6  Activity 7  Activity 8  Activity 9  Activity 10  \\\n",
       "User 1           17           0           0           0            0   \n",
       "User 2           10           2           0           0            0   \n",
       "User 3           12           0           0           0            0   \n",
       "User 4           14           0           0           0            2   \n",
       "User 5            8           0           0           0            0   \n",
       "User 6           19           3           2           0            4   \n",
       "User 7           12           0           0           0            0   \n",
       "User 8           17           0           2           0            0   \n",
       "User 9           28           0           0           0            0   \n",
       "User 10          15           2           0           4            4   \n",
       "User 11          10           0           1           0            0   \n",
       "User 12          19           1           1           0            0   \n",
       "User 13          11           0           0           0            0   \n",
       "User 14          12           0           1           0            0   \n",
       "User 15          19           1           0           0            0   \n",
       "User 16           6           0           0           0            0   \n",
       "User 17          18           0           0           0            0   \n",
       "User 18           9           0           0           0            0   \n",
       "User 19           8           0           0           1            0   \n",
       "User 20          10           0           0           0            0   \n",
       "User 21          12           0           0           0            0   \n",
       "User 22          19           0           0           0            0   \n",
       "User 23           8           3           3           4            0   \n",
       "User 24          11           0           0           1            0   \n",
       "User 25          25           0           0           0            0   \n",
       "User 26           6           0           0           0            0   \n",
       "User 27          11           0           0           0            0   \n",
       "User 28          19           0           0           0            0   \n",
       "User 29           6           0           0           0            0   \n",
       "User 30          17           0           0           2            0   \n",
       "\n",
       "         Activity 11  Activity 12  \n",
       "User 1             0            0  \n",
       "User 2             0            0  \n",
       "User 3             2            0  \n",
       "User 4             0            0  \n",
       "User 5             0            3  \n",
       "User 6             3            3  \n",
       "User 7             0            3  \n",
       "User 8             2            1  \n",
       "User 9             1            3  \n",
       "User 10            2            1  \n",
       "User 11            0            0  \n",
       "User 12            0            0  \n",
       "User 13            0            0  \n",
       "User 14            0            0  \n",
       "User 15            0            0  \n",
       "User 16            0            0  \n",
       "User 17            0            0  \n",
       "User 18            0            0  \n",
       "User 19            0            0  \n",
       "User 20            0            1  \n",
       "User 21            0            1  \n",
       "User 22            1            0  \n",
       "User 23            0            0  \n",
       "User 24            0            0  \n",
       "User 25            0            0  \n",
       "User 26            0            0  \n",
       "User 27            0            0  \n",
       "User 28            0            0  \n",
       "User 29            0            0  \n",
       "User 30            3            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Statistics of table above:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "      <th>Activity 7</th>\n",
       "      <th>Activity 8</th>\n",
       "      <th>Activity 9</th>\n",
       "      <th>Activity 10</th>\n",
       "      <th>Activity 11</th>\n",
       "      <th>Activity 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.466667</td>\n",
       "      <td>2.866667</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>11.966667</td>\n",
       "      <td>12.633333</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.001149</td>\n",
       "      <td>5.715878</td>\n",
       "      <td>7.737430</td>\n",
       "      <td>4.582450</td>\n",
       "      <td>5.690181</td>\n",
       "      <td>5.562188</td>\n",
       "      <td>0.894427</td>\n",
       "      <td>0.758098</td>\n",
       "      <td>1.069966</td>\n",
       "      <td>1.061337</td>\n",
       "      <td>0.937102</td>\n",
       "      <td>1.041661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>8.250000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>14.750000</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  Activity 6  \\\n",
       "count   30.000000   30.000000   30.000000   30.000000   30.000000   30.000000   \n",
       "mean     2.466667    2.866667    3.166667   11.966667   12.633333   13.600000   \n",
       "std      7.001149    5.715878    7.737430    4.582450    5.690181    5.562188   \n",
       "min      0.000000    0.000000    0.000000    6.000000    5.000000    6.000000   \n",
       "25%      0.000000    0.000000    0.000000    8.250000    8.250000   10.000000   \n",
       "50%      0.000000    0.000000    0.000000   11.000000   12.500000   12.000000   \n",
       "75%      0.000000    1.000000    0.000000   15.000000   14.750000   17.750000   \n",
       "max     27.000000   19.000000   32.000000   22.000000   26.000000   28.000000   \n",
       "\n",
       "       Activity 7  Activity 8  Activity 9  Activity 10  Activity 11  \\\n",
       "count   30.000000   30.000000   30.000000    30.000000    30.000000   \n",
       "mean     0.400000    0.333333    0.400000     0.333333     0.466667   \n",
       "std      0.894427    0.758098    1.069966     1.061337     0.937102   \n",
       "min      0.000000    0.000000    0.000000     0.000000     0.000000   \n",
       "25%      0.000000    0.000000    0.000000     0.000000     0.000000   \n",
       "50%      0.000000    0.000000    0.000000     0.000000     0.000000   \n",
       "75%      0.000000    0.000000    0.000000     0.000000     0.000000   \n",
       "max      3.000000    3.000000    4.000000     4.000000     3.000000   \n",
       "\n",
       "       Activity 12  \n",
       "count    30.000000  \n",
       "mean      0.533333  \n",
       "std       1.041661  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.750000  \n",
       "max       3.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "_____ The weights of each activity _____\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "      <th>Activity 7</th>\n",
       "      <th>Activity 8</th>\n",
       "      <th>Activity 9</th>\n",
       "      <th>Activity 10</th>\n",
       "      <th>Activity 11</th>\n",
       "      <th>Activity 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Weights</th>\n",
       "      <td>0.050169</td>\n",
       "      <td>0.058305</td>\n",
       "      <td>0.064407</td>\n",
       "      <td>0.24339</td>\n",
       "      <td>0.256949</td>\n",
       "      <td>0.27661</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.00678</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>0.00678</td>\n",
       "      <td>0.009492</td>\n",
       "      <td>0.010847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  \\\n",
       "Weights    0.050169    0.058305    0.064407     0.24339    0.256949   \n",
       "\n",
       "         Activity 6  Activity 7  Activity 8  Activity 9  Activity 10  \\\n",
       "Weights     0.27661    0.008136     0.00678    0.008136      0.00678   \n",
       "\n",
       "         Activity 11  Activity 12  \n",
       "Weights     0.009492     0.010847  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "________________________________ Cleaned+Dataset type II Dataframe info...________________________________________\n",
      "Number of rows in the clean dataframe Dataset type II: 11162\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Dataset type II has a shape of: 11162 rows and 642 columns\n",
      "\n",
      "\n",
      "\n",
      "The first 3 rows of Dataset type II :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_body_acc_mean()_X</th>\n",
       "      <th>t_body_acc_mean()_Y</th>\n",
       "      <th>t_body_acc_mean()_Z</th>\n",
       "      <th>t_body_acc_std()_X</th>\n",
       "      <th>t_body_acc_std()_Y</th>\n",
       "      <th>t_body_acc_std()_Z</th>\n",
       "      <th>t_body_acc_mad()_X</th>\n",
       "      <th>t_body_acc_mad()_Y</th>\n",
       "      <th>t_body_acc_mad()_Z</th>\n",
       "      <th>t_body_acc_max()_X</th>\n",
       "      <th>...</th>\n",
       "      <th>f_body_gyro_Jerk_Mag_kurtosis()</th>\n",
       "      <th>angle0()</th>\n",
       "      <th>angle1()</th>\n",
       "      <th>angle2()</th>\n",
       "      <th>angle3()</th>\n",
       "      <th>angle4()</th>\n",
       "      <th>angle5()</th>\n",
       "      <th>angle6()</th>\n",
       "      <th>activity_Id</th>\n",
       "      <th>user_Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.004441</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>0.013983</td>\n",
       "      <td>0.027372</td>\n",
       "      <td>0.004725</td>\n",
       "      <td>0.019132</td>\n",
       "      <td>0.025280</td>\n",
       "      <td>0.010209</td>\n",
       "      <td>...</td>\n",
       "      <td>104.954731</td>\n",
       "      <td>1.070749</td>\n",
       "      <td>1.431913</td>\n",
       "      <td>2.116867</td>\n",
       "      <td>1.431211</td>\n",
       "      <td>0.152888</td>\n",
       "      <td>1.692169</td>\n",
       "      <td>1.478284</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000713</td>\n",
       "      <td>-0.003098</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.004491</td>\n",
       "      <td>0.012449</td>\n",
       "      <td>0.022660</td>\n",
       "      <td>0.004168</td>\n",
       "      <td>0.014039</td>\n",
       "      <td>0.022765</td>\n",
       "      <td>0.009030</td>\n",
       "      <td>...</td>\n",
       "      <td>109.749747</td>\n",
       "      <td>1.652580</td>\n",
       "      <td>1.856253</td>\n",
       "      <td>1.210803</td>\n",
       "      <td>1.753009</td>\n",
       "      <td>0.149532</td>\n",
       "      <td>1.687352</td>\n",
       "      <td>1.477548</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000301</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>-0.004280</td>\n",
       "      <td>0.004866</td>\n",
       "      <td>0.009352</td>\n",
       "      <td>0.016821</td>\n",
       "      <td>0.005255</td>\n",
       "      <td>0.010157</td>\n",
       "      <td>0.020681</td>\n",
       "      <td>0.011261</td>\n",
       "      <td>...</td>\n",
       "      <td>110.445137</td>\n",
       "      <td>1.776612</td>\n",
       "      <td>1.159471</td>\n",
       "      <td>1.763958</td>\n",
       "      <td>2.682216</td>\n",
       "      <td>0.157004</td>\n",
       "      <td>1.696158</td>\n",
       "      <td>1.476770</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 642 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   t_body_acc_mean()_X  t_body_acc_mean()_Y  t_body_acc_mean()_Z  \\\n",
       "0             0.002012             0.000431             0.004441   \n",
       "1            -0.000713            -0.003098             0.000823   \n",
       "2            -0.000301             0.004025            -0.004280   \n",
       "\n",
       "   t_body_acc_std()_X  t_body_acc_std()_Y  t_body_acc_std()_Z  \\\n",
       "0            0.004025            0.013983            0.027372   \n",
       "1            0.004491            0.012449            0.022660   \n",
       "2            0.004866            0.009352            0.016821   \n",
       "\n",
       "   t_body_acc_mad()_X  t_body_acc_mad()_Y  t_body_acc_mad()_Z  \\\n",
       "0            0.004725            0.019132            0.025280   \n",
       "1            0.004168            0.014039            0.022765   \n",
       "2            0.005255            0.010157            0.020681   \n",
       "\n",
       "   t_body_acc_max()_X  ...  f_body_gyro_Jerk_Mag_kurtosis()  angle0()  \\\n",
       "0            0.010209  ...                       104.954731  1.070749   \n",
       "1            0.009030  ...                       109.749747  1.652580   \n",
       "2            0.011261  ...                       110.445137  1.776612   \n",
       "\n",
       "   angle1()  angle2()  angle3()  angle4()  angle5()  angle6()  activity_Id  \\\n",
       "0  1.431913  2.116867  1.431211  0.152888  1.692169  1.478284          5.0   \n",
       "1  1.856253  1.210803  1.753009  0.149532  1.687352  1.477548          5.0   \n",
       "2  1.159471  1.763958  2.682216  0.157004  1.696158  1.476770          5.0   \n",
       "\n",
       "   user_Id  \n",
       "0      1.0  \n",
       "1      1.0  \n",
       "2      1.0  \n",
       "\n",
       "[3 rows x 642 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "rows 500, 501, 502 of Dataset type II :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_body_acc_mean()_X</th>\n",
       "      <th>t_body_acc_mean()_Y</th>\n",
       "      <th>t_body_acc_mean()_Z</th>\n",
       "      <th>t_body_acc_std()_X</th>\n",
       "      <th>t_body_acc_std()_Y</th>\n",
       "      <th>t_body_acc_std()_Z</th>\n",
       "      <th>t_body_acc_mad()_X</th>\n",
       "      <th>t_body_acc_mad()_Y</th>\n",
       "      <th>t_body_acc_mad()_Z</th>\n",
       "      <th>t_body_acc_max()_X</th>\n",
       "      <th>...</th>\n",
       "      <th>f_body_gyro_Jerk_Mag_kurtosis()</th>\n",
       "      <th>angle0()</th>\n",
       "      <th>angle1()</th>\n",
       "      <th>angle2()</th>\n",
       "      <th>angle3()</th>\n",
       "      <th>angle4()</th>\n",
       "      <th>angle5()</th>\n",
       "      <th>angle6()</th>\n",
       "      <th>activity_Id</th>\n",
       "      <th>user_Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>-0.012305</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>-0.007489</td>\n",
       "      <td>0.178805</td>\n",
       "      <td>0.136779</td>\n",
       "      <td>0.103982</td>\n",
       "      <td>0.156816</td>\n",
       "      <td>0.121842</td>\n",
       "      <td>0.136083</td>\n",
       "      <td>0.431281</td>\n",
       "      <td>...</td>\n",
       "      <td>95.271875</td>\n",
       "      <td>2.540275</td>\n",
       "      <td>2.259276</td>\n",
       "      <td>0.335739</td>\n",
       "      <td>1.913493</td>\n",
       "      <td>0.324945</td>\n",
       "      <td>1.895142</td>\n",
       "      <td>1.551758</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>-0.009069</td>\n",
       "      <td>0.005967</td>\n",
       "      <td>-0.003001</td>\n",
       "      <td>0.187432</td>\n",
       "      <td>0.135485</td>\n",
       "      <td>0.096906</td>\n",
       "      <td>0.156248</td>\n",
       "      <td>0.114948</td>\n",
       "      <td>0.130979</td>\n",
       "      <td>0.431281</td>\n",
       "      <td>...</td>\n",
       "      <td>99.060916</td>\n",
       "      <td>2.784486</td>\n",
       "      <td>1.514972</td>\n",
       "      <td>0.599218</td>\n",
       "      <td>1.077478</td>\n",
       "      <td>0.324397</td>\n",
       "      <td>1.894571</td>\n",
       "      <td>1.551406</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>0.006119</td>\n",
       "      <td>0.010412</td>\n",
       "      <td>0.003517</td>\n",
       "      <td>0.170990</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>0.103101</td>\n",
       "      <td>0.149613</td>\n",
       "      <td>0.103500</td>\n",
       "      <td>0.111266</td>\n",
       "      <td>0.375686</td>\n",
       "      <td>...</td>\n",
       "      <td>95.542622</td>\n",
       "      <td>1.359307</td>\n",
       "      <td>0.373130</td>\n",
       "      <td>0.789207</td>\n",
       "      <td>2.249128</td>\n",
       "      <td>0.316433</td>\n",
       "      <td>1.886737</td>\n",
       "      <td>1.553741</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 642 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     t_body_acc_mean()_X  t_body_acc_mean()_Y  t_body_acc_mean()_Z  \\\n",
       "551            -0.012305             0.000239            -0.007489   \n",
       "552            -0.009069             0.005967            -0.003001   \n",
       "553             0.006119             0.010412             0.003517   \n",
       "\n",
       "     t_body_acc_std()_X  t_body_acc_std()_Y  t_body_acc_std()_Z  \\\n",
       "551            0.178805            0.136779            0.103982   \n",
       "552            0.187432            0.135485            0.096906   \n",
       "553            0.170990            0.140625            0.103101   \n",
       "\n",
       "     t_body_acc_mad()_X  t_body_acc_mad()_Y  t_body_acc_mad()_Z  \\\n",
       "551            0.156816            0.121842            0.136083   \n",
       "552            0.156248            0.114948            0.130979   \n",
       "553            0.149613            0.103500            0.111266   \n",
       "\n",
       "     t_body_acc_max()_X  ...  f_body_gyro_Jerk_Mag_kurtosis()  angle0()  \\\n",
       "551            0.431281  ...                        95.271875  2.540275   \n",
       "552            0.431281  ...                        99.060916  2.784486   \n",
       "553            0.375686  ...                        95.542622  1.359307   \n",
       "\n",
       "     angle1()  angle2()  angle3()  angle4()  angle5()  angle6()  activity_Id  \\\n",
       "551  2.259276  0.335739  1.913493  0.324945  1.895142  1.551758          1.0   \n",
       "552  1.514972  0.599218  1.077478  0.324397  1.894571  1.551406          1.0   \n",
       "553  0.373130  0.789207  2.249128  0.316433  1.886737  1.553741          1.0   \n",
       "\n",
       "     user_Id  \n",
       "551      2.0  \n",
       "552      2.0  \n",
       "553      2.0  \n",
       "\n",
       "[3 rows x 642 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Description of the 10 first features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_body_acc_mean()_X</th>\n",
       "      <th>t_body_acc_mean()_Y</th>\n",
       "      <th>t_body_acc_mean()_Z</th>\n",
       "      <th>t_body_acc_std()_X</th>\n",
       "      <th>t_body_acc_std()_Y</th>\n",
       "      <th>t_body_acc_std()_Z</th>\n",
       "      <th>t_body_acc_mad()_X</th>\n",
       "      <th>t_body_acc_mad()_Y</th>\n",
       "      <th>t_body_acc_mad()_Z</th>\n",
       "      <th>t_body_acc_max()_X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000100</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>0.133528</td>\n",
       "      <td>0.091768</td>\n",
       "      <td>0.076617</td>\n",
       "      <td>0.121742</td>\n",
       "      <td>0.082952</td>\n",
       "      <td>0.070394</td>\n",
       "      <td>0.335502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.009133</td>\n",
       "      <td>0.007369</td>\n",
       "      <td>0.007432</td>\n",
       "      <td>0.132705</td>\n",
       "      <td>0.077968</td>\n",
       "      <td>0.065510</td>\n",
       "      <td>0.123591</td>\n",
       "      <td>0.070053</td>\n",
       "      <td>0.058752</td>\n",
       "      <td>0.337439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.046247</td>\n",
       "      <td>-0.053277</td>\n",
       "      <td>-0.042451</td>\n",
       "      <td>0.001815</td>\n",
       "      <td>0.002371</td>\n",
       "      <td>0.003535</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>0.002615</td>\n",
       "      <td>0.003151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.003672</td>\n",
       "      <td>-0.003622</td>\n",
       "      <td>-0.003529</td>\n",
       "      <td>0.009718</td>\n",
       "      <td>0.012898</td>\n",
       "      <td>0.012353</td>\n",
       "      <td>0.010759</td>\n",
       "      <td>0.014022</td>\n",
       "      <td>0.013404</td>\n",
       "      <td>0.019114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.000074</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>0.093282</td>\n",
       "      <td>0.101556</td>\n",
       "      <td>0.077919</td>\n",
       "      <td>0.071413</td>\n",
       "      <td>0.082742</td>\n",
       "      <td>0.067476</td>\n",
       "      <td>0.223442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.003596</td>\n",
       "      <td>0.003441</td>\n",
       "      <td>0.237883</td>\n",
       "      <td>0.158614</td>\n",
       "      <td>0.129117</td>\n",
       "      <td>0.218726</td>\n",
       "      <td>0.141180</td>\n",
       "      <td>0.117314</td>\n",
       "      <td>0.615112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.045010</td>\n",
       "      <td>0.041782</td>\n",
       "      <td>0.044077</td>\n",
       "      <td>0.545615</td>\n",
       "      <td>0.344200</td>\n",
       "      <td>0.303396</td>\n",
       "      <td>0.632914</td>\n",
       "      <td>0.360647</td>\n",
       "      <td>0.384583</td>\n",
       "      <td>1.113230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       t_body_acc_mean()_X  t_body_acc_mean()_Y  t_body_acc_mean()_Z  \\\n",
       "count         11162.000000         11162.000000         11162.000000   \n",
       "mean             -0.000100             0.000013            -0.000031   \n",
       "std               0.009133             0.007369             0.007432   \n",
       "min              -0.046247            -0.053277            -0.042451   \n",
       "25%              -0.003672            -0.003622            -0.003529   \n",
       "50%              -0.000074             0.000021            -0.000116   \n",
       "75%               0.003510             0.003596             0.003441   \n",
       "max               0.045010             0.041782             0.044077   \n",
       "\n",
       "       t_body_acc_std()_X  t_body_acc_std()_Y  t_body_acc_std()_Z  \\\n",
       "count        11162.000000        11162.000000        11162.000000   \n",
       "mean             0.133528            0.091768            0.076617   \n",
       "std              0.132705            0.077968            0.065510   \n",
       "min              0.001815            0.002371            0.003535   \n",
       "25%              0.009718            0.012898            0.012353   \n",
       "50%              0.093282            0.101556            0.077919   \n",
       "75%              0.237883            0.158614            0.129117   \n",
       "max              0.545615            0.344200            0.303396   \n",
       "\n",
       "       t_body_acc_mad()_X  t_body_acc_mad()_Y  t_body_acc_mad()_Z  \\\n",
       "count        11162.000000        11162.000000        11162.000000   \n",
       "mean             0.121742            0.082952            0.070394   \n",
       "std              0.123591            0.070053            0.058752   \n",
       "min              0.001536            0.001921            0.002615   \n",
       "25%              0.010759            0.014022            0.013404   \n",
       "50%              0.071413            0.082742            0.067476   \n",
       "75%              0.218726            0.141180            0.117314   \n",
       "max              0.632914            0.360647            0.384583   \n",
       "\n",
       "       t_body_acc_max()_X  \n",
       "count        11162.000000  \n",
       "mean             0.335502  \n",
       "std              0.337439  \n",
       "min              0.003151  \n",
       "25%              0.019114  \n",
       "50%              0.223442  \n",
       "75%              0.615112  \n",
       "max              1.113230  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Description of the 10 first frequency features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_body_acc_mean()_X</th>\n",
       "      <th>f_body_acc_mean()_Y</th>\n",
       "      <th>f_body_acc_mean()_Z</th>\n",
       "      <th>f_body_acc_std()_X</th>\n",
       "      <th>f_body_acc_std()_Y</th>\n",
       "      <th>f_body_acc_std()_Z</th>\n",
       "      <th>f_body_acc_mad()_X</th>\n",
       "      <th>f_body_acc_mad()_Y</th>\n",
       "      <th>f_body_acc_mad()_Z</th>\n",
       "      <th>f_body_acc_max()_X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.772696</td>\n",
       "      <td>0.581905</td>\n",
       "      <td>0.472153</td>\n",
       "      <td>1.297549</td>\n",
       "      <td>0.859322</td>\n",
       "      <td>0.725643</td>\n",
       "      <td>0.339665</td>\n",
       "      <td>0.271808</td>\n",
       "      <td>0.243708</td>\n",
       "      <td>8.175407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.771309</td>\n",
       "      <td>0.522189</td>\n",
       "      <td>0.422343</td>\n",
       "      <td>1.292845</td>\n",
       "      <td>0.716430</td>\n",
       "      <td>0.616372</td>\n",
       "      <td>0.362136</td>\n",
       "      <td>0.274672</td>\n",
       "      <td>0.250152</td>\n",
       "      <td>8.443110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.015014</td>\n",
       "      <td>0.018181</td>\n",
       "      <td>0.027632</td>\n",
       "      <td>0.013632</td>\n",
       "      <td>0.019648</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>0.006759</td>\n",
       "      <td>0.011345</td>\n",
       "      <td>0.051908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.047688</td>\n",
       "      <td>0.060626</td>\n",
       "      <td>0.063985</td>\n",
       "      <td>0.102408</td>\n",
       "      <td>0.136141</td>\n",
       "      <td>0.128495</td>\n",
       "      <td>0.020321</td>\n",
       "      <td>0.022092</td>\n",
       "      <td>0.031033</td>\n",
       "      <td>0.745156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540020</td>\n",
       "      <td>0.597268</td>\n",
       "      <td>0.464441</td>\n",
       "      <td>0.889930</td>\n",
       "      <td>0.950254</td>\n",
       "      <td>0.726380</td>\n",
       "      <td>0.220190</td>\n",
       "      <td>0.200343</td>\n",
       "      <td>0.157640</td>\n",
       "      <td>4.963227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.410956</td>\n",
       "      <td>1.033533</td>\n",
       "      <td>0.819169</td>\n",
       "      <td>2.283636</td>\n",
       "      <td>1.466308</td>\n",
       "      <td>1.191119</td>\n",
       "      <td>0.597980</td>\n",
       "      <td>0.480259</td>\n",
       "      <td>0.409944</td>\n",
       "      <td>14.077887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.037541</td>\n",
       "      <td>2.311382</td>\n",
       "      <td>2.012663</td>\n",
       "      <td>5.398025</td>\n",
       "      <td>3.602431</td>\n",
       "      <td>3.043436</td>\n",
       "      <td>2.287889</td>\n",
       "      <td>1.397714</td>\n",
       "      <td>1.670929</td>\n",
       "      <td>38.571898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f_body_acc_mean()_X  f_body_acc_mean()_Y  f_body_acc_mean()_Z  \\\n",
       "count         11162.000000         11162.000000         11162.000000   \n",
       "mean              0.772696             0.581905             0.472153   \n",
       "std               0.771309             0.522189             0.422343   \n",
       "min               0.015014             0.018181             0.027632   \n",
       "25%               0.047688             0.060626             0.063985   \n",
       "50%               0.540020             0.597268             0.464441   \n",
       "75%               1.410956             1.033533             0.819169   \n",
       "max               3.037541             2.311382             2.012663   \n",
       "\n",
       "       f_body_acc_std()_X  f_body_acc_std()_Y  f_body_acc_std()_Z  \\\n",
       "count        11162.000000        11162.000000        11162.000000   \n",
       "mean             1.297549            0.859322            0.725643   \n",
       "std              1.292845            0.716430            0.616372   \n",
       "min              0.013632            0.019648            0.027300   \n",
       "25%              0.102408            0.136141            0.128495   \n",
       "50%              0.889930            0.950254            0.726380   \n",
       "75%              2.283636            1.466308            1.191119   \n",
       "max              5.398025            3.602431            3.043436   \n",
       "\n",
       "       f_body_acc_mad()_X  f_body_acc_mad()_Y  f_body_acc_mad()_Z  \\\n",
       "count        11162.000000        11162.000000        11162.000000   \n",
       "mean             0.339665            0.271808            0.243708   \n",
       "std              0.362136            0.274672            0.250152   \n",
       "min              0.006298            0.006759            0.011345   \n",
       "25%              0.020321            0.022092            0.031033   \n",
       "50%              0.220190            0.200343            0.157640   \n",
       "75%              0.597980            0.480259            0.409944   \n",
       "max              2.287889            1.397714            1.670929   \n",
       "\n",
       "       f_body_acc_max()_X  \n",
       "count        11162.000000  \n",
       "mean             8.175407  \n",
       "std              8.443110  \n",
       "min              0.051908  \n",
       "25%              0.745156  \n",
       "50%              4.963227  \n",
       "75%             14.077887  \n",
       "max             38.571898  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Number of windows per user and per each activity:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "      <th>Activity 7</th>\n",
       "      <th>Activity 8</th>\n",
       "      <th>Activity 9</th>\n",
       "      <th>Activity 10</th>\n",
       "      <th>Activity 11</th>\n",
       "      <th>Activity 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User 1</th>\n",
       "      <td>108</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>44</td>\n",
       "      <td>54</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 2</th>\n",
       "      <td>65</td>\n",
       "      <td>54</td>\n",
       "      <td>53</td>\n",
       "      <td>45</td>\n",
       "      <td>47</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 3</th>\n",
       "      <td>64</td>\n",
       "      <td>69</td>\n",
       "      <td>58</td>\n",
       "      <td>40</td>\n",
       "      <td>43</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 4</th>\n",
       "      <td>65</td>\n",
       "      <td>58</td>\n",
       "      <td>56</td>\n",
       "      <td>38</td>\n",
       "      <td>47</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 5</th>\n",
       "      <td>62</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>35</td>\n",
       "      <td>39</td>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 6</th>\n",
       "      <td>60</td>\n",
       "      <td>44</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "      <td>46</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 7</th>\n",
       "      <td>58</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>42</td>\n",
       "      <td>49</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 8</th>\n",
       "      <td>54</td>\n",
       "      <td>35</td>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 9</th>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>53</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 10</th>\n",
       "      <td>57</td>\n",
       "      <td>53</td>\n",
       "      <td>49</td>\n",
       "      <td>47</td>\n",
       "      <td>36</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 11</th>\n",
       "      <td>66</td>\n",
       "      <td>60</td>\n",
       "      <td>56</td>\n",
       "      <td>46</td>\n",
       "      <td>50</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 12</th>\n",
       "      <td>58</td>\n",
       "      <td>61</td>\n",
       "      <td>53</td>\n",
       "      <td>44</td>\n",
       "      <td>51</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 13</th>\n",
       "      <td>63</td>\n",
       "      <td>62</td>\n",
       "      <td>55</td>\n",
       "      <td>46</td>\n",
       "      <td>53</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 14</th>\n",
       "      <td>67</td>\n",
       "      <td>44</td>\n",
       "      <td>46</td>\n",
       "      <td>50</td>\n",
       "      <td>52</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 15</th>\n",
       "      <td>60</td>\n",
       "      <td>53</td>\n",
       "      <td>50</td>\n",
       "      <td>59</td>\n",
       "      <td>51</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 16</th>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>55</td>\n",
       "      <td>63</td>\n",
       "      <td>79</td>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 17</th>\n",
       "      <td>67</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>63</td>\n",
       "      <td>79</td>\n",
       "      <td>63</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 18</th>\n",
       "      <td>62</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>60</td>\n",
       "      <td>77</td>\n",
       "      <td>67</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 19</th>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>15</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>83</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 20</th>\n",
       "      <td>44</td>\n",
       "      <td>52</td>\n",
       "      <td>54</td>\n",
       "      <td>58</td>\n",
       "      <td>57</td>\n",
       "      <td>63</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 21</th>\n",
       "      <td>59</td>\n",
       "      <td>53</td>\n",
       "      <td>55</td>\n",
       "      <td>80</td>\n",
       "      <td>85</td>\n",
       "      <td>84</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 22</th>\n",
       "      <td>52</td>\n",
       "      <td>40</td>\n",
       "      <td>46</td>\n",
       "      <td>53</td>\n",
       "      <td>57</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 23</th>\n",
       "      <td>38</td>\n",
       "      <td>56</td>\n",
       "      <td>42</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 24</th>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>67</td>\n",
       "      <td>63</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 25</th>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>66</td>\n",
       "      <td>64</td>\n",
       "      <td>72</td>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 26</th>\n",
       "      <td>65</td>\n",
       "      <td>61</td>\n",
       "      <td>60</td>\n",
       "      <td>76</td>\n",
       "      <td>73</td>\n",
       "      <td>76</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 27</th>\n",
       "      <td>63</td>\n",
       "      <td>59</td>\n",
       "      <td>56</td>\n",
       "      <td>70</td>\n",
       "      <td>81</td>\n",
       "      <td>72</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 28</th>\n",
       "      <td>63</td>\n",
       "      <td>59</td>\n",
       "      <td>55</td>\n",
       "      <td>59</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 29</th>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>56</td>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "      <td>69</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 30</th>\n",
       "      <td>71</td>\n",
       "      <td>72</td>\n",
       "      <td>71</td>\n",
       "      <td>61</td>\n",
       "      <td>52</td>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  \\\n",
       "User 1          108          61          61          44          54   \n",
       "User 2           65          54          53          45          47   \n",
       "User 3           64          69          58          40          43   \n",
       "User 4           65          58          56          38          47   \n",
       "User 5           62          55          56          35          39   \n",
       "User 6           60          44          33          40          46   \n",
       "User 7           58          57          57          42          49   \n",
       "User 8           54          35          38          40          52   \n",
       "User 9           56          56          53          39          42   \n",
       "User 10          57          53          49          47          36   \n",
       "User 11          66          60          56          46          50   \n",
       "User 12          58          61          53          44          51   \n",
       "User 13          63          62          55          46          53   \n",
       "User 14          67          44          46          50          52   \n",
       "User 15          60          53          50          59          51   \n",
       "User 16          57          57          55          63          79   \n",
       "User 17          67          56          56          63          79   \n",
       "User 18          62          65          65          60          77   \n",
       "User 19          30          29          15          70          70   \n",
       "User 20          44          52          54          58          57   \n",
       "User 21          59          53          55          80          85   \n",
       "User 22          52          40          46          53          57   \n",
       "User 23          38          56          42          62          63   \n",
       "User 24          65          65          65          67          63   \n",
       "User 25          80          72          66          64          72   \n",
       "User 26          65          61          60          76          73   \n",
       "User 27          63          59          56          70          81   \n",
       "User 28          63          59          55          59          64   \n",
       "User 29          58          58          56          60          68   \n",
       "User 30          71          72          71          61          52   \n",
       "\n",
       "         Activity 6  Activity 7  Activity 8  Activity 9  Activity 10  \\\n",
       "User 1           39           5           5           6            6   \n",
       "User 2           45           3           5           6            7   \n",
       "User 3           57           5           3           6            6   \n",
       "User 4           44           6           4           7            5   \n",
       "User 5           49           7           4           8            7   \n",
       "User 6           44           3           2           5            1   \n",
       "User 7           44           2           0           7            5   \n",
       "User 8           43           4           4           4            7   \n",
       "User 9           32           4           2           5            5   \n",
       "User 10          50           2           2           1            1   \n",
       "User 11          52           6           3           6            7   \n",
       "User 12          48           5           3           5            6   \n",
       "User 13          57           7           4           6            6   \n",
       "User 14          41           6           4           7            7   \n",
       "User 15          61           3           2           7            5   \n",
       "User 16          70           4           4           6            6   \n",
       "User 17          63           5           5           8            7   \n",
       "User 18          67           8           6           7            7   \n",
       "User 19          83           6           4           4            6   \n",
       "User 20          63           6           5           9            6   \n",
       "User 21          84           5           4           7            6   \n",
       "User 22          60           5           2           4            8   \n",
       "User 23          69           2           2           2            6   \n",
       "User 24          67           5           2           7            6   \n",
       "User 25          55           7           5           6            9   \n",
       "User 26          76           5           5           6            5   \n",
       "User 27          72           6           0           6            5   \n",
       "User 28          65           6           2           6            0   \n",
       "User 29          69           4           4           8            7   \n",
       "User 30          63           3           5           5            6   \n",
       "\n",
       "         Activity 11  Activity 12  \n",
       "User 1             9            6  \n",
       "User 2            10            5  \n",
       "User 3             5            5  \n",
       "User 4            10            5  \n",
       "User 5            11            2  \n",
       "User 6             6            4  \n",
       "User 7             6            2  \n",
       "User 8             4            2  \n",
       "User 9             6            2  \n",
       "User 10            4            1  \n",
       "User 11            6            5  \n",
       "User 12            7            7  \n",
       "User 13            6            7  \n",
       "User 14           10            8  \n",
       "User 15            7            6  \n",
       "User 16            7            4  \n",
       "User 17            8            6  \n",
       "User 18            8            6  \n",
       "User 19            9            4  \n",
       "User 20           12            4  \n",
       "User 21           10            5  \n",
       "User 22            3            4  \n",
       "User 23            8            6  \n",
       "User 24           12            8  \n",
       "User 25            7            8  \n",
       "User 26            6            7  \n",
       "User 27            5            4  \n",
       "User 28            0            5  \n",
       "User 29            6            5  \n",
       "User 30            3            4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Statistics of table above:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "      <th>Activity 7</th>\n",
       "      <th>Activity 8</th>\n",
       "      <th>Activity 9</th>\n",
       "      <th>Activity 10</th>\n",
       "      <th>Activity 11</th>\n",
       "      <th>Activity 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>61.233333</td>\n",
       "      <td>55.866667</td>\n",
       "      <td>53.033333</td>\n",
       "      <td>54.033333</td>\n",
       "      <td>58.400000</td>\n",
       "      <td>57.733333</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>7.033333</td>\n",
       "      <td>4.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.934006</td>\n",
       "      <td>9.754692</td>\n",
       "      <td>10.697996</td>\n",
       "      <td>12.321787</td>\n",
       "      <td>13.586504</td>\n",
       "      <td>13.266326</td>\n",
       "      <td>1.599210</td>\n",
       "      <td>1.522249</td>\n",
       "      <td>1.709003</td>\n",
       "      <td>1.950243</td>\n",
       "      <td>2.797577</td>\n",
       "      <td>1.881855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>57.250000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>50.750000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>49.250000</td>\n",
       "      <td>45.750000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>53.500000</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>65.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>56.750000</td>\n",
       "      <td>62.750000</td>\n",
       "      <td>69.500000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>108.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  Activity 6  \\\n",
       "count   30.000000   30.000000   30.000000   30.000000   30.000000   30.000000   \n",
       "mean    61.233333   55.866667   53.033333   54.033333   58.400000   57.733333   \n",
       "std     12.934006    9.754692   10.697996   12.321787   13.586504   13.266326   \n",
       "min     30.000000   29.000000   15.000000   35.000000   36.000000   32.000000   \n",
       "25%     57.250000   53.000000   50.750000   44.000000   49.250000   45.750000   \n",
       "50%     62.000000   57.000000   55.000000   55.500000   53.500000   58.500000   \n",
       "75%     65.000000   61.000000   56.750000   62.750000   69.500000   67.000000   \n",
       "max    108.000000   72.000000   71.000000   80.000000   85.000000   84.000000   \n",
       "\n",
       "       Activity 7  Activity 8  Activity 9  Activity 10  Activity 11  \\\n",
       "count   30.000000   30.000000   30.000000    30.000000    30.000000   \n",
       "mean     4.833333    3.400000    5.900000     5.700000     7.033333   \n",
       "std      1.599210    1.522249    1.709003     1.950243     2.797577   \n",
       "min      2.000000    0.000000    1.000000     0.000000     0.000000   \n",
       "25%      4.000000    2.000000    5.000000     5.000000     6.000000   \n",
       "50%      5.000000    4.000000    6.000000     6.000000     7.000000   \n",
       "75%      6.000000    4.750000    7.000000     7.000000     9.000000   \n",
       "max      8.000000    6.000000    9.000000     9.000000    12.000000   \n",
       "\n",
       "       Activity 12  \n",
       "count    30.000000  \n",
       "mean      4.900000  \n",
       "std       1.881855  \n",
       "min       1.000000  \n",
       "25%       4.000000  \n",
       "50%       5.000000  \n",
       "75%       6.000000  \n",
       "max       8.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "_____ The weights of each activity _____\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "      <th>Activity 7</th>\n",
       "      <th>Activity 8</th>\n",
       "      <th>Activity 9</th>\n",
       "      <th>Activity 10</th>\n",
       "      <th>Activity 11</th>\n",
       "      <th>Activity 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Weights</th>\n",
       "      <td>0.164576</td>\n",
       "      <td>0.150152</td>\n",
       "      <td>0.142537</td>\n",
       "      <td>0.145225</td>\n",
       "      <td>0.156961</td>\n",
       "      <td>0.155169</td>\n",
       "      <td>0.012991</td>\n",
       "      <td>0.009138</td>\n",
       "      <td>0.015857</td>\n",
       "      <td>0.01532</td>\n",
       "      <td>0.018903</td>\n",
       "      <td>0.01317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  \\\n",
       "Weights    0.164576    0.150152    0.142537    0.145225    0.156961   \n",
       "\n",
       "         Activity 6  Activity 7  Activity 8  Activity 9  Activity 10  \\\n",
       "Weights    0.155169    0.012991    0.009138    0.015857      0.01532   \n",
       "\n",
       "         Activity 11  Activity 12  \n",
       "Weights     0.018903      0.01317  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# apply drop extract outliers to dataset type\n",
    "clean_Dataset_type_II= extract_drop_outliers(Dataset_type_II,100,2)# store the clean dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.2 Features Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "def scaling_array(oneD_signal):\n",
    "    # inputs: 1D numpy array (one column)\n",
    "    maximum=oneD_signal.max() # maximum of the column\n",
    "    minimum=oneD_signal.min() # min value of the column\n",
    "    Difference=float(maximum-minimum) # max-min\n",
    "    # scaling formula: 2 * (x_i-minimum)/(maximum -minimum)\n",
    "    # apply the scaling formula to each value in the column\n",
    "    scaled_signal=np.array([((float(oneD_signal[i])-minimum)/float(Difference))*2 -1 for i in range(len(oneD_signal))])\n",
    "    \n",
    "    #return the scaled array\n",
    "    return scaled_signal\n",
    "\n",
    "def scaling_DF(data_frame):\n",
    "    # input : pandas dataframe (clean datasets type I or II)\n",
    "    columns=data_frame.columns# column names\n",
    "    # apply the scaling function to each feature columns only\n",
    "    scaled_array=np.apply_along_axis(scaling_array,0,np.array(data_frame[columns[:-2]]))\n",
    "    \n",
    "    # buid the scaled dataset\n",
    "    scaled_df=pd.DataFrame(data=scaled_array,columns=columns[:-2])\n",
    "    \n",
    "    # the user and activity ids columns\n",
    "    scaled_df['activity_Id']=np.array(data_frame['activity_Id'])\n",
    "    scaled_df['user_Id']=np.array(data_frame['user_Id'])\n",
    "    \n",
    "    return scaled_df # return the scaled dataset\n",
    "\n",
    "###################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset type I has a shape of: 9233 rows and 642 columns\n",
      "\n",
      "\n",
      "\n",
      "The first 3 rows of Dataset type I :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_body_acc_mean()_X</th>\n",
       "      <th>t_body_acc_mean()_Y</th>\n",
       "      <th>t_body_acc_mean()_Z</th>\n",
       "      <th>t_body_acc_std()_X</th>\n",
       "      <th>t_body_acc_std()_Y</th>\n",
       "      <th>t_body_acc_std()_Z</th>\n",
       "      <th>t_body_acc_mad()_X</th>\n",
       "      <th>t_body_acc_mad()_Y</th>\n",
       "      <th>t_body_acc_mad()_Z</th>\n",
       "      <th>t_body_acc_max()_X</th>\n",
       "      <th>...</th>\n",
       "      <th>f_body_gyro_Jerk_Mag_kurtosis()</th>\n",
       "      <th>angle0()</th>\n",
       "      <th>angle1()</th>\n",
       "      <th>angle2()</th>\n",
       "      <th>angle3()</th>\n",
       "      <th>angle4()</th>\n",
       "      <th>angle5()</th>\n",
       "      <th>angle6()</th>\n",
       "      <th>activity_Id</th>\n",
       "      <th>user_Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.051326</td>\n",
       "      <td>0.043149</td>\n",
       "      <td>0.112734</td>\n",
       "      <td>-0.992018</td>\n",
       "      <td>-0.930446</td>\n",
       "      <td>-0.848213</td>\n",
       "      <td>-0.989362</td>\n",
       "      <td>-0.885423</td>\n",
       "      <td>-0.837624</td>\n",
       "      <td>-0.987283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.791006</td>\n",
       "      <td>-0.320689</td>\n",
       "      <td>-0.091183</td>\n",
       "      <td>0.349595</td>\n",
       "      <td>-0.079805</td>\n",
       "      <td>-0.842265</td>\n",
       "      <td>0.180808</td>\n",
       "      <td>-0.059645</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.006554</td>\n",
       "      <td>-0.051582</td>\n",
       "      <td>0.035282</td>\n",
       "      <td>-0.990336</td>\n",
       "      <td>-0.939562</td>\n",
       "      <td>-0.878181</td>\n",
       "      <td>-0.991221</td>\n",
       "      <td>-0.919660</td>\n",
       "      <td>-0.855571</td>\n",
       "      <td>-0.989407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.883466</td>\n",
       "      <td>0.053468</td>\n",
       "      <td>0.180498</td>\n",
       "      <td>-0.230454</td>\n",
       "      <td>0.127201</td>\n",
       "      <td>-0.845784</td>\n",
       "      <td>0.177436</td>\n",
       "      <td>-0.060186</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.139646</td>\n",
       "      <td>-0.073936</td>\n",
       "      <td>-0.988981</td>\n",
       "      <td>-0.957971</td>\n",
       "      <td>-0.915318</td>\n",
       "      <td>-0.987595</td>\n",
       "      <td>-0.945763</td>\n",
       "      <td>-0.870437</td>\n",
       "      <td>-0.985389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.896875</td>\n",
       "      <td>0.133229</td>\n",
       "      <td>-0.265611</td>\n",
       "      <td>0.123668</td>\n",
       "      <td>0.724941</td>\n",
       "      <td>-0.837948</td>\n",
       "      <td>0.183600</td>\n",
       "      <td>-0.060759</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 642 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   t_body_acc_mean()_X  t_body_acc_mean()_Y  t_body_acc_mean()_Z  \\\n",
       "0             0.051326             0.043149             0.112734   \n",
       "1            -0.006554            -0.051582             0.035282   \n",
       "2             0.002200             0.139646            -0.073936   \n",
       "\n",
       "   t_body_acc_std()_X  t_body_acc_std()_Y  t_body_acc_std()_Z  \\\n",
       "0           -0.992018           -0.930446           -0.848213   \n",
       "1           -0.990336           -0.939562           -0.878181   \n",
       "2           -0.988981           -0.957971           -0.915318   \n",
       "\n",
       "   t_body_acc_mad()_X  t_body_acc_mad()_Y  t_body_acc_mad()_Z  \\\n",
       "0           -0.989362           -0.885423           -0.837624   \n",
       "1           -0.991221           -0.919660           -0.855571   \n",
       "2           -0.987595           -0.945763           -0.870437   \n",
       "\n",
       "   t_body_acc_max()_X  ...  f_body_gyro_Jerk_Mag_kurtosis()  angle0()  \\\n",
       "0           -0.987283  ...                         0.791006 -0.320689   \n",
       "1           -0.989407  ...                         0.883466  0.053468   \n",
       "2           -0.985389  ...                         0.896875  0.133229   \n",
       "\n",
       "   angle1()  angle2()  angle3()  angle4()  angle5()  angle6()  activity_Id  \\\n",
       "0 -0.091183  0.349595 -0.079805 -0.842265  0.180808 -0.059645          5.0   \n",
       "1  0.180498 -0.230454  0.127201 -0.845784  0.177436 -0.060186          5.0   \n",
       "2 -0.265611  0.123668  0.724941 -0.837948  0.183600 -0.060759          5.0   \n",
       "\n",
       "   user_Id  \n",
       "0      1.0  \n",
       "1      1.0  \n",
       "2      1.0  \n",
       "\n",
       "[3 rows x 642 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "rows 500, 501, 502 of Dataset type I :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_body_acc_mean()_X</th>\n",
       "      <th>t_body_acc_mean()_Y</th>\n",
       "      <th>t_body_acc_mean()_Z</th>\n",
       "      <th>t_body_acc_std()_X</th>\n",
       "      <th>t_body_acc_std()_Y</th>\n",
       "      <th>t_body_acc_std()_Z</th>\n",
       "      <th>t_body_acc_mad()_X</th>\n",
       "      <th>t_body_acc_mad()_Y</th>\n",
       "      <th>t_body_acc_mad()_Z</th>\n",
       "      <th>t_body_acc_max()_X</th>\n",
       "      <th>...</th>\n",
       "      <th>f_body_gyro_Jerk_Mag_kurtosis()</th>\n",
       "      <th>angle0()</th>\n",
       "      <th>angle1()</th>\n",
       "      <th>angle2()</th>\n",
       "      <th>angle3()</th>\n",
       "      <th>angle4()</th>\n",
       "      <th>angle5()</th>\n",
       "      <th>angle6()</th>\n",
       "      <th>activity_Id</th>\n",
       "      <th>user_Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>-0.053931</td>\n",
       "      <td>-0.302034</td>\n",
       "      <td>-0.243249</td>\n",
       "      <td>-0.985867</td>\n",
       "      <td>-0.848199</td>\n",
       "      <td>-0.865056</td>\n",
       "      <td>-0.985665</td>\n",
       "      <td>-0.786000</td>\n",
       "      <td>-0.788612</td>\n",
       "      <td>-0.987998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116842</td>\n",
       "      <td>0.279188</td>\n",
       "      <td>0.147179</td>\n",
       "      <td>0.010784</td>\n",
       "      <td>0.052743</td>\n",
       "      <td>-0.628840</td>\n",
       "      <td>0.072625</td>\n",
       "      <td>-0.252448</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>-0.040500</td>\n",
       "      <td>-0.150576</td>\n",
       "      <td>-0.198964</td>\n",
       "      <td>-0.975644</td>\n",
       "      <td>-0.923477</td>\n",
       "      <td>-0.931274</td>\n",
       "      <td>-0.978268</td>\n",
       "      <td>-0.906084</td>\n",
       "      <td>-0.944562</td>\n",
       "      <td>-0.943236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.544244</td>\n",
       "      <td>0.074543</td>\n",
       "      <td>0.336980</td>\n",
       "      <td>-0.295207</td>\n",
       "      <td>0.027356</td>\n",
       "      <td>-0.570983</td>\n",
       "      <td>0.354262</td>\n",
       "      <td>-0.119227</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.019069</td>\n",
       "      <td>0.163345</td>\n",
       "      <td>0.109356</td>\n",
       "      <td>-0.978209</td>\n",
       "      <td>-0.946522</td>\n",
       "      <td>-0.946986</td>\n",
       "      <td>-0.976886</td>\n",
       "      <td>-0.907130</td>\n",
       "      <td>-0.951434</td>\n",
       "      <td>-0.983099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.766160</td>\n",
       "      <td>0.070927</td>\n",
       "      <td>-0.578311</td>\n",
       "      <td>0.401719</td>\n",
       "      <td>0.224743</td>\n",
       "      <td>-0.568398</td>\n",
       "      <td>0.362272</td>\n",
       "      <td>-0.105581</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 642 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     t_body_acc_mean()_X  t_body_acc_mean()_Y  t_body_acc_mean()_Z  \\\n",
       "500            -0.053931            -0.302034            -0.243249   \n",
       "501            -0.040500            -0.150576            -0.198964   \n",
       "502             0.019069             0.163345             0.109356   \n",
       "\n",
       "     t_body_acc_std()_X  t_body_acc_std()_Y  t_body_acc_std()_Z  \\\n",
       "500           -0.985867           -0.848199           -0.865056   \n",
       "501           -0.975644           -0.923477           -0.931274   \n",
       "502           -0.978209           -0.946522           -0.946986   \n",
       "\n",
       "     t_body_acc_mad()_X  t_body_acc_mad()_Y  t_body_acc_mad()_Z  \\\n",
       "500           -0.985665           -0.786000           -0.788612   \n",
       "501           -0.978268           -0.906084           -0.944562   \n",
       "502           -0.976886           -0.907130           -0.951434   \n",
       "\n",
       "     t_body_acc_max()_X  ...  f_body_gyro_Jerk_Mag_kurtosis()  angle0()  \\\n",
       "500           -0.987998  ...                         0.116842  0.279188   \n",
       "501           -0.943236  ...                         0.544244  0.074543   \n",
       "502           -0.983099  ...                         0.766160  0.070927   \n",
       "\n",
       "     angle1()  angle2()  angle3()  angle4()  angle5()  angle6()  activity_Id  \\\n",
       "500  0.147179  0.010784  0.052743 -0.628840  0.072625 -0.252448          4.0   \n",
       "501  0.336980 -0.295207  0.027356 -0.570983  0.354262 -0.119227          5.0   \n",
       "502 -0.578311  0.401719  0.224743 -0.568398  0.362272 -0.105581          5.0   \n",
       "\n",
       "     user_Id  \n",
       "500      2.0  \n",
       "501      2.0  \n",
       "502      2.0  \n",
       "\n",
       "[3 rows x 642 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Description of the 10 first features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_body_acc_mean()_X</th>\n",
       "      <th>t_body_acc_mean()_Y</th>\n",
       "      <th>t_body_acc_mean()_Z</th>\n",
       "      <th>t_body_acc_std()_X</th>\n",
       "      <th>t_body_acc_std()_Y</th>\n",
       "      <th>t_body_acc_std()_Z</th>\n",
       "      <th>t_body_acc_mad()_X</th>\n",
       "      <th>t_body_acc_mad()_Y</th>\n",
       "      <th>t_body_acc_mad()_Z</th>\n",
       "      <th>t_body_acc_max()_X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.010846</td>\n",
       "      <td>0.025428</td>\n",
       "      <td>0.020011</td>\n",
       "      <td>-0.521025</td>\n",
       "      <td>-0.491636</td>\n",
       "      <td>-0.558962</td>\n",
       "      <td>-0.584393</td>\n",
       "      <td>-0.476448</td>\n",
       "      <td>-0.538796</td>\n",
       "      <td>-0.409822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.196114</td>\n",
       "      <td>0.182540</td>\n",
       "      <td>0.146337</td>\n",
       "      <td>0.504987</td>\n",
       "      <td>0.483855</td>\n",
       "      <td>0.432279</td>\n",
       "      <td>0.438608</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>0.430227</td>\n",
       "      <td>0.627284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.059249</td>\n",
       "      <td>-0.063687</td>\n",
       "      <td>-0.051671</td>\n",
       "      <td>-0.975591</td>\n",
       "      <td>-0.946135</td>\n",
       "      <td>-0.952214</td>\n",
       "      <td>-0.973627</td>\n",
       "      <td>-0.931261</td>\n",
       "      <td>-0.932696</td>\n",
       "      <td>-0.975176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.009746</td>\n",
       "      <td>0.028277</td>\n",
       "      <td>0.017101</td>\n",
       "      <td>-0.924071</td>\n",
       "      <td>-0.835035</td>\n",
       "      <td>-0.848213</td>\n",
       "      <td>-0.911444</td>\n",
       "      <td>-0.769705</td>\n",
       "      <td>-0.785732</td>\n",
       "      <td>-0.929371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.077577</td>\n",
       "      <td>0.117079</td>\n",
       "      <td>0.087491</td>\n",
       "      <td>-0.115419</td>\n",
       "      <td>-0.056346</td>\n",
       "      <td>-0.196392</td>\n",
       "      <td>-0.225390</td>\n",
       "      <td>-0.049681</td>\n",
       "      <td>-0.177027</td>\n",
       "      <td>0.124838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       t_body_acc_mean()_X  t_body_acc_mean()_Y  t_body_acc_mean()_Z  \\\n",
       "count          9233.000000          9233.000000          9233.000000   \n",
       "mean              0.010846             0.025428             0.020011   \n",
       "std               0.196114             0.182540             0.146337   \n",
       "min              -1.000000            -1.000000            -1.000000   \n",
       "25%              -0.059249            -0.063687            -0.051671   \n",
       "50%               0.009746             0.028277             0.017101   \n",
       "75%               0.077577             0.117079             0.087491   \n",
       "max               1.000000             1.000000             1.000000   \n",
       "\n",
       "       t_body_acc_std()_X  t_body_acc_std()_Y  t_body_acc_std()_Z  \\\n",
       "count         9233.000000         9233.000000         9233.000000   \n",
       "mean            -0.521025           -0.491636           -0.558962   \n",
       "std              0.504987            0.483855            0.432279   \n",
       "min             -1.000000           -1.000000           -1.000000   \n",
       "25%             -0.975591           -0.946135           -0.952214   \n",
       "50%             -0.924071           -0.835035           -0.848213   \n",
       "75%             -0.115419           -0.056346           -0.196392   \n",
       "max              1.000000            1.000000            1.000000   \n",
       "\n",
       "       t_body_acc_mad()_X  t_body_acc_mad()_Y  t_body_acc_mad()_Z  \\\n",
       "count         9233.000000         9233.000000         9233.000000   \n",
       "mean            -0.584393           -0.476448           -0.538796   \n",
       "std              0.438608            0.490196            0.430227   \n",
       "min             -1.000000           -1.000000           -1.000000   \n",
       "25%             -0.973627           -0.931261           -0.932696   \n",
       "50%             -0.911444           -0.769705           -0.785732   \n",
       "75%             -0.225390           -0.049681           -0.177027   \n",
       "max              1.000000            1.000000            1.000000   \n",
       "\n",
       "       t_body_acc_max()_X  \n",
       "count         9233.000000  \n",
       "mean            -0.409822  \n",
       "std              0.627284  \n",
       "min             -1.000000  \n",
       "25%             -0.975176  \n",
       "50%             -0.929371  \n",
       "75%              0.124838  \n",
       "max              1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Description of the 10 first frequency features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_body_acc_mean()_X</th>\n",
       "      <th>f_body_acc_mean()_Y</th>\n",
       "      <th>f_body_acc_mean()_Z</th>\n",
       "      <th>f_body_acc_std()_X</th>\n",
       "      <th>f_body_acc_std()_Y</th>\n",
       "      <th>f_body_acc_std()_Z</th>\n",
       "      <th>f_body_acc_mad()_X</th>\n",
       "      <th>f_body_acc_mad()_Y</th>\n",
       "      <th>f_body_acc_mad()_Z</th>\n",
       "      <th>f_body_acc_max()_X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.507327</td>\n",
       "      <td>-0.517176</td>\n",
       "      <td>-0.587011</td>\n",
       "      <td>-0.527442</td>\n",
       "      <td>-0.497754</td>\n",
       "      <td>-0.585202</td>\n",
       "      <td>-0.627453</td>\n",
       "      <td>-0.612719</td>\n",
       "      <td>-0.677594</td>\n",
       "      <td>-0.566607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.526375</td>\n",
       "      <td>0.486768</td>\n",
       "      <td>0.426813</td>\n",
       "      <td>0.497241</td>\n",
       "      <td>0.467366</td>\n",
       "      <td>0.399072</td>\n",
       "      <td>0.422685</td>\n",
       "      <td>0.425971</td>\n",
       "      <td>0.366571</td>\n",
       "      <td>0.465838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.982040</td>\n",
       "      <td>-0.968966</td>\n",
       "      <td>-0.971033</td>\n",
       "      <td>-0.972262</td>\n",
       "      <td>-0.936960</td>\n",
       "      <td>-0.944621</td>\n",
       "      <td>-0.986773</td>\n",
       "      <td>-0.978933</td>\n",
       "      <td>-0.976009</td>\n",
       "      <td>-0.968590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.947264</td>\n",
       "      <td>-0.899033</td>\n",
       "      <td>-0.912045</td>\n",
       "      <td>-0.914282</td>\n",
       "      <td>-0.809040</td>\n",
       "      <td>-0.828600</td>\n",
       "      <td>-0.958750</td>\n",
       "      <td>-0.938994</td>\n",
       "      <td>-0.945269</td>\n",
       "      <td>-0.901412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.062607</td>\n",
       "      <td>-0.077847</td>\n",
       "      <td>-0.219068</td>\n",
       "      <td>-0.139677</td>\n",
       "      <td>-0.079295</td>\n",
       "      <td>-0.267568</td>\n",
       "      <td>-0.308852</td>\n",
       "      <td>-0.274010</td>\n",
       "      <td>-0.414634</td>\n",
       "      <td>-0.226136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f_body_acc_mean()_X  f_body_acc_mean()_Y  f_body_acc_mean()_Z  \\\n",
       "count          9233.000000          9233.000000          9233.000000   \n",
       "mean             -0.507327            -0.517176            -0.587011   \n",
       "std               0.526375             0.486768             0.426813   \n",
       "min              -1.000000            -1.000000            -1.000000   \n",
       "25%              -0.982040            -0.968966            -0.971033   \n",
       "50%              -0.947264            -0.899033            -0.912045   \n",
       "75%              -0.062607            -0.077847            -0.219068   \n",
       "max               1.000000             1.000000             1.000000   \n",
       "\n",
       "       f_body_acc_std()_X  f_body_acc_std()_Y  f_body_acc_std()_Z  \\\n",
       "count         9233.000000         9233.000000         9233.000000   \n",
       "mean            -0.527442           -0.497754           -0.585202   \n",
       "std              0.497241            0.467366            0.399072   \n",
       "min             -1.000000           -1.000000           -1.000000   \n",
       "25%             -0.972262           -0.936960           -0.944621   \n",
       "50%             -0.914282           -0.809040           -0.828600   \n",
       "75%             -0.139677           -0.079295           -0.267568   \n",
       "max              1.000000            1.000000            1.000000   \n",
       "\n",
       "       f_body_acc_mad()_X  f_body_acc_mad()_Y  f_body_acc_mad()_Z  \\\n",
       "count         9233.000000         9233.000000         9233.000000   \n",
       "mean            -0.627453           -0.612719           -0.677594   \n",
       "std              0.422685            0.425971            0.366571   \n",
       "min             -1.000000           -1.000000           -1.000000   \n",
       "25%             -0.986773           -0.978933           -0.976009   \n",
       "50%             -0.958750           -0.938994           -0.945269   \n",
       "75%             -0.308852           -0.274010           -0.414634   \n",
       "max              1.000000            1.000000            1.000000   \n",
       "\n",
       "       f_body_acc_max()_X  \n",
       "count         9233.000000  \n",
       "mean            -0.566607  \n",
       "std              0.465838  \n",
       "min             -1.000000  \n",
       "25%             -0.968590  \n",
       "50%             -0.901412  \n",
       "75%             -0.226136  \n",
       "max              1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Number of windows per user and per each activity:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User 1</th>\n",
       "      <td>95</td>\n",
       "      <td>53</td>\n",
       "      <td>49</td>\n",
       "      <td>44</td>\n",
       "      <td>53</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 2</th>\n",
       "      <td>59</td>\n",
       "      <td>47</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "      <td>48</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 3</th>\n",
       "      <td>58</td>\n",
       "      <td>59</td>\n",
       "      <td>49</td>\n",
       "      <td>34</td>\n",
       "      <td>40</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 4</th>\n",
       "      <td>60</td>\n",
       "      <td>52</td>\n",
       "      <td>45</td>\n",
       "      <td>33</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 5</th>\n",
       "      <td>56</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>27</td>\n",
       "      <td>33</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 6</th>\n",
       "      <td>56</td>\n",
       "      <td>39</td>\n",
       "      <td>34</td>\n",
       "      <td>29</td>\n",
       "      <td>42</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 7</th>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "      <td>47</td>\n",
       "      <td>33</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 8</th>\n",
       "      <td>47</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>39</td>\n",
       "      <td>50</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 9</th>\n",
       "      <td>52</td>\n",
       "      <td>49</td>\n",
       "      <td>42</td>\n",
       "      <td>33</td>\n",
       "      <td>38</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 10</th>\n",
       "      <td>53</td>\n",
       "      <td>46</td>\n",
       "      <td>38</td>\n",
       "      <td>47</td>\n",
       "      <td>34</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 11</th>\n",
       "      <td>59</td>\n",
       "      <td>54</td>\n",
       "      <td>46</td>\n",
       "      <td>41</td>\n",
       "      <td>47</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 12</th>\n",
       "      <td>50</td>\n",
       "      <td>52</td>\n",
       "      <td>44</td>\n",
       "      <td>37</td>\n",
       "      <td>46</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 13</th>\n",
       "      <td>57</td>\n",
       "      <td>55</td>\n",
       "      <td>47</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 14</th>\n",
       "      <td>59</td>\n",
       "      <td>34</td>\n",
       "      <td>38</td>\n",
       "      <td>43</td>\n",
       "      <td>49</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 15</th>\n",
       "      <td>53</td>\n",
       "      <td>48</td>\n",
       "      <td>42</td>\n",
       "      <td>54</td>\n",
       "      <td>47</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 16</th>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>47</td>\n",
       "      <td>62</td>\n",
       "      <td>77</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 17</th>\n",
       "      <td>61</td>\n",
       "      <td>48</td>\n",
       "      <td>47</td>\n",
       "      <td>59</td>\n",
       "      <td>77</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 18</th>\n",
       "      <td>56</td>\n",
       "      <td>57</td>\n",
       "      <td>55</td>\n",
       "      <td>57</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 19</th>\n",
       "      <td>31</td>\n",
       "      <td>26</td>\n",
       "      <td>15</td>\n",
       "      <td>66</td>\n",
       "      <td>68</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 20</th>\n",
       "      <td>38</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "      <td>44</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 21</th>\n",
       "      <td>52</td>\n",
       "      <td>46</td>\n",
       "      <td>45</td>\n",
       "      <td>78</td>\n",
       "      <td>79</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 22</th>\n",
       "      <td>46</td>\n",
       "      <td>32</td>\n",
       "      <td>36</td>\n",
       "      <td>47</td>\n",
       "      <td>52</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 23</th>\n",
       "      <td>37</td>\n",
       "      <td>51</td>\n",
       "      <td>38</td>\n",
       "      <td>55</td>\n",
       "      <td>60</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 24</th>\n",
       "      <td>58</td>\n",
       "      <td>59</td>\n",
       "      <td>54</td>\n",
       "      <td>67</td>\n",
       "      <td>60</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 25</th>\n",
       "      <td>74</td>\n",
       "      <td>65</td>\n",
       "      <td>58</td>\n",
       "      <td>63</td>\n",
       "      <td>70</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 26</th>\n",
       "      <td>59</td>\n",
       "      <td>55</td>\n",
       "      <td>50</td>\n",
       "      <td>74</td>\n",
       "      <td>73</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 27</th>\n",
       "      <td>57</td>\n",
       "      <td>51</td>\n",
       "      <td>44</td>\n",
       "      <td>67</td>\n",
       "      <td>75</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 28</th>\n",
       "      <td>54</td>\n",
       "      <td>51</td>\n",
       "      <td>46</td>\n",
       "      <td>53</td>\n",
       "      <td>59</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 29</th>\n",
       "      <td>53</td>\n",
       "      <td>49</td>\n",
       "      <td>48</td>\n",
       "      <td>57</td>\n",
       "      <td>67</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 30</th>\n",
       "      <td>65</td>\n",
       "      <td>64</td>\n",
       "      <td>62</td>\n",
       "      <td>58</td>\n",
       "      <td>46</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  \\\n",
       "User 1           95          53          49          44          53   \n",
       "User 2           59          47          45          43          48   \n",
       "User 3           58          59          49          34          40   \n",
       "User 4           60          52          45          33          43   \n",
       "User 5           56          47          47          27          33   \n",
       "User 6           56          39          34          29          42   \n",
       "User 7           49          51          47          33          45   \n",
       "User 8           47          29          29          39          50   \n",
       "User 9           52          49          42          33          38   \n",
       "User 10          53          46          38          47          34   \n",
       "User 11          59          54          46          41          47   \n",
       "User 12          50          52          44          37          46   \n",
       "User 13          57          55          47          45          49   \n",
       "User 14          59          34          38          43          49   \n",
       "User 15          53          48          42          54          47   \n",
       "User 16          51          51          47          62          77   \n",
       "User 17          61          48          47          59          77   \n",
       "User 18          56          57          55          57          77   \n",
       "User 19          31          26          15          66          68   \n",
       "User 20          38          45          45          50          44   \n",
       "User 21          52          46          45          78          79   \n",
       "User 22          46          32          36          47          52   \n",
       "User 23          37          51          38          55          60   \n",
       "User 24          58          59          54          67          60   \n",
       "User 25          74          65          58          63          70   \n",
       "User 26          59          55          50          74          73   \n",
       "User 27          57          51          44          67          75   \n",
       "User 28          54          51          46          53          59   \n",
       "User 29          53          49          48          57          67   \n",
       "User 30          65          64          62          58          46   \n",
       "\n",
       "         Activity 6  \n",
       "User 1           37  \n",
       "User 2           45  \n",
       "User 3           53  \n",
       "User 4           43  \n",
       "User 5           43  \n",
       "User 6           39  \n",
       "User 7           43  \n",
       "User 8           42  \n",
       "User 9           27  \n",
       "User 10          43  \n",
       "User 11          50  \n",
       "User 12          44  \n",
       "User 13          56  \n",
       "User 14          34  \n",
       "User 15          59  \n",
       "User 16          67  \n",
       "User 17          60  \n",
       "User 18          65  \n",
       "User 19          77  \n",
       "User 20          62  \n",
       "User 21          82  \n",
       "User 22          58  \n",
       "User 23          66  \n",
       "User 24          66  \n",
       "User 25          44  \n",
       "User 26          72  \n",
       "User 27          70  \n",
       "User 28          63  \n",
       "User 29          68  \n",
       "User 30          60  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Statistics of table above:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>55.166667</td>\n",
       "      <td>48.833333</td>\n",
       "      <td>44.400000</td>\n",
       "      <td>49.833333</td>\n",
       "      <td>54.933333</td>\n",
       "      <td>54.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.228300</td>\n",
       "      <td>9.251592</td>\n",
       "      <td>8.791061</td>\n",
       "      <td>13.696421</td>\n",
       "      <td>14.115126</td>\n",
       "      <td>13.7555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>27.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>51.250000</td>\n",
       "      <td>46.250000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>39.500000</td>\n",
       "      <td>45.250000</td>\n",
       "      <td>43.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>45.500000</td>\n",
       "      <td>48.500000</td>\n",
       "      <td>49.500000</td>\n",
       "      <td>57.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>59.000000</td>\n",
       "      <td>53.750000</td>\n",
       "      <td>47.750000</td>\n",
       "      <td>58.750000</td>\n",
       "      <td>67.750000</td>\n",
       "      <td>65.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>95.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>82.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  Activity 6\n",
       "count   30.000000   30.000000   30.000000   30.000000   30.000000     30.0000\n",
       "mean    55.166667   48.833333   44.400000   49.833333   54.933333     54.6000\n",
       "std     11.228300    9.251592    8.791061   13.696421   14.115126     13.7555\n",
       "min     31.000000   26.000000   15.000000   27.000000   33.000000     27.0000\n",
       "25%     51.250000   46.250000   42.000000   39.500000   45.250000     43.0000\n",
       "50%     56.000000   51.000000   45.500000   48.500000   49.500000     57.0000\n",
       "75%     59.000000   53.750000   47.750000   58.750000   67.750000     65.7500\n",
       "max     95.000000   65.000000   62.000000   78.000000   79.000000     82.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "_____ The weights of each activity _____\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Weights</th>\n",
       "      <td>0.179248</td>\n",
       "      <td>0.15867</td>\n",
       "      <td>0.144265</td>\n",
       "      <td>0.161919</td>\n",
       "      <td>0.17849</td>\n",
       "      <td>0.177407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  \\\n",
       "Weights    0.179248     0.15867    0.144265    0.161919     0.17849   \n",
       "\n",
       "         Activity 6  \n",
       "Weights    0.177407  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# apply the scaling function to cleaned dataset type I\n",
    "scaled_type_I=scaling_DF(clean_Dataset_type_I)\n",
    "\n",
    "# explore the scaled dataset type I\n",
    "data_exploration_pipeline(scaled_type_I,1,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset type II has a shape of: 11162 rows and 642 columns\n",
      "\n",
      "\n",
      "\n",
      "The first 3 rows of Dataset type II :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_body_acc_mean()_X</th>\n",
       "      <th>t_body_acc_mean()_Y</th>\n",
       "      <th>t_body_acc_mean()_Z</th>\n",
       "      <th>t_body_acc_std()_X</th>\n",
       "      <th>t_body_acc_std()_Y</th>\n",
       "      <th>t_body_acc_std()_Z</th>\n",
       "      <th>t_body_acc_mad()_X</th>\n",
       "      <th>t_body_acc_mad()_Y</th>\n",
       "      <th>t_body_acc_mad()_Z</th>\n",
       "      <th>t_body_acc_max()_X</th>\n",
       "      <th>...</th>\n",
       "      <th>f_body_gyro_Jerk_Mag_kurtosis()</th>\n",
       "      <th>angle0()</th>\n",
       "      <th>angle1()</th>\n",
       "      <th>angle2()</th>\n",
       "      <th>angle3()</th>\n",
       "      <th>angle4()</th>\n",
       "      <th>angle5()</th>\n",
       "      <th>angle6()</th>\n",
       "      <th>activity_Id</th>\n",
       "      <th>user_Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.057656</td>\n",
       "      <td>0.129985</td>\n",
       "      <td>0.083852</td>\n",
       "      <td>-0.991872</td>\n",
       "      <td>-0.932060</td>\n",
       "      <td>-0.841013</td>\n",
       "      <td>-0.989898</td>\n",
       "      <td>-0.904046</td>\n",
       "      <td>-0.881322</td>\n",
       "      <td>-0.987283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.796342</td>\n",
       "      <td>-0.322101</td>\n",
       "      <td>-0.086128</td>\n",
       "      <td>0.353487</td>\n",
       "      <td>-0.087620</td>\n",
       "      <td>-0.844450</td>\n",
       "      <td>0.179862</td>\n",
       "      <td>-0.040856</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.002071</td>\n",
       "      <td>0.055747</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>-0.990160</td>\n",
       "      <td>-0.941033</td>\n",
       "      <td>-0.872439</td>\n",
       "      <td>-0.991663</td>\n",
       "      <td>-0.932438</td>\n",
       "      <td>-0.894494</td>\n",
       "      <td>-0.989407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882150</td>\n",
       "      <td>0.052825</td>\n",
       "      <td>0.185877</td>\n",
       "      <td>-0.226373</td>\n",
       "      <td>0.118652</td>\n",
       "      <td>-0.847921</td>\n",
       "      <td>0.176493</td>\n",
       "      <td>-0.041387</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006962</td>\n",
       "      <td>0.205607</td>\n",
       "      <td>-0.117723</td>\n",
       "      <td>-0.988781</td>\n",
       "      <td>-0.959152</td>\n",
       "      <td>-0.911384</td>\n",
       "      <td>-0.988219</td>\n",
       "      <td>-0.954085</td>\n",
       "      <td>-0.905404</td>\n",
       "      <td>-0.985389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.894594</td>\n",
       "      <td>0.132750</td>\n",
       "      <td>-0.260766</td>\n",
       "      <td>0.127633</td>\n",
       "      <td>0.714273</td>\n",
       "      <td>-0.840192</td>\n",
       "      <td>0.182652</td>\n",
       "      <td>-0.041949</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 642 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   t_body_acc_mean()_X  t_body_acc_mean()_Y  t_body_acc_mean()_Z  \\\n",
       "0             0.057656             0.129985             0.083852   \n",
       "1            -0.002071             0.055747             0.000216   \n",
       "2             0.006962             0.205607            -0.117723   \n",
       "\n",
       "   t_body_acc_std()_X  t_body_acc_std()_Y  t_body_acc_std()_Z  \\\n",
       "0           -0.991872           -0.932060           -0.841013   \n",
       "1           -0.990160           -0.941033           -0.872439   \n",
       "2           -0.988781           -0.959152           -0.911384   \n",
       "\n",
       "   t_body_acc_mad()_X  t_body_acc_mad()_Y  t_body_acc_mad()_Z  \\\n",
       "0           -0.989898           -0.904046           -0.881322   \n",
       "1           -0.991663           -0.932438           -0.894494   \n",
       "2           -0.988219           -0.954085           -0.905404   \n",
       "\n",
       "   t_body_acc_max()_X  ...  f_body_gyro_Jerk_Mag_kurtosis()  angle0()  \\\n",
       "0           -0.987283  ...                         0.796342 -0.322101   \n",
       "1           -0.989407  ...                         0.882150  0.052825   \n",
       "2           -0.985389  ...                         0.894594  0.132750   \n",
       "\n",
       "   angle1()  angle2()  angle3()  angle4()  angle5()  angle6()  activity_Id  \\\n",
       "0 -0.086128  0.353487 -0.087620 -0.844450  0.179862 -0.040856          5.0   \n",
       "1  0.185877 -0.226373  0.118652 -0.847921  0.176493 -0.041387          5.0   \n",
       "2 -0.260766  0.127633  0.714273 -0.840192  0.182652 -0.041949          5.0   \n",
       "\n",
       "   user_Id  \n",
       "0      1.0  \n",
       "1      1.0  \n",
       "2      1.0  \n",
       "\n",
       "[3 rows x 642 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "rows 500, 501, 502 of Dataset type II :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_body_acc_mean()_X</th>\n",
       "      <th>t_body_acc_mean()_Y</th>\n",
       "      <th>t_body_acc_mean()_Z</th>\n",
       "      <th>t_body_acc_std()_X</th>\n",
       "      <th>t_body_acc_std()_Y</th>\n",
       "      <th>t_body_acc_std()_Z</th>\n",
       "      <th>t_body_acc_mad()_X</th>\n",
       "      <th>t_body_acc_mad()_Y</th>\n",
       "      <th>t_body_acc_mad()_Z</th>\n",
       "      <th>t_body_acc_max()_X</th>\n",
       "      <th>...</th>\n",
       "      <th>f_body_gyro_Jerk_Mag_kurtosis()</th>\n",
       "      <th>angle0()</th>\n",
       "      <th>angle1()</th>\n",
       "      <th>angle2()</th>\n",
       "      <th>angle3()</th>\n",
       "      <th>angle4()</th>\n",
       "      <th>angle5()</th>\n",
       "      <th>angle6()</th>\n",
       "      <th>activity_Id</th>\n",
       "      <th>user_Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>-0.256123</td>\n",
       "      <td>0.125954</td>\n",
       "      <td>-0.191903</td>\n",
       "      <td>-0.349063</td>\n",
       "      <td>-0.213592</td>\n",
       "      <td>-0.330042</td>\n",
       "      <td>-0.508122</td>\n",
       "      <td>-0.331405</td>\n",
       "      <td>-0.301156</td>\n",
       "      <td>-0.228649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623065</td>\n",
       "      <td>0.624847</td>\n",
       "      <td>0.444219</td>\n",
       "      <td>-0.786394</td>\n",
       "      <td>0.221523</td>\n",
       "      <td>-0.666483</td>\n",
       "      <td>0.321834</td>\n",
       "      <td>0.012201</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>-0.185210</td>\n",
       "      <td>0.246477</td>\n",
       "      <td>-0.088161</td>\n",
       "      <td>-0.317336</td>\n",
       "      <td>-0.221163</td>\n",
       "      <td>-0.377236</td>\n",
       "      <td>-0.509923</td>\n",
       "      <td>-0.369845</td>\n",
       "      <td>-0.327881</td>\n",
       "      <td>-0.228649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.690871</td>\n",
       "      <td>0.782214</td>\n",
       "      <td>-0.032887</td>\n",
       "      <td>-0.617773</td>\n",
       "      <td>-0.314362</td>\n",
       "      <td>-0.667049</td>\n",
       "      <td>0.321434</td>\n",
       "      <td>0.011946</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.147668</td>\n",
       "      <td>0.339981</td>\n",
       "      <td>0.062504</td>\n",
       "      <td>-0.377804</td>\n",
       "      <td>-0.191089</td>\n",
       "      <td>-0.335916</td>\n",
       "      <td>-0.530940</td>\n",
       "      <td>-0.433669</td>\n",
       "      <td>-0.431100</td>\n",
       "      <td>-0.328814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.627910</td>\n",
       "      <td>-0.136157</td>\n",
       "      <td>-0.764817</td>\n",
       "      <td>-0.496185</td>\n",
       "      <td>0.436664</td>\n",
       "      <td>-0.675287</td>\n",
       "      <td>0.315955</td>\n",
       "      <td>0.013633</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 642 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     t_body_acc_mean()_X  t_body_acc_mean()_Y  t_body_acc_mean()_Z  \\\n",
       "500            -0.256123             0.125954            -0.191903   \n",
       "501            -0.185210             0.246477            -0.088161   \n",
       "502             0.147668             0.339981             0.062504   \n",
       "\n",
       "     t_body_acc_std()_X  t_body_acc_std()_Y  t_body_acc_std()_Z  \\\n",
       "500           -0.349063           -0.213592           -0.330042   \n",
       "501           -0.317336           -0.221163           -0.377236   \n",
       "502           -0.377804           -0.191089           -0.335916   \n",
       "\n",
       "     t_body_acc_mad()_X  t_body_acc_mad()_Y  t_body_acc_mad()_Z  \\\n",
       "500           -0.508122           -0.331405           -0.301156   \n",
       "501           -0.509923           -0.369845           -0.327881   \n",
       "502           -0.530940           -0.433669           -0.431100   \n",
       "\n",
       "     t_body_acc_max()_X  ...  f_body_gyro_Jerk_Mag_kurtosis()  angle0()  \\\n",
       "500           -0.228649  ...                         0.623065  0.624847   \n",
       "501           -0.228649  ...                         0.690871  0.782214   \n",
       "502           -0.328814  ...                         0.627910 -0.136157   \n",
       "\n",
       "     angle1()  angle2()  angle3()  angle4()  angle5()  angle6()  activity_Id  \\\n",
       "500  0.444219 -0.786394  0.221523 -0.666483  0.321834  0.012201          1.0   \n",
       "501 -0.032887 -0.617773 -0.314362 -0.667049  0.321434  0.011946          1.0   \n",
       "502 -0.764817 -0.496185  0.436664 -0.675287  0.315955  0.013633          1.0   \n",
       "\n",
       "     user_Id  \n",
       "500      2.0  \n",
       "501      2.0  \n",
       "502      2.0  \n",
       "\n",
       "[3 rows x 642 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Description of the 10 first features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_body_acc_mean()_X</th>\n",
       "      <th>t_body_acc_mean()_Y</th>\n",
       "      <th>t_body_acc_mean()_Z</th>\n",
       "      <th>t_body_acc_std()_X</th>\n",
       "      <th>t_body_acc_std()_Y</th>\n",
       "      <th>t_body_acc_std()_Z</th>\n",
       "      <th>t_body_acc_mad()_X</th>\n",
       "      <th>t_body_acc_mad()_Y</th>\n",
       "      <th>t_body_acc_mad()_Z</th>\n",
       "      <th>t_body_acc_max()_X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.011355</td>\n",
       "      <td>0.121200</td>\n",
       "      <td>-0.019519</td>\n",
       "      <td>-0.515584</td>\n",
       "      <td>-0.476947</td>\n",
       "      <td>-0.512558</td>\n",
       "      <td>-0.619226</td>\n",
       "      <td>-0.548228</td>\n",
       "      <td>-0.645105</td>\n",
       "      <td>-0.401212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.200167</td>\n",
       "      <td>0.155037</td>\n",
       "      <td>0.171783</td>\n",
       "      <td>0.488067</td>\n",
       "      <td>0.456181</td>\n",
       "      <td>0.436934</td>\n",
       "      <td>0.391496</td>\n",
       "      <td>0.390565</td>\n",
       "      <td>0.307630</td>\n",
       "      <td>0.607955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.066911</td>\n",
       "      <td>0.044710</td>\n",
       "      <td>-0.100364</td>\n",
       "      <td>-0.970934</td>\n",
       "      <td>-0.938405</td>\n",
       "      <td>-0.941182</td>\n",
       "      <td>-0.970784</td>\n",
       "      <td>-0.932536</td>\n",
       "      <td>-0.943506</td>\n",
       "      <td>-0.971241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.011944</td>\n",
       "      <td>0.121372</td>\n",
       "      <td>-0.021476</td>\n",
       "      <td>-0.663600</td>\n",
       "      <td>-0.419682</td>\n",
       "      <td>-0.503877</td>\n",
       "      <td>-0.778651</td>\n",
       "      <td>-0.549399</td>\n",
       "      <td>-0.660385</td>\n",
       "      <td>-0.603108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.090482</td>\n",
       "      <td>0.196587</td>\n",
       "      <td>0.060745</td>\n",
       "      <td>-0.131784</td>\n",
       "      <td>-0.085841</td>\n",
       "      <td>-0.162395</td>\n",
       "      <td>-0.312013</td>\n",
       "      <td>-0.223594</td>\n",
       "      <td>-0.399430</td>\n",
       "      <td>0.102554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       t_body_acc_mean()_X  t_body_acc_mean()_Y  t_body_acc_mean()_Z  \\\n",
       "count         11162.000000         11162.000000         11162.000000   \n",
       "mean              0.011355             0.121200            -0.019519   \n",
       "std               0.200167             0.155037             0.171783   \n",
       "min              -1.000000            -1.000000            -1.000000   \n",
       "25%              -0.066911             0.044710            -0.100364   \n",
       "50%               0.011944             0.121372            -0.021476   \n",
       "75%               0.090482             0.196587             0.060745   \n",
       "max               1.000000             1.000000             1.000000   \n",
       "\n",
       "       t_body_acc_std()_X  t_body_acc_std()_Y  t_body_acc_std()_Z  \\\n",
       "count        11162.000000        11162.000000        11162.000000   \n",
       "mean            -0.515584           -0.476947           -0.512558   \n",
       "std              0.488067            0.456181            0.436934   \n",
       "min             -1.000000           -1.000000           -1.000000   \n",
       "25%             -0.970934           -0.938405           -0.941182   \n",
       "50%             -0.663600           -0.419682           -0.503877   \n",
       "75%             -0.131784           -0.085841           -0.162395   \n",
       "max              1.000000            1.000000            1.000000   \n",
       "\n",
       "       t_body_acc_mad()_X  t_body_acc_mad()_Y  t_body_acc_mad()_Z  \\\n",
       "count        11162.000000        11162.000000        11162.000000   \n",
       "mean            -0.619226           -0.548228           -0.645105   \n",
       "std              0.391496            0.390565            0.307630   \n",
       "min             -1.000000           -1.000000           -1.000000   \n",
       "25%             -0.970784           -0.932536           -0.943506   \n",
       "50%             -0.778651           -0.549399           -0.660385   \n",
       "75%             -0.312013           -0.223594           -0.399430   \n",
       "max              1.000000            1.000000            1.000000   \n",
       "\n",
       "       t_body_acc_max()_X  \n",
       "count        11162.000000  \n",
       "mean            -0.401212  \n",
       "std              0.607955  \n",
       "min             -1.000000  \n",
       "25%             -0.971241  \n",
       "50%             -0.603108  \n",
       "75%              0.102554  \n",
       "max              1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Description of the 10 first frequency features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_body_acc_mean()_X</th>\n",
       "      <th>f_body_acc_mean()_Y</th>\n",
       "      <th>f_body_acc_mean()_Z</th>\n",
       "      <th>f_body_acc_std()_X</th>\n",
       "      <th>f_body_acc_std()_Y</th>\n",
       "      <th>f_body_acc_std()_Z</th>\n",
       "      <th>f_body_acc_mad()_X</th>\n",
       "      <th>f_body_acc_mad()_Y</th>\n",
       "      <th>f_body_acc_mad()_Z</th>\n",
       "      <th>f_body_acc_max()_X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.498643</td>\n",
       "      <td>-0.508352</td>\n",
       "      <td>-0.552127</td>\n",
       "      <td>-0.523097</td>\n",
       "      <td>-0.531273</td>\n",
       "      <td>-0.536929</td>\n",
       "      <td>-0.707776</td>\n",
       "      <td>-0.618896</td>\n",
       "      <td>-0.719974</td>\n",
       "      <td>-0.578219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.510374</td>\n",
       "      <td>0.455424</td>\n",
       "      <td>0.425528</td>\n",
       "      <td>0.480220</td>\n",
       "      <td>0.399930</td>\n",
       "      <td>0.408716</td>\n",
       "      <td>0.317442</td>\n",
       "      <td>0.394940</td>\n",
       "      <td>0.301464</td>\n",
       "      <td>0.438375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.978379</td>\n",
       "      <td>-0.962982</td>\n",
       "      <td>-0.963372</td>\n",
       "      <td>-0.967025</td>\n",
       "      <td>-0.934971</td>\n",
       "      <td>-0.932897</td>\n",
       "      <td>-0.987707</td>\n",
       "      <td>-0.977952</td>\n",
       "      <td>-0.976274</td>\n",
       "      <td>-0.964006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.652604</td>\n",
       "      <td>-0.494953</td>\n",
       "      <td>-0.559897</td>\n",
       "      <td>-0.674504</td>\n",
       "      <td>-0.480512</td>\n",
       "      <td>-0.536440</td>\n",
       "      <td>-0.812506</td>\n",
       "      <td>-0.721652</td>\n",
       "      <td>-0.823696</td>\n",
       "      <td>-0.744999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.076308</td>\n",
       "      <td>-0.114467</td>\n",
       "      <td>-0.202494</td>\n",
       "      <td>-0.156821</td>\n",
       "      <td>-0.192438</td>\n",
       "      <td>-0.228271</td>\n",
       "      <td>-0.481343</td>\n",
       "      <td>-0.319173</td>\n",
       "      <td>-0.519640</td>\n",
       "      <td>-0.271756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f_body_acc_mean()_X  f_body_acc_mean()_Y  f_body_acc_mean()_Z  \\\n",
       "count         11162.000000         11162.000000         11162.000000   \n",
       "mean             -0.498643            -0.508352            -0.552127   \n",
       "std               0.510374             0.455424             0.425528   \n",
       "min              -1.000000            -1.000000            -1.000000   \n",
       "25%              -0.978379            -0.962982            -0.963372   \n",
       "50%              -0.652604            -0.494953            -0.559897   \n",
       "75%              -0.076308            -0.114467            -0.202494   \n",
       "max               1.000000             1.000000             1.000000   \n",
       "\n",
       "       f_body_acc_std()_X  f_body_acc_std()_Y  f_body_acc_std()_Z  \\\n",
       "count        11162.000000        11162.000000        11162.000000   \n",
       "mean            -0.523097           -0.531273           -0.536929   \n",
       "std              0.480220            0.399930            0.408716   \n",
       "min             -1.000000           -1.000000           -1.000000   \n",
       "25%             -0.967025           -0.934971           -0.932897   \n",
       "50%             -0.674504           -0.480512           -0.536440   \n",
       "75%             -0.156821           -0.192438           -0.228271   \n",
       "max              1.000000            1.000000            1.000000   \n",
       "\n",
       "       f_body_acc_mad()_X  f_body_acc_mad()_Y  f_body_acc_mad()_Z  \\\n",
       "count        11162.000000        11162.000000        11162.000000   \n",
       "mean            -0.707776           -0.618896           -0.719974   \n",
       "std              0.317442            0.394940            0.301464   \n",
       "min             -1.000000           -1.000000           -1.000000   \n",
       "25%             -0.987707           -0.977952           -0.976274   \n",
       "50%             -0.812506           -0.721652           -0.823696   \n",
       "75%             -0.481343           -0.319173           -0.519640   \n",
       "max              1.000000            1.000000            1.000000   \n",
       "\n",
       "       f_body_acc_max()_X  \n",
       "count        11162.000000  \n",
       "mean            -0.578219  \n",
       "std              0.438375  \n",
       "min             -1.000000  \n",
       "25%             -0.964006  \n",
       "50%             -0.744999  \n",
       "75%             -0.271756  \n",
       "max              1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Number of windows per user and per each activity:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "      <th>Activity 7</th>\n",
       "      <th>Activity 8</th>\n",
       "      <th>Activity 9</th>\n",
       "      <th>Activity 10</th>\n",
       "      <th>Activity 11</th>\n",
       "      <th>Activity 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User 1</th>\n",
       "      <td>108</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>44</td>\n",
       "      <td>54</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 2</th>\n",
       "      <td>65</td>\n",
       "      <td>54</td>\n",
       "      <td>53</td>\n",
       "      <td>45</td>\n",
       "      <td>47</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 3</th>\n",
       "      <td>64</td>\n",
       "      <td>69</td>\n",
       "      <td>58</td>\n",
       "      <td>40</td>\n",
       "      <td>43</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 4</th>\n",
       "      <td>65</td>\n",
       "      <td>58</td>\n",
       "      <td>56</td>\n",
       "      <td>38</td>\n",
       "      <td>47</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 5</th>\n",
       "      <td>62</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>35</td>\n",
       "      <td>39</td>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 6</th>\n",
       "      <td>60</td>\n",
       "      <td>44</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "      <td>46</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 7</th>\n",
       "      <td>58</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>42</td>\n",
       "      <td>49</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 8</th>\n",
       "      <td>54</td>\n",
       "      <td>35</td>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 9</th>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>53</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 10</th>\n",
       "      <td>57</td>\n",
       "      <td>53</td>\n",
       "      <td>49</td>\n",
       "      <td>47</td>\n",
       "      <td>36</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 11</th>\n",
       "      <td>66</td>\n",
       "      <td>60</td>\n",
       "      <td>56</td>\n",
       "      <td>46</td>\n",
       "      <td>50</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 12</th>\n",
       "      <td>58</td>\n",
       "      <td>61</td>\n",
       "      <td>53</td>\n",
       "      <td>44</td>\n",
       "      <td>51</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 13</th>\n",
       "      <td>63</td>\n",
       "      <td>62</td>\n",
       "      <td>55</td>\n",
       "      <td>46</td>\n",
       "      <td>53</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 14</th>\n",
       "      <td>67</td>\n",
       "      <td>44</td>\n",
       "      <td>46</td>\n",
       "      <td>50</td>\n",
       "      <td>52</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 15</th>\n",
       "      <td>60</td>\n",
       "      <td>53</td>\n",
       "      <td>50</td>\n",
       "      <td>59</td>\n",
       "      <td>51</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 16</th>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>55</td>\n",
       "      <td>63</td>\n",
       "      <td>79</td>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 17</th>\n",
       "      <td>67</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>63</td>\n",
       "      <td>79</td>\n",
       "      <td>63</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 18</th>\n",
       "      <td>62</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>60</td>\n",
       "      <td>77</td>\n",
       "      <td>67</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 19</th>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>15</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>83</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 20</th>\n",
       "      <td>44</td>\n",
       "      <td>52</td>\n",
       "      <td>54</td>\n",
       "      <td>58</td>\n",
       "      <td>57</td>\n",
       "      <td>63</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 21</th>\n",
       "      <td>59</td>\n",
       "      <td>53</td>\n",
       "      <td>55</td>\n",
       "      <td>80</td>\n",
       "      <td>85</td>\n",
       "      <td>84</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 22</th>\n",
       "      <td>52</td>\n",
       "      <td>40</td>\n",
       "      <td>46</td>\n",
       "      <td>53</td>\n",
       "      <td>57</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 23</th>\n",
       "      <td>38</td>\n",
       "      <td>56</td>\n",
       "      <td>42</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 24</th>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>67</td>\n",
       "      <td>63</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 25</th>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>66</td>\n",
       "      <td>64</td>\n",
       "      <td>72</td>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 26</th>\n",
       "      <td>65</td>\n",
       "      <td>61</td>\n",
       "      <td>60</td>\n",
       "      <td>76</td>\n",
       "      <td>73</td>\n",
       "      <td>76</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 27</th>\n",
       "      <td>63</td>\n",
       "      <td>59</td>\n",
       "      <td>56</td>\n",
       "      <td>70</td>\n",
       "      <td>81</td>\n",
       "      <td>72</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 28</th>\n",
       "      <td>63</td>\n",
       "      <td>59</td>\n",
       "      <td>55</td>\n",
       "      <td>59</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 29</th>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>56</td>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "      <td>69</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 30</th>\n",
       "      <td>71</td>\n",
       "      <td>72</td>\n",
       "      <td>71</td>\n",
       "      <td>61</td>\n",
       "      <td>52</td>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  \\\n",
       "User 1          108          61          61          44          54   \n",
       "User 2           65          54          53          45          47   \n",
       "User 3           64          69          58          40          43   \n",
       "User 4           65          58          56          38          47   \n",
       "User 5           62          55          56          35          39   \n",
       "User 6           60          44          33          40          46   \n",
       "User 7           58          57          57          42          49   \n",
       "User 8           54          35          38          40          52   \n",
       "User 9           56          56          53          39          42   \n",
       "User 10          57          53          49          47          36   \n",
       "User 11          66          60          56          46          50   \n",
       "User 12          58          61          53          44          51   \n",
       "User 13          63          62          55          46          53   \n",
       "User 14          67          44          46          50          52   \n",
       "User 15          60          53          50          59          51   \n",
       "User 16          57          57          55          63          79   \n",
       "User 17          67          56          56          63          79   \n",
       "User 18          62          65          65          60          77   \n",
       "User 19          30          29          15          70          70   \n",
       "User 20          44          52          54          58          57   \n",
       "User 21          59          53          55          80          85   \n",
       "User 22          52          40          46          53          57   \n",
       "User 23          38          56          42          62          63   \n",
       "User 24          65          65          65          67          63   \n",
       "User 25          80          72          66          64          72   \n",
       "User 26          65          61          60          76          73   \n",
       "User 27          63          59          56          70          81   \n",
       "User 28          63          59          55          59          64   \n",
       "User 29          58          58          56          60          68   \n",
       "User 30          71          72          71          61          52   \n",
       "\n",
       "         Activity 6  Activity 7  Activity 8  Activity 9  Activity 10  \\\n",
       "User 1           39           5           5           6            6   \n",
       "User 2           45           3           5           6            7   \n",
       "User 3           57           5           3           6            6   \n",
       "User 4           44           6           4           7            5   \n",
       "User 5           49           7           4           8            7   \n",
       "User 6           44           3           2           5            1   \n",
       "User 7           44           2           0           7            5   \n",
       "User 8           43           4           4           4            7   \n",
       "User 9           32           4           2           5            5   \n",
       "User 10          50           2           2           1            1   \n",
       "User 11          52           6           3           6            7   \n",
       "User 12          48           5           3           5            6   \n",
       "User 13          57           7           4           6            6   \n",
       "User 14          41           6           4           7            7   \n",
       "User 15          61           3           2           7            5   \n",
       "User 16          70           4           4           6            6   \n",
       "User 17          63           5           5           8            7   \n",
       "User 18          67           8           6           7            7   \n",
       "User 19          83           6           4           4            6   \n",
       "User 20          63           6           5           9            6   \n",
       "User 21          84           5           4           7            6   \n",
       "User 22          60           5           2           4            8   \n",
       "User 23          69           2           2           2            6   \n",
       "User 24          67           5           2           7            6   \n",
       "User 25          55           7           5           6            9   \n",
       "User 26          76           5           5           6            5   \n",
       "User 27          72           6           0           6            5   \n",
       "User 28          65           6           2           6            0   \n",
       "User 29          69           4           4           8            7   \n",
       "User 30          63           3           5           5            6   \n",
       "\n",
       "         Activity 11  Activity 12  \n",
       "User 1             9            6  \n",
       "User 2            10            5  \n",
       "User 3             5            5  \n",
       "User 4            10            5  \n",
       "User 5            11            2  \n",
       "User 6             6            4  \n",
       "User 7             6            2  \n",
       "User 8             4            2  \n",
       "User 9             6            2  \n",
       "User 10            4            1  \n",
       "User 11            6            5  \n",
       "User 12            7            7  \n",
       "User 13            6            7  \n",
       "User 14           10            8  \n",
       "User 15            7            6  \n",
       "User 16            7            4  \n",
       "User 17            8            6  \n",
       "User 18            8            6  \n",
       "User 19            9            4  \n",
       "User 20           12            4  \n",
       "User 21           10            5  \n",
       "User 22            3            4  \n",
       "User 23            8            6  \n",
       "User 24           12            8  \n",
       "User 25            7            8  \n",
       "User 26            6            7  \n",
       "User 27            5            4  \n",
       "User 28            0            5  \n",
       "User 29            6            5  \n",
       "User 30            3            4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Statistics of table above:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "      <th>Activity 7</th>\n",
       "      <th>Activity 8</th>\n",
       "      <th>Activity 9</th>\n",
       "      <th>Activity 10</th>\n",
       "      <th>Activity 11</th>\n",
       "      <th>Activity 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>61.233333</td>\n",
       "      <td>55.866667</td>\n",
       "      <td>53.033333</td>\n",
       "      <td>54.033333</td>\n",
       "      <td>58.400000</td>\n",
       "      <td>57.733333</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>5.900000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>7.033333</td>\n",
       "      <td>4.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.934006</td>\n",
       "      <td>9.754692</td>\n",
       "      <td>10.697996</td>\n",
       "      <td>12.321787</td>\n",
       "      <td>13.586504</td>\n",
       "      <td>13.266326</td>\n",
       "      <td>1.599210</td>\n",
       "      <td>1.522249</td>\n",
       "      <td>1.709003</td>\n",
       "      <td>1.950243</td>\n",
       "      <td>2.797577</td>\n",
       "      <td>1.881855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>57.250000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>50.750000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>49.250000</td>\n",
       "      <td>45.750000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>53.500000</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>65.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>56.750000</td>\n",
       "      <td>62.750000</td>\n",
       "      <td>69.500000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>108.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  Activity 6  \\\n",
       "count   30.000000   30.000000   30.000000   30.000000   30.000000   30.000000   \n",
       "mean    61.233333   55.866667   53.033333   54.033333   58.400000   57.733333   \n",
       "std     12.934006    9.754692   10.697996   12.321787   13.586504   13.266326   \n",
       "min     30.000000   29.000000   15.000000   35.000000   36.000000   32.000000   \n",
       "25%     57.250000   53.000000   50.750000   44.000000   49.250000   45.750000   \n",
       "50%     62.000000   57.000000   55.000000   55.500000   53.500000   58.500000   \n",
       "75%     65.000000   61.000000   56.750000   62.750000   69.500000   67.000000   \n",
       "max    108.000000   72.000000   71.000000   80.000000   85.000000   84.000000   \n",
       "\n",
       "       Activity 7  Activity 8  Activity 9  Activity 10  Activity 11  \\\n",
       "count   30.000000   30.000000   30.000000    30.000000    30.000000   \n",
       "mean     4.833333    3.400000    5.900000     5.700000     7.033333   \n",
       "std      1.599210    1.522249    1.709003     1.950243     2.797577   \n",
       "min      2.000000    0.000000    1.000000     0.000000     0.000000   \n",
       "25%      4.000000    2.000000    5.000000     5.000000     6.000000   \n",
       "50%      5.000000    4.000000    6.000000     6.000000     7.000000   \n",
       "75%      6.000000    4.750000    7.000000     7.000000     9.000000   \n",
       "max      8.000000    6.000000    9.000000     9.000000    12.000000   \n",
       "\n",
       "       Activity 12  \n",
       "count    30.000000  \n",
       "mean      4.900000  \n",
       "std       1.881855  \n",
       "min       1.000000  \n",
       "25%       4.000000  \n",
       "50%       5.000000  \n",
       "75%       6.000000  \n",
       "max       8.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "_____ The weights of each activity _____\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "      <th>Activity 7</th>\n",
       "      <th>Activity 8</th>\n",
       "      <th>Activity 9</th>\n",
       "      <th>Activity 10</th>\n",
       "      <th>Activity 11</th>\n",
       "      <th>Activity 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Weights</th>\n",
       "      <td>0.164576</td>\n",
       "      <td>0.150152</td>\n",
       "      <td>0.142537</td>\n",
       "      <td>0.145225</td>\n",
       "      <td>0.156961</td>\n",
       "      <td>0.155169</td>\n",
       "      <td>0.012991</td>\n",
       "      <td>0.009138</td>\n",
       "      <td>0.015857</td>\n",
       "      <td>0.01532</td>\n",
       "      <td>0.018903</td>\n",
       "      <td>0.01317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  \\\n",
       "Weights    0.164576    0.150152    0.142537    0.145225    0.156961   \n",
       "\n",
       "         Activity 6  Activity 7  Activity 8  Activity 9  Activity 10  \\\n",
       "Weights    0.155169    0.012991    0.009138    0.015857      0.01532   \n",
       "\n",
       "         Activity 11  Activity 12  \n",
       "Weights     0.018903      0.01317  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# apply the scaling function to cleaned dataset type II\n",
    "scaled_type_II=scaling_DF(clean_Dataset_type_II)\n",
    "\n",
    "# explore the scaled dataset type II\n",
    "data_exploration_pipeline(scaled_type_II,2,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI Dataset type III:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI.1. Dataset type III generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_labels=list(scaled_type_II['activity_Id']) # extract activity labels from scaled type II (ids from 1 to 12)\n",
    "\n",
    "for i in range(len(act_labels)):# iterate throw each activity label\n",
    "    \n",
    "    if act_labels[i]>6: # if activity label belongs to postural transitions ids from 7 to 12\n",
    "        act_labels[i]=7 # the target will be replaced by the id=7 (postural transition)\n",
    "\n",
    "# build dataset type III by replacing the activity id column by the new column create above\n",
    "scaled_type_III=pd.DataFrame(data=np.array(scaled_type_II),columns=scaled_type_II.columns)\n",
    "scaled_type_III['activity_Id']=np.array(act_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI.2. Dataset type III exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset type III has a shape of: 11162 rows and 642 columns\n",
      "\n",
      "\n",
      "\n",
      "The first 3 rows of Dataset type III :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_body_acc_mean()_X</th>\n",
       "      <th>t_body_acc_mean()_Y</th>\n",
       "      <th>t_body_acc_mean()_Z</th>\n",
       "      <th>t_body_acc_std()_X</th>\n",
       "      <th>t_body_acc_std()_Y</th>\n",
       "      <th>t_body_acc_std()_Z</th>\n",
       "      <th>t_body_acc_mad()_X</th>\n",
       "      <th>t_body_acc_mad()_Y</th>\n",
       "      <th>t_body_acc_mad()_Z</th>\n",
       "      <th>t_body_acc_max()_X</th>\n",
       "      <th>...</th>\n",
       "      <th>f_body_gyro_Jerk_Mag_kurtosis()</th>\n",
       "      <th>angle0()</th>\n",
       "      <th>angle1()</th>\n",
       "      <th>angle2()</th>\n",
       "      <th>angle3()</th>\n",
       "      <th>angle4()</th>\n",
       "      <th>angle5()</th>\n",
       "      <th>angle6()</th>\n",
       "      <th>activity_Id</th>\n",
       "      <th>user_Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.057656</td>\n",
       "      <td>0.129985</td>\n",
       "      <td>0.083852</td>\n",
       "      <td>-0.991872</td>\n",
       "      <td>-0.932060</td>\n",
       "      <td>-0.841013</td>\n",
       "      <td>-0.989898</td>\n",
       "      <td>-0.904046</td>\n",
       "      <td>-0.881322</td>\n",
       "      <td>-0.987283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.796342</td>\n",
       "      <td>-0.322101</td>\n",
       "      <td>-0.086128</td>\n",
       "      <td>0.353487</td>\n",
       "      <td>-0.087620</td>\n",
       "      <td>-0.844450</td>\n",
       "      <td>0.179862</td>\n",
       "      <td>-0.040856</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.002071</td>\n",
       "      <td>0.055747</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>-0.990160</td>\n",
       "      <td>-0.941033</td>\n",
       "      <td>-0.872439</td>\n",
       "      <td>-0.991663</td>\n",
       "      <td>-0.932438</td>\n",
       "      <td>-0.894494</td>\n",
       "      <td>-0.989407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882150</td>\n",
       "      <td>0.052825</td>\n",
       "      <td>0.185877</td>\n",
       "      <td>-0.226373</td>\n",
       "      <td>0.118652</td>\n",
       "      <td>-0.847921</td>\n",
       "      <td>0.176493</td>\n",
       "      <td>-0.041387</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006962</td>\n",
       "      <td>0.205607</td>\n",
       "      <td>-0.117723</td>\n",
       "      <td>-0.988781</td>\n",
       "      <td>-0.959152</td>\n",
       "      <td>-0.911384</td>\n",
       "      <td>-0.988219</td>\n",
       "      <td>-0.954085</td>\n",
       "      <td>-0.905404</td>\n",
       "      <td>-0.985389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.894594</td>\n",
       "      <td>0.132750</td>\n",
       "      <td>-0.260766</td>\n",
       "      <td>0.127633</td>\n",
       "      <td>0.714273</td>\n",
       "      <td>-0.840192</td>\n",
       "      <td>0.182652</td>\n",
       "      <td>-0.041949</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 642 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   t_body_acc_mean()_X  t_body_acc_mean()_Y  t_body_acc_mean()_Z  \\\n",
       "0             0.057656             0.129985             0.083852   \n",
       "1            -0.002071             0.055747             0.000216   \n",
       "2             0.006962             0.205607            -0.117723   \n",
       "\n",
       "   t_body_acc_std()_X  t_body_acc_std()_Y  t_body_acc_std()_Z  \\\n",
       "0           -0.991872           -0.932060           -0.841013   \n",
       "1           -0.990160           -0.941033           -0.872439   \n",
       "2           -0.988781           -0.959152           -0.911384   \n",
       "\n",
       "   t_body_acc_mad()_X  t_body_acc_mad()_Y  t_body_acc_mad()_Z  \\\n",
       "0           -0.989898           -0.904046           -0.881322   \n",
       "1           -0.991663           -0.932438           -0.894494   \n",
       "2           -0.988219           -0.954085           -0.905404   \n",
       "\n",
       "   t_body_acc_max()_X  ...  f_body_gyro_Jerk_Mag_kurtosis()  angle0()  \\\n",
       "0           -0.987283  ...                         0.796342 -0.322101   \n",
       "1           -0.989407  ...                         0.882150  0.052825   \n",
       "2           -0.985389  ...                         0.894594  0.132750   \n",
       "\n",
       "   angle1()  angle2()  angle3()  angle4()  angle5()  angle6()  activity_Id  \\\n",
       "0 -0.086128  0.353487 -0.087620 -0.844450  0.179862 -0.040856          5.0   \n",
       "1  0.185877 -0.226373  0.118652 -0.847921  0.176493 -0.041387          5.0   \n",
       "2 -0.260766  0.127633  0.714273 -0.840192  0.182652 -0.041949          5.0   \n",
       "\n",
       "   user_Id  \n",
       "0      1.0  \n",
       "1      1.0  \n",
       "2      1.0  \n",
       "\n",
       "[3 rows x 642 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "rows 500, 501, 502 of Dataset type III :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_body_acc_mean()_X</th>\n",
       "      <th>t_body_acc_mean()_Y</th>\n",
       "      <th>t_body_acc_mean()_Z</th>\n",
       "      <th>t_body_acc_std()_X</th>\n",
       "      <th>t_body_acc_std()_Y</th>\n",
       "      <th>t_body_acc_std()_Z</th>\n",
       "      <th>t_body_acc_mad()_X</th>\n",
       "      <th>t_body_acc_mad()_Y</th>\n",
       "      <th>t_body_acc_mad()_Z</th>\n",
       "      <th>t_body_acc_max()_X</th>\n",
       "      <th>...</th>\n",
       "      <th>f_body_gyro_Jerk_Mag_kurtosis()</th>\n",
       "      <th>angle0()</th>\n",
       "      <th>angle1()</th>\n",
       "      <th>angle2()</th>\n",
       "      <th>angle3()</th>\n",
       "      <th>angle4()</th>\n",
       "      <th>angle5()</th>\n",
       "      <th>angle6()</th>\n",
       "      <th>activity_Id</th>\n",
       "      <th>user_Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>-0.256123</td>\n",
       "      <td>0.125954</td>\n",
       "      <td>-0.191903</td>\n",
       "      <td>-0.349063</td>\n",
       "      <td>-0.213592</td>\n",
       "      <td>-0.330042</td>\n",
       "      <td>-0.508122</td>\n",
       "      <td>-0.331405</td>\n",
       "      <td>-0.301156</td>\n",
       "      <td>-0.228649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.623065</td>\n",
       "      <td>0.624847</td>\n",
       "      <td>0.444219</td>\n",
       "      <td>-0.786394</td>\n",
       "      <td>0.221523</td>\n",
       "      <td>-0.666483</td>\n",
       "      <td>0.321834</td>\n",
       "      <td>0.012201</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>-0.185210</td>\n",
       "      <td>0.246477</td>\n",
       "      <td>-0.088161</td>\n",
       "      <td>-0.317336</td>\n",
       "      <td>-0.221163</td>\n",
       "      <td>-0.377236</td>\n",
       "      <td>-0.509923</td>\n",
       "      <td>-0.369845</td>\n",
       "      <td>-0.327881</td>\n",
       "      <td>-0.228649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.690871</td>\n",
       "      <td>0.782214</td>\n",
       "      <td>-0.032887</td>\n",
       "      <td>-0.617773</td>\n",
       "      <td>-0.314362</td>\n",
       "      <td>-0.667049</td>\n",
       "      <td>0.321434</td>\n",
       "      <td>0.011946</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.147668</td>\n",
       "      <td>0.339981</td>\n",
       "      <td>0.062504</td>\n",
       "      <td>-0.377804</td>\n",
       "      <td>-0.191089</td>\n",
       "      <td>-0.335916</td>\n",
       "      <td>-0.530940</td>\n",
       "      <td>-0.433669</td>\n",
       "      <td>-0.431100</td>\n",
       "      <td>-0.328814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.627910</td>\n",
       "      <td>-0.136157</td>\n",
       "      <td>-0.764817</td>\n",
       "      <td>-0.496185</td>\n",
       "      <td>0.436664</td>\n",
       "      <td>-0.675287</td>\n",
       "      <td>0.315955</td>\n",
       "      <td>0.013633</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 642 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     t_body_acc_mean()_X  t_body_acc_mean()_Y  t_body_acc_mean()_Z  \\\n",
       "500            -0.256123             0.125954            -0.191903   \n",
       "501            -0.185210             0.246477            -0.088161   \n",
       "502             0.147668             0.339981             0.062504   \n",
       "\n",
       "     t_body_acc_std()_X  t_body_acc_std()_Y  t_body_acc_std()_Z  \\\n",
       "500           -0.349063           -0.213592           -0.330042   \n",
       "501           -0.317336           -0.221163           -0.377236   \n",
       "502           -0.377804           -0.191089           -0.335916   \n",
       "\n",
       "     t_body_acc_mad()_X  t_body_acc_mad()_Y  t_body_acc_mad()_Z  \\\n",
       "500           -0.508122           -0.331405           -0.301156   \n",
       "501           -0.509923           -0.369845           -0.327881   \n",
       "502           -0.530940           -0.433669           -0.431100   \n",
       "\n",
       "     t_body_acc_max()_X  ...  f_body_gyro_Jerk_Mag_kurtosis()  angle0()  \\\n",
       "500           -0.228649  ...                         0.623065  0.624847   \n",
       "501           -0.228649  ...                         0.690871  0.782214   \n",
       "502           -0.328814  ...                         0.627910 -0.136157   \n",
       "\n",
       "     angle1()  angle2()  angle3()  angle4()  angle5()  angle6()  activity_Id  \\\n",
       "500  0.444219 -0.786394  0.221523 -0.666483  0.321834  0.012201          1.0   \n",
       "501 -0.032887 -0.617773 -0.314362 -0.667049  0.321434  0.011946          1.0   \n",
       "502 -0.764817 -0.496185  0.436664 -0.675287  0.315955  0.013633          1.0   \n",
       "\n",
       "     user_Id  \n",
       "500      2.0  \n",
       "501      2.0  \n",
       "502      2.0  \n",
       "\n",
       "[3 rows x 642 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Description of the 10 first features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_body_acc_mean()_X</th>\n",
       "      <th>t_body_acc_mean()_Y</th>\n",
       "      <th>t_body_acc_mean()_Z</th>\n",
       "      <th>t_body_acc_std()_X</th>\n",
       "      <th>t_body_acc_std()_Y</th>\n",
       "      <th>t_body_acc_std()_Z</th>\n",
       "      <th>t_body_acc_mad()_X</th>\n",
       "      <th>t_body_acc_mad()_Y</th>\n",
       "      <th>t_body_acc_mad()_Z</th>\n",
       "      <th>t_body_acc_max()_X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.011355</td>\n",
       "      <td>0.121200</td>\n",
       "      <td>-0.019519</td>\n",
       "      <td>-0.515584</td>\n",
       "      <td>-0.476947</td>\n",
       "      <td>-0.512558</td>\n",
       "      <td>-0.619226</td>\n",
       "      <td>-0.548228</td>\n",
       "      <td>-0.645105</td>\n",
       "      <td>-0.401212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.200167</td>\n",
       "      <td>0.155037</td>\n",
       "      <td>0.171783</td>\n",
       "      <td>0.488067</td>\n",
       "      <td>0.456181</td>\n",
       "      <td>0.436934</td>\n",
       "      <td>0.391496</td>\n",
       "      <td>0.390565</td>\n",
       "      <td>0.307630</td>\n",
       "      <td>0.607955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.066911</td>\n",
       "      <td>0.044710</td>\n",
       "      <td>-0.100364</td>\n",
       "      <td>-0.970934</td>\n",
       "      <td>-0.938405</td>\n",
       "      <td>-0.941182</td>\n",
       "      <td>-0.970784</td>\n",
       "      <td>-0.932536</td>\n",
       "      <td>-0.943506</td>\n",
       "      <td>-0.971241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.011944</td>\n",
       "      <td>0.121372</td>\n",
       "      <td>-0.021476</td>\n",
       "      <td>-0.663600</td>\n",
       "      <td>-0.419682</td>\n",
       "      <td>-0.503877</td>\n",
       "      <td>-0.778651</td>\n",
       "      <td>-0.549399</td>\n",
       "      <td>-0.660385</td>\n",
       "      <td>-0.603108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.090482</td>\n",
       "      <td>0.196587</td>\n",
       "      <td>0.060745</td>\n",
       "      <td>-0.131784</td>\n",
       "      <td>-0.085841</td>\n",
       "      <td>-0.162395</td>\n",
       "      <td>-0.312013</td>\n",
       "      <td>-0.223594</td>\n",
       "      <td>-0.399430</td>\n",
       "      <td>0.102554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       t_body_acc_mean()_X  t_body_acc_mean()_Y  t_body_acc_mean()_Z  \\\n",
       "count         11162.000000         11162.000000         11162.000000   \n",
       "mean              0.011355             0.121200            -0.019519   \n",
       "std               0.200167             0.155037             0.171783   \n",
       "min              -1.000000            -1.000000            -1.000000   \n",
       "25%              -0.066911             0.044710            -0.100364   \n",
       "50%               0.011944             0.121372            -0.021476   \n",
       "75%               0.090482             0.196587             0.060745   \n",
       "max               1.000000             1.000000             1.000000   \n",
       "\n",
       "       t_body_acc_std()_X  t_body_acc_std()_Y  t_body_acc_std()_Z  \\\n",
       "count        11162.000000        11162.000000        11162.000000   \n",
       "mean            -0.515584           -0.476947           -0.512558   \n",
       "std              0.488067            0.456181            0.436934   \n",
       "min             -1.000000           -1.000000           -1.000000   \n",
       "25%             -0.970934           -0.938405           -0.941182   \n",
       "50%             -0.663600           -0.419682           -0.503877   \n",
       "75%             -0.131784           -0.085841           -0.162395   \n",
       "max              1.000000            1.000000            1.000000   \n",
       "\n",
       "       t_body_acc_mad()_X  t_body_acc_mad()_Y  t_body_acc_mad()_Z  \\\n",
       "count        11162.000000        11162.000000        11162.000000   \n",
       "mean            -0.619226           -0.548228           -0.645105   \n",
       "std              0.391496            0.390565            0.307630   \n",
       "min             -1.000000           -1.000000           -1.000000   \n",
       "25%             -0.970784           -0.932536           -0.943506   \n",
       "50%             -0.778651           -0.549399           -0.660385   \n",
       "75%             -0.312013           -0.223594           -0.399430   \n",
       "max              1.000000            1.000000            1.000000   \n",
       "\n",
       "       t_body_acc_max()_X  \n",
       "count        11162.000000  \n",
       "mean            -0.401212  \n",
       "std              0.607955  \n",
       "min             -1.000000  \n",
       "25%             -0.971241  \n",
       "50%             -0.603108  \n",
       "75%              0.102554  \n",
       "max              1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Description of the 10 first frequency features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_body_acc_mean()_X</th>\n",
       "      <th>f_body_acc_mean()_Y</th>\n",
       "      <th>f_body_acc_mean()_Z</th>\n",
       "      <th>f_body_acc_std()_X</th>\n",
       "      <th>f_body_acc_std()_Y</th>\n",
       "      <th>f_body_acc_std()_Z</th>\n",
       "      <th>f_body_acc_mad()_X</th>\n",
       "      <th>f_body_acc_mad()_Y</th>\n",
       "      <th>f_body_acc_mad()_Z</th>\n",
       "      <th>f_body_acc_max()_X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "      <td>11162.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.498643</td>\n",
       "      <td>-0.508352</td>\n",
       "      <td>-0.552127</td>\n",
       "      <td>-0.523097</td>\n",
       "      <td>-0.531273</td>\n",
       "      <td>-0.536929</td>\n",
       "      <td>-0.707776</td>\n",
       "      <td>-0.618896</td>\n",
       "      <td>-0.719974</td>\n",
       "      <td>-0.578219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.510374</td>\n",
       "      <td>0.455424</td>\n",
       "      <td>0.425528</td>\n",
       "      <td>0.480220</td>\n",
       "      <td>0.399930</td>\n",
       "      <td>0.408716</td>\n",
       "      <td>0.317442</td>\n",
       "      <td>0.394940</td>\n",
       "      <td>0.301464</td>\n",
       "      <td>0.438375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.978379</td>\n",
       "      <td>-0.962982</td>\n",
       "      <td>-0.963372</td>\n",
       "      <td>-0.967025</td>\n",
       "      <td>-0.934971</td>\n",
       "      <td>-0.932897</td>\n",
       "      <td>-0.987707</td>\n",
       "      <td>-0.977952</td>\n",
       "      <td>-0.976274</td>\n",
       "      <td>-0.964006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.652604</td>\n",
       "      <td>-0.494953</td>\n",
       "      <td>-0.559897</td>\n",
       "      <td>-0.674504</td>\n",
       "      <td>-0.480512</td>\n",
       "      <td>-0.536440</td>\n",
       "      <td>-0.812506</td>\n",
       "      <td>-0.721652</td>\n",
       "      <td>-0.823696</td>\n",
       "      <td>-0.744999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.076308</td>\n",
       "      <td>-0.114467</td>\n",
       "      <td>-0.202494</td>\n",
       "      <td>-0.156821</td>\n",
       "      <td>-0.192438</td>\n",
       "      <td>-0.228271</td>\n",
       "      <td>-0.481343</td>\n",
       "      <td>-0.319173</td>\n",
       "      <td>-0.519640</td>\n",
       "      <td>-0.271756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f_body_acc_mean()_X  f_body_acc_mean()_Y  f_body_acc_mean()_Z  \\\n",
       "count         11162.000000         11162.000000         11162.000000   \n",
       "mean             -0.498643            -0.508352            -0.552127   \n",
       "std               0.510374             0.455424             0.425528   \n",
       "min              -1.000000            -1.000000            -1.000000   \n",
       "25%              -0.978379            -0.962982            -0.963372   \n",
       "50%              -0.652604            -0.494953            -0.559897   \n",
       "75%              -0.076308            -0.114467            -0.202494   \n",
       "max               1.000000             1.000000             1.000000   \n",
       "\n",
       "       f_body_acc_std()_X  f_body_acc_std()_Y  f_body_acc_std()_Z  \\\n",
       "count        11162.000000        11162.000000        11162.000000   \n",
       "mean            -0.523097           -0.531273           -0.536929   \n",
       "std              0.480220            0.399930            0.408716   \n",
       "min             -1.000000           -1.000000           -1.000000   \n",
       "25%             -0.967025           -0.934971           -0.932897   \n",
       "50%             -0.674504           -0.480512           -0.536440   \n",
       "75%             -0.156821           -0.192438           -0.228271   \n",
       "max              1.000000            1.000000            1.000000   \n",
       "\n",
       "       f_body_acc_mad()_X  f_body_acc_mad()_Y  f_body_acc_mad()_Z  \\\n",
       "count        11162.000000        11162.000000        11162.000000   \n",
       "mean            -0.707776           -0.618896           -0.719974   \n",
       "std              0.317442            0.394940            0.301464   \n",
       "min             -1.000000           -1.000000           -1.000000   \n",
       "25%             -0.987707           -0.977952           -0.976274   \n",
       "50%             -0.812506           -0.721652           -0.823696   \n",
       "75%             -0.481343           -0.319173           -0.519640   \n",
       "max              1.000000            1.000000            1.000000   \n",
       "\n",
       "       f_body_acc_max()_X  \n",
       "count        11162.000000  \n",
       "mean            -0.578219  \n",
       "std              0.438375  \n",
       "min             -1.000000  \n",
       "25%             -0.964006  \n",
       "50%             -0.744999  \n",
       "75%             -0.271756  \n",
       "max              1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Number of windows per user and per each activity:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "      <th>P_Transitions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User 1</th>\n",
       "      <td>108</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>44</td>\n",
       "      <td>54</td>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 2</th>\n",
       "      <td>65</td>\n",
       "      <td>54</td>\n",
       "      <td>53</td>\n",
       "      <td>45</td>\n",
       "      <td>47</td>\n",
       "      <td>45</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 3</th>\n",
       "      <td>64</td>\n",
       "      <td>69</td>\n",
       "      <td>58</td>\n",
       "      <td>40</td>\n",
       "      <td>43</td>\n",
       "      <td>57</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 4</th>\n",
       "      <td>65</td>\n",
       "      <td>58</td>\n",
       "      <td>56</td>\n",
       "      <td>38</td>\n",
       "      <td>47</td>\n",
       "      <td>44</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 5</th>\n",
       "      <td>62</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>35</td>\n",
       "      <td>39</td>\n",
       "      <td>49</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 6</th>\n",
       "      <td>60</td>\n",
       "      <td>44</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "      <td>46</td>\n",
       "      <td>44</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 7</th>\n",
       "      <td>58</td>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>42</td>\n",
       "      <td>49</td>\n",
       "      <td>44</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 8</th>\n",
       "      <td>54</td>\n",
       "      <td>35</td>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 9</th>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>53</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>32</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 10</th>\n",
       "      <td>57</td>\n",
       "      <td>53</td>\n",
       "      <td>49</td>\n",
       "      <td>47</td>\n",
       "      <td>36</td>\n",
       "      <td>50</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 11</th>\n",
       "      <td>66</td>\n",
       "      <td>60</td>\n",
       "      <td>56</td>\n",
       "      <td>46</td>\n",
       "      <td>50</td>\n",
       "      <td>52</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 12</th>\n",
       "      <td>58</td>\n",
       "      <td>61</td>\n",
       "      <td>53</td>\n",
       "      <td>44</td>\n",
       "      <td>51</td>\n",
       "      <td>48</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 13</th>\n",
       "      <td>63</td>\n",
       "      <td>62</td>\n",
       "      <td>55</td>\n",
       "      <td>46</td>\n",
       "      <td>53</td>\n",
       "      <td>57</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 14</th>\n",
       "      <td>67</td>\n",
       "      <td>44</td>\n",
       "      <td>46</td>\n",
       "      <td>50</td>\n",
       "      <td>52</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 15</th>\n",
       "      <td>60</td>\n",
       "      <td>53</td>\n",
       "      <td>50</td>\n",
       "      <td>59</td>\n",
       "      <td>51</td>\n",
       "      <td>61</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 16</th>\n",
       "      <td>57</td>\n",
       "      <td>57</td>\n",
       "      <td>55</td>\n",
       "      <td>63</td>\n",
       "      <td>79</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 17</th>\n",
       "      <td>67</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>63</td>\n",
       "      <td>79</td>\n",
       "      <td>63</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 18</th>\n",
       "      <td>62</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>60</td>\n",
       "      <td>77</td>\n",
       "      <td>67</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 19</th>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>15</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>83</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 20</th>\n",
       "      <td>44</td>\n",
       "      <td>52</td>\n",
       "      <td>54</td>\n",
       "      <td>58</td>\n",
       "      <td>57</td>\n",
       "      <td>63</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 21</th>\n",
       "      <td>59</td>\n",
       "      <td>53</td>\n",
       "      <td>55</td>\n",
       "      <td>80</td>\n",
       "      <td>85</td>\n",
       "      <td>84</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 22</th>\n",
       "      <td>52</td>\n",
       "      <td>40</td>\n",
       "      <td>46</td>\n",
       "      <td>53</td>\n",
       "      <td>57</td>\n",
       "      <td>60</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 23</th>\n",
       "      <td>38</td>\n",
       "      <td>56</td>\n",
       "      <td>42</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>69</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 24</th>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>67</td>\n",
       "      <td>63</td>\n",
       "      <td>67</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 25</th>\n",
       "      <td>80</td>\n",
       "      <td>72</td>\n",
       "      <td>66</td>\n",
       "      <td>64</td>\n",
       "      <td>72</td>\n",
       "      <td>55</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 26</th>\n",
       "      <td>65</td>\n",
       "      <td>61</td>\n",
       "      <td>60</td>\n",
       "      <td>76</td>\n",
       "      <td>73</td>\n",
       "      <td>76</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 27</th>\n",
       "      <td>63</td>\n",
       "      <td>59</td>\n",
       "      <td>56</td>\n",
       "      <td>70</td>\n",
       "      <td>81</td>\n",
       "      <td>72</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 28</th>\n",
       "      <td>63</td>\n",
       "      <td>59</td>\n",
       "      <td>55</td>\n",
       "      <td>59</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 29</th>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>56</td>\n",
       "      <td>60</td>\n",
       "      <td>68</td>\n",
       "      <td>69</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 30</th>\n",
       "      <td>71</td>\n",
       "      <td>72</td>\n",
       "      <td>71</td>\n",
       "      <td>61</td>\n",
       "      <td>52</td>\n",
       "      <td>63</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  \\\n",
       "User 1          108          61          61          44          54   \n",
       "User 2           65          54          53          45          47   \n",
       "User 3           64          69          58          40          43   \n",
       "User 4           65          58          56          38          47   \n",
       "User 5           62          55          56          35          39   \n",
       "User 6           60          44          33          40          46   \n",
       "User 7           58          57          57          42          49   \n",
       "User 8           54          35          38          40          52   \n",
       "User 9           56          56          53          39          42   \n",
       "User 10          57          53          49          47          36   \n",
       "User 11          66          60          56          46          50   \n",
       "User 12          58          61          53          44          51   \n",
       "User 13          63          62          55          46          53   \n",
       "User 14          67          44          46          50          52   \n",
       "User 15          60          53          50          59          51   \n",
       "User 16          57          57          55          63          79   \n",
       "User 17          67          56          56          63          79   \n",
       "User 18          62          65          65          60          77   \n",
       "User 19          30          29          15          70          70   \n",
       "User 20          44          52          54          58          57   \n",
       "User 21          59          53          55          80          85   \n",
       "User 22          52          40          46          53          57   \n",
       "User 23          38          56          42          62          63   \n",
       "User 24          65          65          65          67          63   \n",
       "User 25          80          72          66          64          72   \n",
       "User 26          65          61          60          76          73   \n",
       "User 27          63          59          56          70          81   \n",
       "User 28          63          59          55          59          64   \n",
       "User 29          58          58          56          60          68   \n",
       "User 30          71          72          71          61          52   \n",
       "\n",
       "         Activity 6  P_Transitions  \n",
       "User 1           39             37  \n",
       "User 2           45             36  \n",
       "User 3           57             30  \n",
       "User 4           44             37  \n",
       "User 5           49             39  \n",
       "User 6           44             21  \n",
       "User 7           44             22  \n",
       "User 8           43             25  \n",
       "User 9           32             24  \n",
       "User 10          50             11  \n",
       "User 11          52             33  \n",
       "User 12          48             33  \n",
       "User 13          57             36  \n",
       "User 14          41             42  \n",
       "User 15          61             30  \n",
       "User 16          70             31  \n",
       "User 17          63             39  \n",
       "User 18          67             42  \n",
       "User 19          83             33  \n",
       "User 20          63             42  \n",
       "User 21          84             37  \n",
       "User 22          60             26  \n",
       "User 23          69             26  \n",
       "User 24          67             40  \n",
       "User 25          55             42  \n",
       "User 26          76             34  \n",
       "User 27          72             26  \n",
       "User 28          65             19  \n",
       "User 29          69             34  \n",
       "User 30          63             26  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Statistics of table above:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "      <th>P_Transitions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>61.233333</td>\n",
       "      <td>55.866667</td>\n",
       "      <td>53.033333</td>\n",
       "      <td>54.033333</td>\n",
       "      <td>58.400000</td>\n",
       "      <td>57.733333</td>\n",
       "      <td>31.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.934006</td>\n",
       "      <td>9.754692</td>\n",
       "      <td>10.697996</td>\n",
       "      <td>12.321787</td>\n",
       "      <td>13.586504</td>\n",
       "      <td>13.266326</td>\n",
       "      <td>7.824292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>57.250000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>50.750000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>49.250000</td>\n",
       "      <td>45.750000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>53.500000</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>65.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>56.750000</td>\n",
       "      <td>62.750000</td>\n",
       "      <td>69.500000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>108.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  Activity 6  \\\n",
       "count   30.000000   30.000000   30.000000   30.000000   30.000000   30.000000   \n",
       "mean    61.233333   55.866667   53.033333   54.033333   58.400000   57.733333   \n",
       "std     12.934006    9.754692   10.697996   12.321787   13.586504   13.266326   \n",
       "min     30.000000   29.000000   15.000000   35.000000   36.000000   32.000000   \n",
       "25%     57.250000   53.000000   50.750000   44.000000   49.250000   45.750000   \n",
       "50%     62.000000   57.000000   55.000000   55.500000   53.500000   58.500000   \n",
       "75%     65.000000   61.000000   56.750000   62.750000   69.500000   67.000000   \n",
       "max    108.000000   72.000000   71.000000   80.000000   85.000000   84.000000   \n",
       "\n",
       "       P_Transitions  \n",
       "count      30.000000  \n",
       "mean       31.766667  \n",
       "std         7.824292  \n",
       "min        11.000000  \n",
       "25%        26.000000  \n",
       "50%        33.000000  \n",
       "75%        37.000000  \n",
       "max        42.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "_____ The weights of each activity _____\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "      <th>Activity 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Weights</th>\n",
       "      <td>0.164576</td>\n",
       "      <td>0.150152</td>\n",
       "      <td>0.142537</td>\n",
       "      <td>0.145225</td>\n",
       "      <td>0.156961</td>\n",
       "      <td>0.155169</td>\n",
       "      <td>0.085379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  \\\n",
       "Weights    0.164576    0.150152    0.142537    0.145225    0.156961   \n",
       "\n",
       "         Activity 6  Activity 7  \n",
       "Weights    0.155169    0.085379  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# apply the data exploration pipeline to scaled dataset type III\n",
    "data_exploration_pipeline(scaled_type_III,3,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Train-Test Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V.1. Train-Test Datasets creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique Users Ids used for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# volunteersids used for training\n",
    "train_users =[1,3,5,6,7,8,10,11,14,15,27,17,21,29,30,16,19,20,22,23,25,]\n",
    "\n",
    "# volunteers ids used for testing\n",
    "test_users = [2,4,9,12,13,26,18,28,24,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_testing_data(scaled_Df,train_users,test_users,typ):\n",
    "    # inputs:\n",
    "    #        scaled_DF : pandas dataframe already scaled\n",
    "    #       train_users: list of integers contains train user ids \n",
    "    #       train_users: list of integers contains test user ids \n",
    "    #       typ        : integer from 1 to 3 (depending on the dataset type)\n",
    "    \n",
    "    # select rows related to train users ids store them in numpy array\n",
    "    array_train =np.array([np.array(scaled_Df.iloc[i]) \n",
    "                           for i in range(len(scaled_Df)) if int(scaled_Df['user_Id'].iloc[i]) in train_users])\n",
    "    # select rows related to test users ids store them in numpy array\n",
    "    array_test  =np.array([np.array(scaled_Df.iloc[i]) \n",
    "                           for i in range(len(scaled_Df)) if int(scaled_Df['user_Id'].iloc[i]) in test_users])\n",
    "    \n",
    "    # columns names\n",
    "    columns=scaled_Df.columns\n",
    "    \n",
    "    # build train and test dataframes from numpy arrays above\n",
    "    Df_train= pd.DataFrame(data= array_train,columns=columns)\n",
    "    Df_test = pd.DataFrame(data= array_test,columns=columns)\n",
    "    \n",
    "    \n",
    "    # train features dataframe\n",
    "    Df_train_features= Df_train[columns[:-2]]\n",
    "    # train labels dataframe\n",
    "    Df_train_labels  = Df_train[columns[-2:-1]]\n",
    "    # train user id labels dataframe\n",
    "    Df_train_users   = Df_train[columns[-1]]\n",
    "    \n",
    "    # test features dataframe\n",
    "    Df_test_features= Df_test[columns[:-2]]\n",
    "    # test labels dataframe\n",
    "    Df_test_labels  = Df_test[columns[-2:-1]]\n",
    "    # test user id labels dataframe\n",
    "    Df_test_users   = Df_test[columns[-1]]\n",
    "    \n",
    "    # 2D numpy array : train features\n",
    "    X_train =np.array(Df_train_features)\n",
    "    \n",
    "    # 2D numpy array : test features\n",
    "    X_test  =np.array(Df_test_features)\n",
    "    \n",
    "    # 1D numpy array : train labels\n",
    "    y_train= np.array(Df_train_labels['activity_Id'])\n",
    "    \n",
    "    # 1D numpy array : test labels\n",
    "    y_test = np.array(Df_test_labels ['activity_Id'])\n",
    "    \n",
    "    # adapting the dataset name switch the case\n",
    "    if typ==1:\n",
    "           Dataset_name=\"Dataset type I\"\n",
    "    if typ==2:\n",
    "           Dataset_name=\"Dataset type II\"\n",
    "    if typ==3:\n",
    "           Dataset_name=\"Dataset type III\"\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"______________________________\"+Dataset_name+\" Train features & labels info:______________________________________\")\n",
    "    print(\"\")\n",
    "    visualize_column(Df_train,'activity_Id')# visualize activity distribution of train dataframe\n",
    "    print(\"\")\n",
    "    print(\"______________________________Test features & labels info:______________________________________\")\n",
    "    print(\"\")\n",
    "    visualize_column(Df_test,'activity_Id') # visualize the activity distribution of the test dataframe\n",
    "    \n",
    "    return  [X_train, X_test, y_train, y_test] # return train and test numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary will contain train and test files of each dataframe type\n",
    "train_test_files_dic={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "______________________________Dataset type I Train features & labels info:______________________________________\n",
      "\n",
      "_____ The weights of each activity _____\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Weights</th>\n",
       "      <td>0.179491</td>\n",
       "      <td>0.154206</td>\n",
       "      <td>0.141096</td>\n",
       "      <td>0.164351</td>\n",
       "      <td>0.180272</td>\n",
       "      <td>0.180584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  \\\n",
       "Weights    0.179491    0.154206    0.141096    0.164351    0.180272   \n",
       "\n",
       "         Activity 6  \n",
       "Weights    0.180584  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAHFCAYAAAAT5Oa6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABNr0lEQVR4nO3de1zO9/8/8Melw1VRUelEKmNIKGxO26dayCGnGFbMaeZMZKbZVLYxNmljmC3lFHbQnDaT4+Y0JIccMpaY1TK1EqnU6/uHX++fS6XrynV1ej/ut9t1u7le79f7/X6+X1f08HofLoUQQoCIiIhIxupUdQFEREREVY2BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIao3o6GgoFAoYGRkhJSWlxHJPT0+4urpWQWXAoUOHoFAo8P3331fJ/jV148YN9O3bFxYWFlAoFAgMDCyzr5OTExQKBRQKBerUqQNzc3O0atUKb775Jvbu3ftcdaxcuRLR0dHPtY3K4uTkhNGjR1do3ZiYGERERGi1ntrmWWOkUCgQGhqq8TaL/824ceOGWvuh2k2/qgsg0ra8vDy8//772LBhQ1WXUmPNnDkTv//+O9auXQtbW1vY2dk9s3+3bt3w2WefAQBycnKQlJSELVu2wMfHB4MHD8bmzZthYGCgcR0rV66ElZVVhYNGZYqNjYWZmVmF1o2JiUFiYuIzg6fcPWuMjh8/jsaNG2u8zb59++L48eMqP9/8LOSLgYhqnV69eiEmJgazZ89Gu3btqrqcSpWbmwsjIyMoFIrn2k5iYiJefvllDBw4UK3+9evXR+fOnaX33bt3x5QpUxAaGoqwsDC8//77WLx48XPVVN25u7tXdQmVrqCgAAqFAvr6Vfur5MmfPU00bNgQDRs21HI1VFPxlBnVOnPmzIGlpSXefffdZ/a7ceMGFApFqadknp6CDw0NhUKhwPnz5/H666/D3NwcFhYWmDVrFh49eoSkpCT06tULpqamcHJywpIlS0rd58OHDzFr1izY2trC2NgYHh4eSEhIKNHv9OnT6N+/PywsLGBkZAR3d3d8++23Kn2Kp/v37t2LsWPHomHDhjAxMUFeXl6Zx3zz5k2MGDEC1tbWUCqVaNWqFZYuXYqioiIA///U3rVr1/Dzzz9Lp8KePKWgidDQULRu3RorVqzAw4cPpfawsDB06tQJFhYWMDMzQ/v27REZGYknv2vayckJFy9exOHDh6U6nJycpHEMCgqCm5ub9Fl06dIF27dvV6uu4tOnv/32Gzp37gxjY2M0atQIH3zwAQoLC1X6ZmRkYPLkyWjUqBEMDQ3RtGlTzJs3r8Q4P33KrHgsN2/ejHnz5sHe3h5mZmbo3r07kpKSVGrZvXs3UlJSpON8MtCuWrUK7dq1Q7169WBqaoqWLVvivffee+bxFf9sL1myBB9//DGaNGkCIyMjdOzYEfv37y/R/48//oC/v7/Kz8WXX36p0qf4eDZs2ICgoCA0atQISqUS165dK7MOdT7nYjExMejSpQvq1auHevXqwc3NDZGRkWqN0ZN/X8+dOweFQiGt+6Tin+kdO3YAKHnKrKz9CCHQvHlz+Pj4lNhmTk4OzM3NMWXKlDLHgWoGBiKqdUxNTfH+++/jl19+wYEDB7S67aFDh6Jdu3b44YcfMH78eCxbtgwzZ87EwIED0bdvX8TGxuK1117Du+++i23btpVY/7333sOff/6Jb775Bt988w3+/vtveHp64s8//5T6HDx4EN26dcN///2H1atXY/v27XBzc8OwYcNKDW9jx46FgYEBNmzYgO+//77MU1N37txB165dsXfvXnz44YfYsWMHunfvjtmzZ2Pq1KkAgPbt2+P48eOwtbVFt27dcPz48RKnFDTVr18/PHjwAKdPn5babty4gQkTJuDbb7/Ftm3b4Ofnh2nTpuHDDz+U+sTGxqJp06Zwd3eX6oiNjQXw+LRoRkYGZs+ejR9//BGbN2/GK6+8Aj8/P6xfv16tutLS0jB8+HAEBARg+/btGDJkCD766CPMmDFD6vPw4UN4eXlh/fr1mDVrFnbv3o0RI0ZgyZIl8PPzU2s/7733HlJSUvDNN99gzZo1+OOPP9CvXz8peK1cuRLdunWDra2tdJzHjx8HAGzZsgWTJ0+Gh4cHYmNj8eOPP2LmzJm4f/++WvtesWIF9uzZg4iICGzcuBF16tRB7969pe0DwKVLl/DSSy8hMTERS5cuxa5du9C3b19Mnz4dYWFhJbYZHByMmzdvYvXq1di5cyesra3L3L86nzMAzJ8/HwEBAbC3t0d0dDRiY2MxatQo6VrAZ43R09q1awd3d3dERUWVWBYdHQ1ra2v06dOn1HXL2o9CocC0adMQFxeHP/74Q2Wd9evXIzs7m4GoNhBEtURUVJQAIE6dOiXy8vJE06ZNRceOHUVRUZEQQggPDw/RunVrqX9ycrIAIKKiokpsC4AICQmR3oeEhAgAYunSpSr93NzcBACxbds2qa2goEA0bNhQ+Pn5SW0HDx4UAET79u2leoQQ4saNG8LAwEC89dZbUlvLli2Fu7u7KCgoUNmXr6+vsLOzE4WFhSrH++abb6o1PnPnzhUAxO+//67SPmnSJKFQKERSUpLU5ujoKPr27avWdsvru2rVKgFAbN26tdTlhYWFoqCgQCxYsEBYWlqqjE/r1q2Fh4dHuTU8evRIFBQUiHHjxgl3d/dy+3t4eAgAYvv27Srt48ePF3Xq1BEpKSlCCCFWr14tAIhvv/1Wpd/ixYsFALF3716pzdHRUYwaNUp6X/yZ9+nTR2Xdb7/9VgAQx48fl9r69u0rHB0dS9Q5depUUb9+/XKP52nFP9v29vYiNzdXas/OzhYWFhaie/fuUpuPj49o3LixyMrKKrFvIyMjkZGRoXI8//vf/zSuR4iyP+c///xT6OnpiYCAgGeuX9YYCVHy7+sXX3whAKj8TGdkZAilUimCgoKktuK/Q8nJyeXuJzs7W5iamooZM2aotLu4uAgvL69n1k41A2eIqFYyNDTERx99hNOnT5c41fQ8fH19Vd63atUKCoUCvXv3ltr09fXRrFmzUu908/f3V5nqd3R0RNeuXXHw4EEAwLVr13DlyhUEBAQAAB49eiS9+vTpg9TUVJXTLQAwePBgtWo/cOAAXFxc8PLLL6u0jx49GkIIrc+mFROlnB45cOAAunfvDnNzc+jp6cHAwADz58/H3bt3kZ6ertZ2v/vuO3Tr1g316tWDvr4+DAwMEBkZicuXL6u1vqmpKfr376/S5u/vj6KiIvz6669SnXXr1sWQIUNU+hWfGivt9NPTnt5H27ZtAaDUn4+nvfzyy/jvv//wxhtvYPv27fj333/LXedJfn5+MDIykt6bmpqiX79++PXXX1FYWIiHDx9i//79GDRoEExMTEr8vD18+BAnTpxQ2aa6P2+Aep9zXFwcCgsLtTrDEhAQAKVSqTKjunnzZuTl5WHMmDEV2qapqSnGjBmD6OhoaYbuwIEDuHTpkjTDSjUbAxHVWsOHD0f79u0xb948FBQUaGWbFhYWKu8NDQ1hYmKi8kunuP3Ja2aK2draltp29+5dAMA///wDAJg9ezYMDAxUXpMnTwaAEr8U1T2ddffu3VL72tvbS8t1ofgXf/F+Tp48iZ49ewIAvv76axw9ehSnTp3CvHnzADy+MLw827Ztw9ChQ9GoUSNs3LgRx48fx6lTpzB27NhSx700NjY2JdqKP5/isbh79y5sbW1LXKRubW0NfX19tcbM0tJS5b1SqQSg3nGOHDkSa9euRUpKCgYPHgxra2t06tQJcXFx5a775PE83Zafn4+cnBzcvXsXjx49wvLly0v8vBWfVqroz5u6n/OdO3cAoEJ3iZXFwsIC/fv3x/r166VTk9HR0Xj55ZfRunXrCm932rRpuHfvHjZt2gTg8SnJxo0bY8CAAVqpm6oW7zKjWkuhUGDx4sXo0aMH1qxZU2J5cYh5+uJYXQUD4PF1K6W1Ff/StLKyAvD4Oo2yrlFp0aKFynt17yiztLREampqifa///5bZd/aJITAzp07UbduXXTs2BHA4+tiDAwMsGvXLpUg+eOPP6q93Y0bN8LZ2Rlbt25VOf5nXVD+tOLw+aTiz6f487C0tMTvv/8OIYTKftLT0/Ho0SOdjNnTxowZgzFjxuD+/fv49ddfERISAl9fX1y9ehWOjo7PXLesnzdDQ0PUq1cPBgYG0NPTw8iRI8ucoXF2dlZ5r+7Pm7qfc/FdXn/99RccHBzU2rY6xowZg++++w5xcXFo0qQJTp06hVWrVj3XNps1a4bevXvjyy+/RO/evbFjxw6EhYVBT09PS1VTVeIMEdVq3bt3R48ePbBgwQLk5OSoLLOxsYGRkRHOnz+v0q7unUoVsXnzZpVTSCkpKTh27Bg8PT0BPA47zZs3x7lz59CxY8dSX6amphXat7e3Ny5duoQzZ86otK9fvx4KhQJeXl4VPq6yhIWF4dKlS5gxY4b0S7H4Nu0nf4nk5uaW+twopVJZ6kyKQqGAoaGhyi/ntLQ0jT67e/fuSXcbFYuJiUGdOnXwv//9D8DjMcvJySnxS7z4wm1vb2+19/csZR3nk+rWrYvevXtj3rx5yM/Px8WLF8vd7rZt21RmzO7du4edO3fi1VdfhZ6eHkxMTODl5YWEhAS0bdu21J+3p2e41KXu59yzZ0/o6emVG1bUGaOnt9uoUSNERUUhKioKRkZGeOONN8pdr7z9zJgxA+fPn8eoUaOgp6eH8ePHq10TVW+cIaJab/HixejQoQPS09NVpssVCgVGjBiBtWvX4oUXXkC7du1w8uRJxMTE6KyW9PR0DBo0COPHj0dWVhZCQkJgZGSE4OBgqc9XX32F3r17w8fHB6NHj0ajRo2QkZGBy5cv48yZM/juu+8qtO+ZM2di/fr16Nu3LxYsWABHR0fs3r0bK1euxKRJk/Diiy9W+Lj+++8/6VqT+/fvSw9m/O233zB06FCVu5X69u2L8PBw+Pv74+2338bdu3fx2WefSaeSntSmTRts2bIFW7duRdOmTWFkZIQ2bdrA19cX27Ztw+TJkzFkyBDcunULH374Iezs7ErcBVQWS0tLTJo0CTdv3sSLL76In376CV9//TUmTZqEJk2aAADefPNNfPnllxg1ahRu3LiBNm3a4MiRI1i4cCH69OmD7t27V3jMnj7Obdu2YdWqVejQoQPq1KmDjh07Yvz48TA2Nka3bt1gZ2eHtLQ0LFq0CObm5njppZfK3a6enh569OiBWbNmoaioCIsXL0Z2drbK5/H555/jlVdewauvvopJkybByckJ9+7dw7Vr17Bz584KX1um7ufs5OSE9957Dx9++CFyc3PxxhtvwNzcHJcuXcK///4r1VrWGD3r2N98802Eh4fDzMwMfn5+MDc3L7fu8vbTo0cPuLi44ODBg9IjLKiWqNJLuom06Mm7zJ7m7+8vAKjcZSaEEFlZWeKtt94SNjY2om7duqJfv37ixo0bZd5ldufOHZX1R40aJerWrVtif0/f0VZ8h86GDRvE9OnTRcOGDYVSqRSvvvqqOH36dIn1z507J4YOHSqsra2FgYGBsLW1Fa+99ppYvXq1WsdblpSUFOHv7y8sLS2FgYGBaNGihfj000+lO9eKaXqXGQABQCgUClGvXj3RokULMXLkSPHLL7+Uus7atWtFixYthFKpFE2bNhWLFi0SkZGRJe74uXHjhujZs6cwNTUVAFTu/vnkk0+Ek5OTUCqVolWrVuLrr7+WPqfyFH8+hw4dEh07dhRKpVLY2dmJ9957r8TdfXfv3hUTJ04UdnZ2Ql9fXzg6Oorg4GDx8OHDEuNQ2l1m3333nUq/0u5uzMjIEEOGDBH169cXCoVCOoZ169YJLy8vYWNjIwwNDYW9vb0YOnSoOH/+/DOPr3gfixcvFmFhYaJx48bC0NBQuLu7l/qZJCcni7Fjx4pGjRoJAwMD0bBhQ9G1a1fx0UcflXs8z6Lu5yyEEOvXrxcvvfSSMDIyEvXq1RPu7u5qjZEQJe8yK3b16lXpZzMuLq7E8tLuMnvWfoqFhoYKAOLEiRNqjwVVfwohSrkFhIioFvP09MS///6LxMTEqi5FJ27cuAFnZ2d8+umnmD17dlWXU+t07NgRCoUCp06dqupSSIt4yoyIiKgc2dnZSExMxK5duxAfHy89JJRqDwYiIiKicpw5cwZeXl6wtLRESEiI2t/zRzUHT5kRERGR7PG2eyIiIpI9BiIiIiKSPQYiIiIikj1eVK2moqIi/P333zA1NVX70fVERERUtYQQuHfvHuzt7VGnzjPmgaryIUiHDx8Wvr6+ws7OTgAQsbGx0rL8/HwxZ84c4erqKkxMTISdnZ0YOXKkuH37tso2Hj58KKZOnSosLS2FiYmJ6Nevn7h165ZKn4yMDDFixAhhZmYmzMzMxIgRI0RmZqZGtd66dUt6wBdffPHFF1988VWzXk9ng6dV6QzR/fv30a5dO4wZMwaDBw9WWfbgwQOcOXMGH3zwAdq1a4fMzEwEBgaif//+OH36tNQvMDAQO3fuxJYtW2BpaYmgoCD4+voiPj5e+g4df39//PXXX9izZw8A4O2338bIkSOxc+dOtWst/v6oW7duwczM7HkPnYiIiCpBdnY2HBwcyv0eyGpz271CoUBsbOwzn+1w6tQpvPzyy0hJSUGTJk2QlZWFhg0bYsOGDRg2bBiAx9/c7eDggJ9++gk+Pj64fPkyXFxccOLECXTq1AkAcOLECXTp0gVXrlwp8c3hZcnOzoa5uTmysrIYiIiIiGoIdX9/16iLqrOysqBQKFC/fn0AQHx8PAoKCtCzZ0+pj729PVxdXXHs2DEAwPHjx2Fubi6FIQDo3LkzzM3NpT5EREQkbzXmouqHDx9i7ty58Pf3lxJeWloaDA0N0aBBA5W+NjY2SEtLk/qU9m3E1tbWUp/S5OXlIS8vT3qfnZ2tjcMgIiKiaqhGzBAVFBRg+PDhKCoqwsqVK8vtL4RQuROstLvCnu7ztEWLFsHc3Fx6OTg4VKx4IiIiqvaqfSAqKCjA0KFDkZycjLi4OJXzf7a2tsjPz0dmZqbKOunp6bCxsZH6/PPPPyW2e+fOHalPaYKDg5GVlSW9bt26paUjIiIiouqmWgei4jD0xx9/YN++fbC0tFRZ3qFDBxgYGCAuLk5qS01NRWJiIrp27QoA6NKlC7KysnDy5Empz++//46srCypT2mUSiXMzMxUXkRERFQ7Vek1RDk5Obh27Zr0Pjk5GWfPnoWFhQXs7e0xZMgQnDlzBrt27UJhYaF0zY+FhQUMDQ1hbm6OcePGISgoCJaWlrCwsMDs2bPRpk0bdO/eHQDQqlUr9OrVC+PHj8dXX30F4PFt976+vmrfYUZERES1W5Xedn/o0CF4eXmVaB81ahRCQ0Ph7Oxc6noHDx6Ep6cngMcXW7/zzjuIiYlBbm4uvL29sXLlSpVrfjIyMjB9+nTs2LEDANC/f3+sWLFCultNHbztnoiIqOZR9/d3tXkOUXXHQERERFTz1MrnEBERERHpAgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJXo35tnsiIqpZnOburuoSqsSNT/o+1/oct6rBGSIiIiKSPc4QVQNy/d8AUPX/IyAiIgI4Q0RERETEQERERETEQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREsqdf1QUQEdUETnN3V3UJVeLGJ32rugSiSsEZIiIiIpI9BiIiIiKSPQYiIiIikj0GIiIiIpI9BiIiIiKSPQYiIiIikj0GIiIiIpI9BiIiIiKSPQYiIiIikj0GIiIiIpI9BiIiIiKSvSoNRL/++iv69esHe3t7KBQK/PjjjyrLhRAIDQ2Fvb09jI2N4enpiYsXL6r0ycvLw7Rp02BlZYW6deuif//++Ouvv1T6ZGZmYuTIkTA3N4e5uTlGjhyJ//77T8dHR0RERDVFlQai+/fvo127dlixYkWpy5csWYLw8HCsWLECp06dgq2tLXr06IF79+5JfQIDAxEbG4stW7bgyJEjyMnJga+vLwoLC6U+/v7+OHv2LPbs2YM9e/bg7NmzGDlypM6Pj4iIiGqGKv22+969e6N3796lLhNCICIiAvPmzYOfnx8AYN26dbCxsUFMTAwmTJiArKwsREZGYsOGDejevTsAYOPGjXBwcMC+ffvg4+ODy5cvY8+ePThx4gQ6deoEAPj666/RpUsXJCUloUWLFpVzsERERFRtVdtriJKTk5GWloaePXtKbUqlEh4eHjh27BgAID4+HgUFBSp97O3t4erqKvU5fvw4zM3NpTAEAJ07d4a5ubnUpzR5eXnIzs5WeREREVHtVG0DUVpaGgDAxsZGpd3GxkZalpaWBkNDQzRo0OCZfaytrUts39raWupTmkWLFknXHJmbm8PBweG5joeIiIiqr2obiIopFAqV90KIEm1Pe7pPaf3L205wcDCysrKk161btzSsnIiIiGqKahuIbG1tAaDELE56ero0a2Rra4v8/HxkZmY+s88///xTYvt37twpMfv0JKVSCTMzM5UXERER1U7VNhA5OzvD1tYWcXFxUlt+fj4OHz6Mrl27AgA6dOgAAwMDlT6pqalITEyU+nTp0gVZWVk4efKk1Of3339HVlaW1IeIiIjkrUrvMsvJycG1a9ek98nJyTh79iwsLCzQpEkTBAYGYuHChWjevDmaN2+OhQsXwsTEBP7+/gAAc3NzjBs3DkFBQbC0tISFhQVmz56NNm3aSHedtWrVCr169cL48ePx1VdfAQDefvtt+Pr68g6zGs5p7u6qLqFK3Pikb1WXQERU61RpIDp9+jS8vLyk97NmzQIAjBo1CtHR0ZgzZw5yc3MxefJkZGZmolOnTti7dy9MTU2ldZYtWwZ9fX0MHToUubm58Pb2RnR0NPT09KQ+mzZtwvTp06W70fr371/ms4+IiIhIfqo0EHl6ekIIUeZyhUKB0NBQhIaGltnHyMgIy5cvx/Lly8vsY2FhgY0bNz5PqURERFSLVdtriIiIiIgqCwMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyR4DEREREckeAxERERHJHgMRERERyZ5+VRdARJXLae7uqi6hStz4pG9Vl0BE1RhniIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9hiIiIiISPYYiIiIiEj2GIiIiIhI9jQORHv27MGRI0ek919++SXc3Nzg7++PzMxMrRZHREREVBk0DkTvvPMOsrOzAQAXLlxAUFAQ+vTpgz///BOzZs3SeoFEREREuqbxt90nJyfDxcUFAPDDDz/A19cXCxcuxJkzZ9CnTx+tF0hERESkaxrPEBkaGuLBgwcAgH379qFnz54AAAsLC2nmiIiIiKgm0XiG6JVXXsGsWbPQrVs3nDx5Elu3bgUAXL16FY0bN9Z6gURERES6pvEM0YoVK6Cvr4/vv/8eq1atQqNGjQAAP//8M3r16qX1AomIiIh0TeMZoiZNmmDXrl0l2pctW6aVgoiIiIgqm8YzRHp6ekhPTy/RfvfuXejp6WmlKCIiIqLKpHEgEkKU2p6XlwdDQ8PnLoiIiIiosql9yuyLL74AACgUCnzzzTeoV6+etKywsBC//vorWrZsqf0KiYiIiHRM7UBUfI2QEAKrV69WOT1maGgIJycnrF69WvsVEhEREemY2oEoOTkZAODl5YVt27ahQYMGOiuKiIiIqDJpfJfZwYMHdVEHERERUZXROBAVFhYiOjoa+/fvR3p6OoqKilSWHzhwQGvFEREREVUGjQPRjBkzEB0djb59+8LV1RUKhUIXdRERERFVGo0D0ZYtW/Dtt99Wyhe5Pnr0CKGhodi0aRPS0tJgZ2eH0aNH4/3330edOo+fGCCEQFhYGNasWYPMzEx06tQJX375JVq3bi1tJy8vD7Nnz8bmzZuRm5sLb29vrFy5kl81QkRERAAq+OWuzZo100UtJSxevBirV6/GihUrcPnyZSxZsgSffvopli9fLvVZsmQJwsPDsWLFCpw6dQq2trbo0aMH7t27J/UJDAxEbGwstmzZgiNHjiAnJwe+vr4oLCyslOMgIiKi6k3jQBQUFITPP/+8zAc0atPx48cxYMAA9O3bF05OThgyZAh69uyJ06dPA3g8OxQREYF58+bBz88Prq6uWLduHR48eICYmBgAQFZWFiIjI7F06VJ0794d7u7u2LhxIy5cuIB9+/bp/BiIiIio+tP4lNmRI0dw8OBB/Pzzz2jdujUMDAxUlm/btk1rxb3yyitYvXo1rl69ihdffBHnzp3DkSNHEBERAeDxowDS0tLQs2dPaR2lUgkPDw8cO3YMEyZMQHx8PAoKClT62Nvbw9XVFceOHYOPj0+p+87Ly0NeXp70Pjs7W2vHRURERNWLxoGofv36GDRokC5qKeHdd99FVlYWWrZsCT09PRQWFuLjjz/GG2+8AQBIS0sDANjY2KisZ2Njg5SUFKmPoaFhiecm2djYSOuXZtGiRQgLC9Pm4RAREVE1pXEgioqK0kUdpdq6dSs2btyImJgYtG7dGmfPnkVgYCDs7e0xatQoqd/Td7oJIcq9+628PsHBwZg1a5b0Pjs7Gw4ODhU8EiIiIqrONA5Elemdd97B3LlzMXz4cABAmzZtkJKSgkWLFmHUqFGwtbUFAOkOtGLp6enSrJGtrS3y8/ORmZmpMkuUnp6Orl27lrlvpVIJpVKpi8MiIiKiakati6rbt2+PzMxMAIC7uzvat29f5kubHjx4IN1eX0xPT096GKSzszNsbW0RFxcnLc/Pz8fhw4elsNOhQwcYGBio9ElNTUViYuIzAxERERHJh1ozRAMGDJBmSwYOHKjLelT069cPH3/8MZo0aYLWrVsjISEB4eHhGDt2LIDHp8oCAwOxcOFCNG/eHM2bN8fChQthYmICf39/AIC5uTnGjRuHoKAgWFpawsLCArNnz0abNm3QvXv3SjsWIiIiqr7UCkQhISGl/lnXli9fjg8++ACTJ09Geno67O3tMWHCBMyfP1/qM2fOHOTm5mLy5MnSgxn37t0LU1NTqc+yZcugr6+PoUOHSg9mjI6Ohp6eXqUdCxEREVVfFb6GKD4+HpcvX4ZCoYCLiwvc3d21WRcAwNTUFBEREdJt9qVRKBQIDQ1FaGhomX2MjIywfPlylQc6EhERERXTOBClp6dj+PDhOHToEOrXrw8hBLKysuDl5YUtW7agYcOGuqiTiIiISGc0flL1tGnTkJ2djYsXLyIjIwOZmZlITExEdnY2pk+frosaiYiIiHRK4xmiPXv2YN++fWjVqpXU5uLigi+//FLladBERERENYXGM0RFRUUlvq4DAAwMDKTb4YmIiIhqEo0D0WuvvYYZM2bg77//ltpu376NmTNnwtvbW6vFEREREVUGjQPRihUrcO/ePTg5OeGFF15As2bN4OzsjHv37vEuLiIiIqqRNL6GyMHBAWfOnEFcXByuXLkCIQRcXFz4kEMiIiKqsSr8HKIePXqgR48e2qyFiIiIqEpofMoMAPbv3w9fX1/plJmvry/27dun7dqIiIiIKkWFriHq1asXTE1NMWPGDEyfPh1mZmbo06cPVqxYoYsaiYiIiHRK41NmixYtwrJlyzB16lSpbfr06ejWrRs+/vhjlXYiIiKimkDjGaLs7Gz06tWrRHvPnj2RnZ2tlaKIiIiIKpPGgah///6IjY0t0b59+3b069dPK0URERERVSaNT5m1atUKH3/8MQ4dOoQuXboAAE6cOIGjR48iKCgIX3zxhdSX321GRERENYHGgSgyMhINGjTApUuXcOnSJam9fv36iIyMlN4rFAoGIiIiIqoRNA5EycnJuqiDiIiIqMpU6DlERERERLUJAxERERHJHgMRERERyR4DEREREckeAxERERHJXoW/7f7Bgwe4efMm8vPzVdrbtm373EURERERVSaNA9GdO3cwZswY/Pzzz6UuLywsfO6iiIiIiCqTxqfMAgMDkZmZiRMnTsDY2Bh79uzBunXr0Lx5c+zYsUMXNRIRERHplMYzRAcOHMD27dvx0ksvoU6dOnB0dESPHj1gZmaGRYsWoW/fvrqok4iIiEhnNJ4hun//PqytrQEAFhYWuHPnDgCgTZs2OHPmjHarIyIiIqoEGgeiFi1aICkpCQDg5uaGr776Crdv38bq1athZ2en9QKJiIiIdE3jU2aBgYFITU0FAISEhMDHxwebNm2CoaEhoqOjtV0fERERkc5pHIgCAgKkP7u7u+PGjRu4cuUKmjRpAisrK60WR0RERFQZND5ltmDBAjx48EB6b2Jigvbt26Nu3bpYsGCBVosjIiIiqgwaB6KwsDDk5OSUaH/w4AHCwsK0UhQRERFRZdI4EAkhoFAoSrSfO3cOFhYWWimKiIiIqDKpfQ1RgwYNoFAooFAo8OKLL6qEosLCQuTk5GDixIk6KZKIiIhIl9QORBERERBCYOzYsQgLC4O5ubm0zNDQEE5OTujSpYtOiiQiIiLSJbUD0ahRowAAzs7O6Nq1KwwMDHRWFBEREVFl0vi2ew8PD+nPubm5KCgoUFluZmb2/FURERERVSKNL6p+8OABpk6dCmtra9SrVw8NGjRQeRERERHVNBoHonfeeQcHDhzAypUroVQq8c033yAsLAz29vZYv369LmokIiIi0imNT5nt3LkT69evh6enJ8aOHYtXX30VzZo1g6OjIzZt2qTyJGsiIiKimkDjGaKMjAw4OzsDeHy9UEZGBgDglVdewa+//qrd6oiIiIgqgcaBqGnTprhx4wYAwMXFBd9++y2AxzNH9evX12ZtRERERJVC40A0ZswYnDt3DgAQHBwsXUs0c+ZMvPPOO1ovkIiIiEjXNL6GaObMmdKfvby8cOXKFZw+fRovvPAC2rVrp9XiiIiIiCqDxoHoaU2aNEGTJk20UQsRERFRldAoEBUVFSE6Ohrbtm3DjRs3oFAo4OzsjCFDhmDkyJGlfukrERERUXWn9jVEQgj0798fb731Fm7fvo02bdqgdevWSElJwejRozFo0CBd1klERESkM2rPEEVHR+PXX3/F/v374eXlpbLswIEDGDhwINavX48333xT60USERER6ZLaM0SbN2/Ge++9VyIMAcBrr72GuXPnYtOmTVotjoiIiKgyqB2Izp8/j169epW5vHfv3tLt+EREREQ1idqBKCMjAzY2NmUut7GxQWZmplaKIiIiIqpMageiwsJC6OuXfcmRnp4eHj16pJWinnT79m2MGDEClpaWMDExgZubG+Lj46XlQgiEhobC3t4exsbG8PT0xMWLF1W2kZeXh2nTpsHKygp169ZF//798ddff2m9ViIiIqqZ1L6oWgiB0aNHQ6lUlro8Ly9Pa0UVy8zMRLdu3eDl5YWff/4Z1tbWuH79uspXhCxZsgTh4eGIjo7Giy++iI8++gg9evRAUlISTE1NAQCBgYHYuXMntmzZAktLSwQFBcHX1xfx8fHQ09PTet1ERERUs6gdiEaNGlVuH23fYbZ48WI4ODggKipKanNycpL+LIRAREQE5s2bBz8/PwDAunXrYGNjg5iYGEyYMAFZWVmIjIzEhg0b0L17dwDAxo0b4eDggH379sHHx0erNRMREVHNo3YgejKUVJYdO3bAx8cHr7/+Og4fPoxGjRph8uTJGD9+PAAgOTkZaWlp6Nmzp7SOUqmEh4cHjh07hgkTJiA+Ph4FBQUqfezt7eHq6opjx46VGYjy8vJUZr2ys7N1dJRERERU1TT+ctfK9Oeff2LVqlVo3rw5fvnlF0ycOBHTp0/H+vXrAQBpaWkAUOJibxsbG2lZWloaDA0N0aBBgzL7lGbRokUwNzeXXg4ODto8NCIiIqpGqnUgKioqQvv27bFw4UK4u7tjwoQJGD9+PFatWqXS7+mvDBFClPs1IuX1CQ4ORlZWlvS6detWxQ+EiIiIqrVqHYjs7Ozg4uKi0taqVSvcvHkTAGBrawsAJWZ60tPTpVkjW1tb5Ofnl3gkwJN9SqNUKmFmZqbyIiIiotqpWgeibt26ISkpSaXt6tWrcHR0BAA4OzvD1tYWcXFx0vL8/HwcPnwYXbt2BQB06NABBgYGKn1SU1ORmJgo9SEiIiJ5UysQtW/fXpphWbBgAR48eKDToorNnDkTJ06cwMKFC3Ht2jXExMRgzZo1mDJlCoDHp8oCAwOxcOFCxMbGIjExEaNHj4aJiQn8/f0BAObm5hg3bhyCgoKwf/9+JCQkYMSIEWjTpo101xkRERHJm1p3mV2+fBn3799HgwYNEBYWhokTJ8LExETXteGll15CbGwsgoODsWDBAjg7OyMiIgIBAQFSnzlz5iA3NxeTJ09GZmYmOnXqhL1790rPIAKAZcuWQV9fH0OHDkVubi68vb0RHR3NZxARERERADUDkZubG8aMGYNXXnkFQgh89tlnqFevXql958+fr9UCfX194evrW+ZyhUKB0NBQhIaGltnHyMgIy5cvx/Lly7VaGxEREdUOagWi6OhohISEYNeuXVAoFPj5559L/RoPhUKh9UBEREREpGtqBaIWLVpgy5YtAIA6depg//79sLa21mlhRERERJVF7SdVFysqKtJFHURERERVRuNABADXr19HREQELl++DIVCgVatWmHGjBl44YUXtF0fERERkc5p/ByiX375BS4uLjh58iTatm0LV1dX/P7772jdurXKs36IiIiIagqNZ4jmzp2LmTNn4pNPPinR/u6776JHjx5aK46IiIioMmg8Q3T58mWMGzeuRPvYsWNx6dIlrRRFREREVJk0DkQNGzbE2bNnS7SfPXuWd54RERFRjaTxKbPx48fj7bffxp9//omuXbtCoVDgyJEjWLx4MYKCgnRRIxEREZFOaRyIPvjgA5iammLp0qUIDg4GANjb2yM0NBTTp0/XeoFEREREuqZxIFIoFJg5cyZmzpyJe/fuAYDK94YRERER1TQVeg5RMQYhIiIiqg00vqiaiIiIqLZhICIiIiLZYyAiIiIi2dMoEBUUFMDLywtXr17VVT1ERERElU6jQGRgYIDExEQoFApd1UNERERU6TQ+Zfbmm28iMjJSF7UQERERVQmNb7vPz8/HN998g7i4OHTs2BF169ZVWR4eHq614oiIiIgqg8aBKDExEe3btweAEtcS8VQaERER1UQaB6KDBw/qog4iIiKiKlPh2+6vXbuGX375Bbm5uQAAIYTWiiIiIiKqTBoHort378Lb2xsvvvgi+vTpg9TUVADAW2+9xW+7JyIiohpJ40A0c+ZMGBgY4ObNmzAxMZHahw0bhj179mi1OCIiIqLKoPE1RHv37sUvv/yCxo0bq7Q3b94cKSkpWiuMiIiIqLJoPEN0//59lZmhYv/++y+USqVWiiIiIiKqTBoHov/9739Yv3699F6hUKCoqAiffvopvLy8tFocERERUWXQ+JTZp59+Ck9PT5w+fRr5+fmYM2cOLl68iIyMDBw9elQXNRIRERHplMYzRC4uLjh//jxefvll9OjRA/fv34efnx8SEhLwwgsv6KJGIiIiIp3SeIYIAGxtbREWFqbtWoiIiIiqRIUCUWZmJiIjI3H58mUoFAq0atUKY8aMgYWFhbbrIyIiItI5jU+ZHT58GM7Ozvjiiy+QmZmJjIwMfPHFF3B2dsbhw4d1USMRERGRTmk8QzRlyhQMHToUq1atgp6eHgCgsLAQkydPxpQpU5CYmKj1IomIiIh0SeMZouvXryMoKEgKQwCgp6eHWbNm4fr161otjoiIiKgyaByI2rdvj8uXL5dov3z5Mtzc3LRRExEREVGlUuuU2fnz56U/T58+HTNmzMC1a9fQuXNnAMCJEyfw5Zdf4pNPPtFNlUREREQ6pFYgcnNzg0KhgBBCapszZ06Jfv7+/hg2bJj2qiMiIiKqBGoFouTkZF3XQURERFRl1ApEjo6Ouq6DiIiIqMpU6MGMt2/fxtGjR5Geno6ioiKVZdOnT9dKYURERESVReNAFBUVhYkTJ8LQ0BCWlpZQKBTSMoVCwUBERERENY7GgWj+/PmYP38+goODUaeOxnftExEREVU7GieaBw8eYPjw4QxDREREVGtonGrGjRuH7777The1EBEREVUJjU+ZLVq0CL6+vtizZw/atGkDAwMDleXh4eFaK46IiIioMmgciBYuXIhffvkFLVq0AIASF1UTERER1TQaB6Lw8HCsXbsWo0eP1kE5RERERJVP42uIlEolunXrpotaiIiIiKqExoFoxowZWL58uS5qISIiIqoSGp8yO3nyJA4cOIBdu3ahdevWJS6q3rZtm9aKIyIiIqoMGs8Q1a9fH35+fvDw8ICVlRXMzc1VXrq0aNEiKBQKBAYGSm1CCISGhsLe3h7Gxsbw9PTExYsXVdbLy8vDtGnTYGVlhbp166J///7466+/dForERER1RwV+uqOqnDq1CmsWbMGbdu2VWlfsmQJwsPDER0djRdffBEfffQRevTogaSkJJiamgIAAgMDsXPnTmzZsgWWlpYICgqCr68v4uPjoaenVxWHQ0RERNVIjXjcdE5ODgICAvD111+jQYMGUrsQAhEREZg3bx78/Pzg6uqKdevW4cGDB4iJiQEAZGVlITIyEkuXLkX37t3h7u6OjRs34sKFC9i3b19VHRIRERFVIxoHImdnZzRt2rTMly5MmTIFffv2Rffu3VXak5OTkZaWhp49e0ptSqUSHh4eOHbsGAAgPj4eBQUFKn3s7e3h6uoq9SlNXl4esrOzVV5ERERUO2l8yuzJ63cAoKCgAAkJCdizZw/eeecdbdUl2bJlC+Lj43H69OkSy9LS0gAANjY2Ku02NjZISUmR+hgaGqrMLBX3KV6/NIsWLUJYWNjzlk9EREQ1gMaBaMaMGaW2f/nll6WGludx69YtzJgxA3v37oWRkVGZ/Z5+QrYQotynZpfXJzg4GLNmzZLeZ2dnw8HBQc3KiYiIqCbR2jVEvXv3xg8//KCtzQF4fLorPT0dHTp0gL6+PvT19XH48GF88cUX0NfXl2aGnp7pSU9Pl5bZ2toiPz8fmZmZZfYpjVKphJmZmcqLiIiIaietBaLvv/8eFhYW2tocAMDb2xsXLlzA2bNnpVfHjh0REBCAs2fPomnTprC1tUVcXJy0Tn5+Pg4fPoyuXbsCADp06AADAwOVPqmpqUhMTJT6EBERkbxpfMrM3d1d5VSTEAJpaWm4c+cOVq5cqdXiTE1N4erqqtJWt25dWFpaSu2BgYFYuHAhmjdvjubNm2PhwoUwMTGBv78/AMDc3Bzjxo1DUFAQLC0tYWFhgdmzZ6NNmzYlLtImIiIiedI4EA0cOFDlfZ06ddCwYUN4enqiZcuW2qpLbXPmzEFubi4mT56MzMxMdOrUCXv37pWeQQQAy5Ytg76+PoYOHYrc3Fx4e3sjOjqazyAiIiIiABUIRCEhIbqoQ22HDh1Sea9QKBAaGorQ0NAy1zEyMsLy5cv5HWxERERUqhrxYEYiIiIiXVJ7hqhOnTrl3squUCjw6NGj5y6KiIiIqDKpHYhiY2PLXHbs2DEsX74cQgitFEVERERUmdQORAMGDCjRduXKFQQHB2Pnzp0ICAjAhx9+qNXiiIiIiCpDha4h+vvvvzF+/Hi0bdsWjx49QkJCAtatW4cmTZpouz4iIiIindMoEGVlZeHdd99Fs2bNcPHiRezfvx87d+5EmzZtdFUfERERkc6pfcpsyZIlWLx4MWxtbbF58+ZST6ERERER1URqB6K5c+fC2NgYzZo1w7p167Bu3bpS+23btk1rxRERERFVBrUD0ZtvvlnubfdERERENZHagSg6OlqHZRARERFVHT6pmoiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSPgYiIiIhkj4GIiIiIZI+BiIiIiGSvWgeiRYsW4aWXXoKpqSmsra0xcOBAJCUlqfQRQiA0NBT29vYwNjaGp6cnLl68qNInLy8P06ZNg5WVFerWrYv+/fvjr7/+qsxDISIiomqsWgeiw4cPY8qUKThx4gTi4uLw6NEj9OzZE/fv35f6LFmyBOHh4VixYgVOnToFW1tb9OjRA/fu3ZP6BAYGIjY2Flu2bMGRI0eQk5MDX19fFBYWVsVhERERUTWjX9UFPMuePXtU3kdFRcHa2hrx8fH43//+ByEEIiIiMG/ePPj5+QEA1q1bBxsbG8TExGDChAnIyspCZGQkNmzYgO7duwMANm7cCAcHB+zbtw8+Pj6VflxERERUvVTrGaKnZWVlAQAsLCwAAMnJyUhLS0PPnj2lPkqlEh4eHjh27BgAID4+HgUFBSp97O3t4erqKvUpTV5eHrKzs1VeREREVDvVmEAkhMCsWbPwyiuvwNXVFQCQlpYGALCxsVHpa2NjIy1LS0uDoaEhGjRoUGaf0ixatAjm5ubSy8HBQZuHQ0RERNVIjQlEU6dOxfnz57F58+YSyxQKhcp7IUSJtqeV1yc4OBhZWVnS69atWxUrnIiIiKq9GhGIpk2bhh07duDgwYNo3Lix1G5rawsAJWZ60tPTpVkjW1tb5OfnIzMzs8w+pVEqlTAzM1N5ERERUe1UrQOREAJTp07Ftm3bcODAATg7O6ssd3Z2hq2tLeLi4qS2/Px8HD58GF27dgUAdOjQAQYGBip9UlNTkZiYKPUhIiIieavWd5lNmTIFMTEx2L59O0xNTaWZIHNzcxgbG0OhUCAwMBALFy5E8+bN0bx5cyxcuBAmJibw9/eX+o4bNw5BQUGwtLSEhYUFZs+ejTZt2kh3nREREZG8VetAtGrVKgCAp6enSntUVBRGjx4NAJgzZw5yc3MxefJkZGZmolOnTti7dy9MTU2l/suWLYO+vj6GDh2K3NxceHt7Izo6Gnp6epV1KERERFSNVetAJIQot49CoUBoaChCQ0PL7GNkZITly5dj+fLlWqyOiIiIaotqfQ0RERERUWVgICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItljICIiIiLZYyAiIiIi2WMgIiIiItmTVSBauXIlnJ2dYWRkhA4dOuC3336r6pKIiIioGpBNINq6dSsCAwMxb948JCQk4NVXX0Xv3r1x8+bNqi6NiIiIqphsAlF4eDjGjRuHt956C61atUJERAQcHBywatWqqi6NiIiIqpgsAlF+fj7i4+PRs2dPlfaePXvi2LFjVVQVERERVRf6VV1AZfj3339RWFgIGxsblXYbGxukpaWVuk5eXh7y8vKk91lZWQCA7OxsrddXlPdA69usKZ5nPOU6bs/7M8hxqxiOm+Y4ZhXDcdPNdoUQz+wni0BUTKFQqLwXQpRoK7Zo0SKEhYWVaHdwcNBJbXJlHlHVFdQ8HLOK4bhVDMdNcxyzitH1uN27dw/m5uZlLpdFILKysoKenl6J2aD09PQSs0bFgoODMWvWLOl9UVERMjIyYGlpWWaIqmmys7Ph4OCAW7duwczMrKrLqTE4bhXDcasYjpvmOGYVU1vHTQiBe/fuwd7e/pn9ZBGIDA0N0aFDB8TFxWHQoEFSe1xcHAYMGFDqOkqlEkqlUqWtfv36uiyzypiZmdWqH/7KwnGrGI5bxXDcNMcxq5jaOG7PmhkqJotABACzZs3CyJEj0bFjR3Tp0gVr1qzBzZs3MXHixKoujYiIiKqYbALRsGHDcPfuXSxYsACpqalwdXXFTz/9BEdHx6oujYiIiKqYbAIRAEyePBmTJ0+u6jKqDaVSiZCQkBKnBunZOG4Vw3GrGI6b5jhmFSP3cVOI8u5DIyIiIqrlZPFgRiIiIqJnYSAiIiIi2WMgIiIiItljIKrFoqOjNXp20qFDh6BQKPDff//prKbqjmNWMRy3iuG4VQzHTXMcMzUIqjaOHj0q6tSpI3x8fDRe19HRUSxbtkyl7cGDB+Kff/5Rext5eXkiNTVVFBUVCSGEiIqKEubm5hrXUprp06eL9u3bC0NDQ9GuXTutbFOI2jtmZ8+eFcOHDxeNGzcWRkZGomXLliIiIuK5t1usto7bv//+K3x8fISdnZ0wNDQUjRs3FlOmTBFZWVnPvW0hau+4Penff/8VjRo1EgBEZmamVrZZm8cNQInXqlWrnnu7tXnMirfXpk0boVQqhY2NjZgyZYrWtl1RnCGqRtauXYtp06bhyJEjuHnz5nNvz9jYGNbW1mr3NzQ0hK2trU6+mkQIgbFjx2LYsGFa3W5tHbP4+Hg0bNgQGzduxMWLFzFv3jwEBwdjxYoVWtl+bR23OnXqYMCAAdixYweuXr2K6Oho7Nu3T2sPYK2t4/akcePGoW3btlrdZm0ft6ioKKSmpkqvUaNGPfc2a/OYhYeHY968eZg7dy4uXryI/fv3w8fHR+v70VhVJzJ6LCcnR5iamoorV66IYcOGibCwsBJ9tm/fLjp06CCUSqWwtLQUgwYNEkII4eHhUeJ/KEKoJvorV64IAOLy5csq21y6dKlwdHQURUVF4uDBg9L/Cov//OQrJCREhIWFCVdX1xK1tW/fXnzwwQflHmdISIjWZojkMmbFJk+eLLy8vNTuXxa5jdvnn38uGjdurHb/sshh3FauXCk8PDzE/v37tTZDVNvHDYCIjY2t4OiUrjaPWUZGhjA2Nhb79u17niHSCQaiaiIyMlJ07NhRCCHEzp07hZOTkzRVKYQQu3btEnp6emL+/Pni0qVL4uzZs+Ljjz8WQghx9+5d0bhxY7FgwQKRmpoqUlNThRAlpzg7dOgg3n//fZX9dujQQQQHBwshhMpfgLy8PBERESHMzMykbd67d0/cunVL1KlTR5w8eVLaxrlz54RCoRDXr18v9zi1GYjkMmbFAgICxODBgzUbpFLIadxu374tPDw8REBAgOYD9ZTaPm4XL14Utra2IiUlRWU/z6u2jxsA0ahRI2FpaSk6duwoVq1aJQoLCzlmZYzZ1q1bhVKpFOvWrRMtW7YUjRo1Eq+//rq4efPmc42ZNjAQVRNdu3aVrhEpKCgQVlZWIi4uTlrepUuXZ/6jXto546f/AoSHh4umTZtK75OSkgQAcfHiRSGEKPGPYFnnjHv37i0mTZokvQ8MDBSenp5qHac2A5FcxkwIIY4dOyYMDAzE3r171V6nLHIYt+HDhwtjY2MBQPTr10/k5uaWu055avO4PXz4ULRt21Zs2LCh1P08j9o8bkII8eGHH4pjx46JhIQE8dlnnwkTExPx4YcfPnOd8tTmMVu0aJEwMDAQLVq0EHv27BHHjx8X3t7eokWLFiIvL6/M9SoDryGqBpKSknDy5EkMHz4cAKCvr49hw4Zh7dq1Up+zZ8/C29v7ufYzfPhwpKSk4MSJEwCATZs2wc3NDS4uLhptZ/z48di8eTMePnyIgoICbNq0CWPHjn2u2jQlpzG7ePEiBgwYgPnz56NHjx4aH8OT5DJuy5Ytw5kzZ/Djjz/i+vXrmDVrVoWOo1htH7fg4GC0atUKI0aMeK76n1bbxw0A3n//fXTp0gVubm4ICgrCggUL8Omnn1b4WGr7mBUVFaGgoABffPEFfHx80LlzZ2zevBl//PEHDh48+FzH9Lxk9V1m1VVkZCQePXqERo0aSW1CCBgYGCAzMxMNGjSAsbHxc+/Hzs4OXl5eiImJkX4IJ0yYoPF2+vXrB6VSidjYWCiVSuTl5WHw4MHPXZ8m5DJmly5dwmuvvYbx48fj/fffr8ghqJDLuNna2sLW1hYtW7aEpaUlXn31VXzwwQews7OryOHU+nE7cOAALly4gO+//x7A42MDACsrK8ybNw9hYWEVOp7aPm6l6dy5M7Kzs/HPP//AxsZG4xpq+5gV/x18Mng1bNgQVlZWWrl4/HlwhqiKPXr0COvXr8fSpUtx9uxZ6XXu3Dk4Ojpi06ZNAIC2bdti//79ZW7H0NAQhYWF5e4vICAAW7duxfHjx3H9+nXpfyGabFNfXx+jRo1CVFQUoqKiMHz4cJiYmKhxtNohlzG7ePEivLy8MGrUKHz88cfl1lkeuYzb04p/uefl5Wm0XjE5jNsPP/yAc+fOScf2zTffAAB+++03TJkypdyaSyOHcStNQkICjIyMNHrmTzE5jFm3bt0APJ4JK5aRkYF///0Xjo6O5dasU1V3to6EECI2NlYYGhqK//77r8Sy9957T7i5uQkhHp/PrVOnjnQR3fnz58XixYulvj169BD9+/cXf/31l7hz544QovRzvllZWcLIyEi0a9dOeHt7qyx7+pzx0aNHBQCxb98+cefOHXH//n2p79WrV4Wenp7Q09MTJ06cKPc4//jjD5GQkCAmTJggXnzxRZGQkCASEhIqdM5YDmOWmJgoGjZsKAICAqSLGFNTU0V6erra4/Q0OYzb7t27xdq1a8WFCxdEcnKy2L17t2jdurXo1q2b2uP0NDmM29O0cQ2RHMZtx44dYs2aNeLChQvi2rVr4uuvvxZmZmZi+vTpao/Tk+QwZkIIMWDAANG6dWtx9OhRceHCBeHr6ytcXFxEfn6+WuOkKwxEVczX11f06dOn1GXx8fECgIiPjxdCCPHDDz8INzc3YWhoKKysrISfn5/U9/jx46Jt27ZCqVSWepvlk15//XUBQKxdu1alvbR/BCdOnCgsLS2l2yyf9OqrrwoXFxe1jrO0W0EBiOTkZLXWf5IcxiwkJKTU8XJ0dCx33bLIYdwOHDggunTpIszNzYWRkZFo3ry5ePfdd5/rF7scxu1p2ghEchi3n3/+Wbi5uYl69eoJExMT4erqKiIiIkRBQUG565ZGDmMmxOMgNnbsWFG/fn1hYWEhBg0aVC3uMlMI8f/mk4k0IIRAy5YtMWHChOe+YFUuOGYVw3GrGI5bxXDcNFdbxowXVZPG0tPTsWHDBty+fRtjxoyp6nJqBI5ZxXDcKobjVjEcN83VpjFjICKN2djYwMrKCmvWrEGDBg2qupwagWNWMRy3iuG4VQzHTXO1acx4yoyIiIhkj7fdExERkewxEBEREZHsMRARERGR7DEQERERkewxEBFRtRQdHa3R1x8cOnQICoUC//33n85qqignJydEREQ81zZCQ0Ph5uamlXqIqCQGIiLSimPHjkFPTw+9evXSeN3SAsOwYcNw9epVtbfRtWtXpKamwtzcHIDmgaosN27cgEKhwNmzZ597W0RUfTEQEZFWrF27FtOmTcORI0e08q3VxsbGsLa2Vru/oaEhbG1toVAonnvfRCQ/DERE9Nzu37+Pb7/9FpMmTYKvry+io6NL9NmxYwc6duwIIyMjWFlZwc/PDwDg6emJlJQUzJw5EwqFQgo0T87wJCUlQaFQ4MqVKyrbDA8Ph5OTE4QQKqfMDh06hDFjxiArK0vaZmhoKBYsWIA2bdqUqK1Dhw6YP39+hY79+vXrGDBgAGxsbFCvXj289NJL2LdvX4l+9+7dg7+/P+rVqwd7e3ssX75cZXlWVhbefvttWFtbw8zMDK+99hrOnTtX5n4PHTqEl19+GXXr1kX9+vXRrVs3pKSkVOgYiIiBiIi0YOvWrWjRogVatGiBESNGICoqCk8+83X37t3w8/ND3759kZCQgP3796Njx44AgG3btqFx48ZYsGABUlNTkZqaWmL7LVq0QIcOHbBp0yaV9piYGPj7+5eYFeratSsiIiJgZmYmbXP27NkYO3YsLl26hFOnTkl9z58/j4SEBIwePbpCx56Tk4M+ffpg3759SEhIgI+PD/r161diluzTTz9F27ZtcebMGQQHB2PmzJmIi4sD8Pi7oPr27Yu0tDT89NNPiI+PR/v27eHt7Y2MjIwS+3z06BEGDhwIDw8PnD9/HsePH8fbb7/N2TGi51ElXylLRLVK165dRUREhBBCiIKCAmFlZSXi4uKk5V26dBEBAQFlru/o6CiWLVum0vb0t3OHh4eLpk2bSu+TkpIEAHHx4kUhRMlv5y7r27179+4tJk2aJL0PDAwUnp6eZdaWnJwsAIiEhIQy+zzNxcVFLF++XOX4evXqpdJn2LBhonfv3kIIIfbv3y/MzMzEw4cPVfq88MIL4quvvhJCCBESEiLatWsnhBDi7t27AoA4dOiQ2jUR0bNxhoiInktSUhJOnjyJ4cOHAwD09fUxbNgwrF27Vupz9uxZeHt7P9d+hg8fjpSUFJw4cQIAsGnTJri5ucHFxUWj7YwfPx6bN2/Gw4cPUVBQgE2bNmHs2LEVruv+/fuYM2cOXFxcUL9+fdSrVw9XrlwpMUPUpUuXEu8vX74MAIiPj0dOTg4sLS1Rr1496ZWcnIzr16+X2KeFhQVGjx4tzUZ9/vnnpc6sEZH6+OWuRPRcIiMj8ejRIzRq1EhqE0LAwMAAmZmZaNCgAYyNjZ97P3Z2dvDy8kJMTAw6d+6MzZs3Y8KECRpvp1+/flAqlYiNjYVSqUReXh4GDx5c4breeecd/PLLL/jss8/QrFkzGBsbY8iQIcjPzy933eJTXEVFRbCzs8OhQ4dK9CnrTrmoqChMnz4de/bswdatW/H+++8jLi4OnTt3rvCxEMkZAxERVdijR4+wfv16LF26FD179lRZNnjwYGzatAlTp05F27ZtsX//fowZM6bU7RgaGqKwsLDc/QUEBODdd9/FG2+8gevXr0uzUppsU19fH6NGjUJUVBSUSiWGDx8OExOTcvddlt9++w2jR4/GoEGDADy+pujGjRsl+hXPbD35vmXLlgCA9u3bIy0tDfr6+nByclJ73+7u7nB3d0dwcDC6dOkihUUi0hwDERFV2K5du5CZmYlx48ZJz/8pNmTIEERGRmLq1KkICQmBt7c3XnjhBQwfPhyPHj3Czz//jDlz5gB4/ByiX3/9FcOHD4dSqYSVlVWp+/Pz88OkSZMwadIkeHl5qcxKPc3JyQk5OTnYv38/2rVrBxMTEyn4vPXWW2jVqhUA4OjRo2oda1JSUok2FxcXNGvWDNu2bUO/fv2gUCjwwQcfoKioqETfo0ePYsmSJRg4cCDi4uLw3XffYffu3QCA7t27o0uXLhg4cCAWL16MFi1a4O+//8ZPP/2EgQMHShegF0tOTsaaNWvQv39/2NvbIykpCVevXsWbb76p1rEQUSmq+iImIqq5fH19RZ8+fUpdFh8fLwCI+Ph4IYQQP/zwg3BzcxOGhobCyspK+Pn5SX2PHz8u2rZtK5RKpSj+Z6msi6Jff/11AUCsXbtWpf3pi6qFEGLixInC0tJSABAhISEq/V999VXh4uJS7jEWX1Rd2is5OVkkJycLLy8vYWxsLBwcHMSKFSuEh4eHmDFjhrQNR0dHERYWJoYOHSpMTEyEjY2NdBF6sezsbDFt2jRhb28vDAwMhIODgwgICBA3b94UQqheVJ2WliYGDhwo7OzshKGhoXB0dBTz588XhYWF5R4PEZVOIcQT98YSEcmAEAItW7bEhAkTMGvWrKouh4iqAZ4yIyJZSU9Px4YNG3D79u0yr2kiIvlhICIiWbGxsYGVlRXWrFmDBg0aVHU5RFRNMBARkazwKgEiKg0fzEhERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLLHQERERESyx0BEREREssdARERERLL3fycXrKYoVhYrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "______________________________Test features & labels info:______________________________________\n",
      "\n",
      "_____ The weights of each activity _____\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Weights</th>\n",
       "      <td>0.178698</td>\n",
       "      <td>0.16879</td>\n",
       "      <td>0.151451</td>\n",
       "      <td>0.156405</td>\n",
       "      <td>0.174452</td>\n",
       "      <td>0.170205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  \\\n",
       "Weights    0.178698     0.16879    0.151451    0.156405    0.174452   \n",
       "\n",
       "         Activity 6  \n",
       "Weights    0.170205  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# apply create_training_testing_data to scaled dataset type I\n",
    "[X_1_train, X_1_test, y_1_train, y_1_test] = create_training_testing_data(scaled_type_I,train_users,test_users,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store train test files type I in the dictionary \n",
    "train_test_files_dic[1]=[X_1_train, X_1_test, y_1_train, y_1_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "______________________________Dataset type II Train features & labels info:______________________________________\n",
      "\n",
      "_____ The weights of each activity _____\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "      <th>Activity 7</th>\n",
       "      <th>Activity 8</th>\n",
       "      <th>Activity 9</th>\n",
       "      <th>Activity 10</th>\n",
       "      <th>Activity 11</th>\n",
       "      <th>Activity 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Weights</th>\n",
       "      <td>0.164495</td>\n",
       "      <td>0.146433</td>\n",
       "      <td>0.138821</td>\n",
       "      <td>0.147981</td>\n",
       "      <td>0.159334</td>\n",
       "      <td>0.158818</td>\n",
       "      <td>0.012385</td>\n",
       "      <td>0.008902</td>\n",
       "      <td>0.01574</td>\n",
       "      <td>0.015998</td>\n",
       "      <td>0.018836</td>\n",
       "      <td>0.012256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  \\\n",
       "Weights    0.164495    0.146433    0.138821    0.147981    0.159334   \n",
       "\n",
       "         Activity 6  Activity 7  Activity 8  Activity 9  Activity 10  \\\n",
       "Weights    0.158818    0.012385    0.008902     0.01574     0.015998   \n",
       "\n",
       "         Activity 11  Activity 12  \n",
       "Weights     0.018836     0.012256  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "______________________________Test features & labels info:______________________________________\n",
      "\n",
      "_____ The weights of each activity _____\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "      <th>Activity 7</th>\n",
       "      <th>Activity 8</th>\n",
       "      <th>Activity 9</th>\n",
       "      <th>Activity 10</th>\n",
       "      <th>Activity 11</th>\n",
       "      <th>Activity 12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Weights</th>\n",
       "      <td>0.164761</td>\n",
       "      <td>0.158605</td>\n",
       "      <td>0.150982</td>\n",
       "      <td>0.138962</td>\n",
       "      <td>0.151568</td>\n",
       "      <td>0.146878</td>\n",
       "      <td>0.014365</td>\n",
       "      <td>0.009675</td>\n",
       "      <td>0.016124</td>\n",
       "      <td>0.013779</td>\n",
       "      <td>0.019056</td>\n",
       "      <td>0.015245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  \\\n",
       "Weights    0.164761    0.158605    0.150982    0.138962    0.151568   \n",
       "\n",
       "         Activity 6  Activity 7  Activity 8  Activity 9  Activity 10  \\\n",
       "Weights    0.146878    0.014365    0.009675    0.016124     0.013779   \n",
       "\n",
       "         Activity 11  Activity 12  \n",
       "Weights     0.019056     0.015245  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHFCAYAAAAUpjivAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABQxElEQVR4nO3deVRU9f8/8OdlmWERUEAZUATcUAQFtUytEAVxQTPsq6YlLpn7bhpZCWaalmhp2adCcDcrybRScUFzS0XUXNNC1IIoJRZFQHj//uhwf44DMgNDM96ej3PmnOZ933Pv6y4Oz953GUkIIUBERESkUBamLoCIiIioNjHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGiMezQIyExMRGSJMHGxgYZGRk607t27Qp/f38TVAakpKRAkiR8+eWXJlm+oa5evYo+ffrA2dkZkiRh6tSplfb19vaGJEmQJAkWFhZwcnJCq1atMGzYMOzatatGdXz00UdITEys0Tz+Ld7e3hg+fHi1PrthwwYsW7bMqPUozcO2kSRJiImJMXie5d8ZV69e1Ws5pGxWpi6AyBBFRUV4/fXXsXbtWlOX8siaNm0afvzxR6xatQoajQbu7u4P7d+lSxe89957AICCggJcunQJmzZtQnh4OAYMGICNGzfC2tra4Do++ugjuLq6VjtE/JuSkpLg6OhYrc9u2LABZ8+efWio/K972DY6cuQIGjVqZPA8+/TpgyNHjmgd39wX/10MO/RI6dmzJzZs2ICZM2eibdu2pi7nX1VYWAgbGxtIklSj+Zw9exaPP/44+vfvr1f/unXr4oknnpDfh4aGYsKECYiJiUFsbCxef/11LFq0qEY1mbugoCBTl/CvKykpgSRJsLIy7Z+J+489Q9SvXx/169c3cjX0qOJpLHqkzJo1Cy4uLpg9e/ZD+129ehWSJFV4muTBYfGYmBhIkoQzZ87g//7v/+Dk5ARnZ2dMnz4d9+7dw6VLl9CzZ084ODjA29sbixcvrnCZd+/exfTp06HRaGBra4vg4GCkpaXp9Dtx4gT69esHZ2dn2NjYICgoCJs3b9bqUz4Ev2vXLowcORL169eHnZ0dioqKKl3na9eu4YUXXkCDBg2gVqvRqlUrLFmyBGVlZQD+/+m2K1eu4Pvvv5dPT90/zG+ImJgYtG7dGitWrMDdu3fl9tjYWHTs2BHOzs5wdHREu3btEB8fj/t/c9jb2xvnzp3D/v375Tq8vb3l7ThjxgwEBgbK+6JTp07YunWrXnWVn9L84Ycf8MQTT8DW1hYNGzbEG2+8gdLSUq2+t27dwvjx49GwYUOoVCo0adIEc+bM0dnOD57GKt+WGzduxJw5c+Dh4QFHR0eEhobi0qVLWrV8++23yMjIkNfz/rC6cuVKtG3bFnXq1IGDgwNatmyJ11577aHrV35sL168GG+//TYaN24MGxsbdOjQAXv27NHpf/nyZQwZMkTruPjwww+1+pSvz9q1azFjxgw0bNgQarUaV65cqbQOffZzuQ0bNqBTp06oU6cO6tSpg8DAQMTHx+u1je7/93r69GlIkiR/9n7lx/Q333wDQPc0VmXLEUKgefPmCA8P15lnQUEBnJycMGHChEq3Az0aGHbokeLg4IDXX38dO3fuxN69e40674EDB6Jt27b46quvMHr0aCxduhTTpk1D//790adPHyQlJaFbt26YPXs2tmzZovP51157Db/++is+++wzfPbZZ/j999/RtWtX/Prrr3Kfffv2oUuXLvj777/x8ccfY+vWrQgMDMSgQYMqDGYjR46EtbU11q5diy+//LLS00V//vknOnfujF27duGtt97CN998g9DQUMycORMTJ04EALRr1w5HjhyBRqNBly5dcOTIEZ1hfkP17dsXd+7cwYkTJ+S2q1evYsyYMdi8eTO2bNmCyMhITJo0CW+99ZbcJykpCU2aNEFQUJBcR1JSEoB/TlXeunULM2fOxNdff42NGzfiySefRGRkJNasWaNXXVlZWRg8eDCGDh2KrVu34rnnnsP8+fMxZcoUuc/du3cREhKCNWvWYPr06fj222/xwgsvYPHixYiMjNRrOa+99hoyMjLw2Wef4ZNPPsHly5fRt29fOVR99NFH6NKlCzQajbyeR44cAQBs2rQJ48ePR3BwMJKSkvD1119j2rRpuH37tl7LXrFiBXbs2IFly5Zh3bp1sLCwQK9eveT5A8D58+fx2GOP4ezZs1iyZAm2b9+OPn36YPLkyYiNjdWZZ3R0NK5du4aPP/4Y27ZtQ4MGDSpdvj77GQDefPNNDB06FB4eHkhMTERSUhKioqLka+8eto0e1LZtWwQFBSEhIUFnWmJiIho0aIDevXtX+NnKliNJEiZNmoTk5GRcvnxZ6zNr1qxBXl4ew44SCKJHQEJCggAgjh8/LoqKikSTJk1Ehw4dRFlZmRBCiODgYNG6dWu5f3p6ugAgEhISdOYFQMydO1d+P3fuXAFALFmyRKtfYGCgACC2bNkit5WUlIj69euLyMhIuW3fvn0CgGjXrp1cjxBCXL16VVhbW4uXXnpJbmvZsqUICgoSJSUlWsuKiIgQ7u7uorS0VGt9hw0bptf2efXVVwUA8eOPP2q1jxs3TkiSJC5duiS3eXl5iT59+ug136r6rly5UgAQn3/+eYXTS0tLRUlJiZg3b55wcXHR2j6tW7cWwcHBVdZw7949UVJSIkaNGiWCgoKq7B8cHCwAiK1bt2q1jx49WlhYWIiMjAwhhBAff/yxACA2b96s1W/RokUCgNi1a5fc5uXlJaKiouT35fu8d+/eWp/dvHmzACCOHDkit/Xp00d4eXnp1Dlx4kRRt27dKtfnQeXHtoeHhygsLJTb8/LyhLOzswgNDZXbwsPDRaNGjURubq7Osm1sbMStW7e01ufpp582uB4hKt/Pv/76q7C0tBRDhw596Ocr20ZC6P57/eCDDwQArWP61q1bQq1WixkzZsht5f+G0tPTq1xOXl6ecHBwEFOmTNFq9/PzEyEhIQ+tnR4NHNmhR45KpcL8+fNx4sQJndM/NREREaH1vlWrVpAkCb169ZLbrKys0KxZswrvCBsyZIjW8LuXlxc6d+6Mffv2AQCuXLmCixcvYujQoQCAe/fuya/evXsjMzNT6xQIAAwYMECv2vfu3Qs/Pz88/vjjWu3Dhw+HEMLoo2DlRAWnLPbu3YvQ0FA4OTnB0tIS1tbWePPNN3Hz5k1kZ2frNd8vvvgCXbp0QZ06dWBlZQVra2vEx8fjwoULen3ewcEB/fr102obMmQIysrKcODAAblOe3t7PPfcc1r9yk9XVXRK6EEPLqNNmzYAUOHx8aDHH38cf//9N55//nls3boVf/31V5WfuV9kZCRsbGzk9w4ODujbty8OHDiA0tJS3L17F3v27MGzzz4LOzs7nePt7t27OHr0qNY89T3eAP32c3JyMkpLS406MjJ06FCo1WqtkdCNGzeiqKgII0aMqNY8HRwcMGLECCQmJsoja3v37sX58+flkVF6tDHs0CNp8ODBaNeuHebMmYOSkhKjzNPZ2VnrvUqlgp2dndYflPL2+69RKafRaCpsu3nzJgDgjz/+AADMnDkT1tbWWq/x48cDgM4fPH1PMd28ebPCvh4eHvL02lD+R718OceOHUOPHj0AAJ9++ikOHTqE48ePY86cOQD+uci6Klu2bMHAgQPRsGFDrFu3DkeOHMHx48cxcuTICrd7Rdzc3HTayvdP+ba4efMmNBqNzgXfDRo0gJWVlV7bzMXFReu9Wq0GoN96vvjii1i1ahUyMjIwYMAANGjQAB07dkRycnKVn71/fR5sKy4uRkFBAW7evIl79+5h+fLlOsdb+ame6h5v+u7nP//8EwCqdTdVZZydndGvXz+sWbNGPl2YmJiIxx9/HK1bt672fCdNmoT8/HysX78ewD+nCRs1aoRnnnnGKHWTafFuLHokSZKERYsWISwsDJ988onO9PKA8uCFprX1Rx/45zqRitrK/yC6uroC+Oe6iMquCfH19dV6r++dVy4uLsjMzNRp//3337WWbUxCCGzbtg329vbo0KEDgH+uQ7G2tsb27du1QuLXX3+t93zXrVsHHx8ffP7551rr/7CLsx9UHizvV75/yveHi4sLfvzxRwghtJaTnZ2Ne/fu1co2e9CIESMwYsQI3L59GwcOHMDcuXMRERGBn3/+GV5eXg/9bGXHm0qlQp06dWBtbQ1LS0u8+OKLlY6s+Pj4aL3X93jTdz+X3w1148YNeHp66jVvfYwYMQJffPEFkpOT0bhxYxw/fhwrV66s0TybNWuGXr164cMPP0SvXr3wzTffIDY2FpaWlkaqmkyJIzv0yAoNDUVYWBjmzZuHgoICrWlubm6wsbHBmTNntNr1vaOnOjZu3Kh1WicjIwOHDx9G165dAfwTZJo3b47Tp0+jQ4cOFb4cHByqtezu3bvj/PnzOHnypFb7mjVrIEkSQkJCqr1elYmNjcX58+cxZcoU+Q9e+a3K9/+BKCwsrPC5SGq1usIREEmSoFKptP7wZmVlGbTv8vPz5btyym3YsAEWFhZ4+umnAfyzzQoKCnT+QJdfBN29e3e9l/cwla3n/ezt7dGrVy/MmTMHxcXFOHfuXJXz3bJli9ZIV35+PrZt24annnoKlpaWsLOzQ0hICNLS0tCmTZsKj7cHR6b0pe9+7tGjBywtLasMIvpsowfn27BhQyQkJCAhIQE2NjZ4/vnnq/xcVcuZMmUKzpw5g6ioKFhaWmL06NF610TmjSM79EhbtGgR2rdvj+zsbK0hbEmS8MILL2DVqlVo2rQp2rZti2PHjmHDhg21Vkt2djaeffZZjB49Grm5uZg7dy5sbGwQHR0t9/nf//6HXr16ITw8HMOHD0fDhg1x69YtXLhwASdPnsQXX3xRrWVPmzYNa9asQZ8+fTBv3jx4eXnh22+/xUcffYRx48ahRYsW1V6vv//+W7624/bt2/JDBX/44QcMHDhQ666ePn36IC4uDkOGDMHLL7+Mmzdv4r333pNP79wvICAAmzZtwueff44mTZrAxsYGAQEBiIiIwJYtWzB+/Hg899xzuH79Ot566y24u7vr3C1TGRcXF4wbNw7Xrl1DixYt8N133+HTTz/FuHHj0LhxYwDAsGHD8OGHHyIqKgpXr15FQEAADh48iAULFqB3794IDQ2t9jZ7cD23bNmClStXon379rCwsECHDh0wevRo2NraokuXLnB3d0dWVhYWLlwIJycnPPbYY1XO19LSEmFhYZg+fTrKysqwaNEi5OXlae2P999/H08++SSeeuopjBs3Dt7e3sjPz8eVK1ewbdu2al/Lpe9+9vb2xmuvvYa33noLhYWFeP755+Hk5ITz58/jr7/+kmutbBs9bN2HDRuGuLg4ODo6IjIyEk5OTlXWXdVywsLC4Ofnh3379smPcSCFMOnl0UR6uv9urAcNGTJEANC6G0sIIXJzc8VLL70k3NzchL29vejbt6+4evVqpXdj/fnnn1qfj4qKEvb29jrLe/DOr/I7WdauXSsmT54s6tevL9RqtXjqqafEiRMndD5/+vRpMXDgQNGgQQNhbW0tNBqN6Natm/j444/1Wt/KZGRkiCFDhggXFxdhbW0tfH19xbvvvivf4VXO0LuxAAgAQpIkUadOHeHr6ytefPFFsXPnzgo/s2rVKuHr6yvUarVo0qSJWLhwoYiPj9e5M+bq1auiR48ewsHBQQDQukvmnXfeEd7e3kKtVotWrVqJTz/9VN5PVSnfPykpKaJDhw5CrVYLd3d38dprr+ncBXfz5k0xduxY4e7uLqysrISXl5eIjo4Wd+/e1dkOFd2N9cUXX2j1q+guwFu3bonnnntO1K1bV0iSJK/D6tWrRUhIiHBzcxMqlUp4eHiIgQMHijNnzjx0/cqXsWjRIhEbGysaNWokVCqVCAoKqnCfpKeni5EjR4qGDRsKa2trUb9+fdG5c2cxf/78KtfnYfTdz0IIsWbNGvHYY48JGxsbUadOHREUFKTXNhJC926scj///LN8bCYnJ+tMr+hurIctp1xMTIwAII4ePar3tiDzJwlRwe0URESPqK5du+Kvv/7C2bNnTV1Krbh69Sp8fHzw7rvvYubMmaYuR3E6dOgASZJw/PhxU5dCRsTTWERE9J+Wl5eHs2fPYvv27UhNTZUfcEnKwbBDRET/aSdPnkRISAhcXFwwd+5cvX83jh4dPI1FREREisZbz4mIiEjRGHaIiIhI0Rh2iIiISNF4gTKAsrIy/P7773BwcND7celERERkWkII5Ofnw8PDAxYWlY/fMOzgn98PMubvthAREdG/5/r16w/9wVmGHUD+PaLr16/D0dHRxNUQERGRPvLy8uDp6Vnl7woy7OD//9Kvo6Mjww4REdEjpqpLUHiBMhERESkaww4REREpGsMOERERKRrDDhERESkaww4REREpGsMOERERKRrDDhERESkaww4REREpGsMOERERKRrDDhERESkaww4REREpGsMOERERKRrDDhERESkaww4REREpGsMOERERKZqVqQtQOu9XvzXZsq++08dkyyYiIjIXHNkhIiIiRWPYISIiIkVj2CEiIiJFY9ghIiIiRWPYISIiIkVj2CEiIiJFY9ghIiIiRWPYISIiIkVj2CEiIiJFY9ghIiIiRWPYISIiIkVj2CEiIiJF4w+B/oeZ6kdK+QOlRET0b+LIDhERESkaww4REREpGsMOERERKRrDDhERESkaww4REREpGsMOERERKRrDDhERESkaww4REREpGsMOERERKRrDDhERESkaww4REREpGsMOERERKRrDDhERESkaww4REREpmpWpCyCimvF+9VuTLfvqO31MtmwiIn0x7JDZMdUfb/7hJiJSJp7GIiIiIkVj2CEiIiJFY9ghIiIiRWPYISIiIkUzadiJiYmBJElaL41GI08XQiAmJgYeHh6wtbVF165dce7cOa15FBUVYdKkSXB1dYW9vT369euHGzdu/NurQkRERGbK5CM7rVu3RmZmpvz66aef5GmLFy9GXFwcVqxYgePHj0Oj0SAsLAz5+flyn6lTpyIpKQmbNm3CwYMHUVBQgIiICJSWlppidYiIiMjMmPzWcysrK63RnHJCCCxbtgxz5sxBZGQkAGD16tVwc3PDhg0bMGbMGOTm5iI+Ph5r165FaGgoAGDdunXw9PTE7t27ER4e/q+uCxEREZkfk4/sXL58GR4eHvDx8cHgwYPx66+/AgDS09ORlZWFHj16yH3VajWCg4Nx+PBhAEBqaipKSkq0+nh4eMDf31/uQ0RERP9tJh3Z6dixI9asWYMWLVrgjz/+wPz589G5c2ecO3cOWVlZAAA3Nzetz7i5uSEjIwMAkJWVBZVKhXr16un0Kf98RYqKilBUVCS/z8vLM9YqEdF9+IBIIjIHJg07vXr1kv87ICAAnTp1QtOmTbF69Wo88cQTAABJkrQ+I4TQaXtQVX0WLlyI2NjYGlROREREjwqTn8a6n729PQICAnD58mX5Op4HR2iys7Pl0R6NRoPi4mLk5ORU2qci0dHRyM3NlV/Xr1838poQERGRuTCrsFNUVIQLFy7A3d0dPj4+0Gg0SE5OlqcXFxdj//796Ny5MwCgffv2sLa21uqTmZmJs2fPyn0qolar4ejoqPUiIiIiZTLpaayZM2eib9++aNy4MbKzszF//nzk5eUhKioKkiRh6tSpWLBgAZo3b47mzZtjwYIFsLOzw5AhQwAATk5OGDVqFGbMmAEXFxc4Oztj5syZCAgIkO/OIiIiov82k4adGzdu4Pnnn8dff/2F+vXr44knnsDRo0fh5eUFAJg1axYKCwsxfvx45OTkoGPHjti1axccHBzkeSxduhRWVlYYOHAgCgsL0b17dyQmJsLS0tJUq0VERERmxKRhZ9OmTQ+dLkkSYmJiEBMTU2kfGxsbLF++HMuXLzdydURERKQEZnXNDhEREZGxMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGimfTnIogeJd6vfmuyZV99p4/Jlk1E9KjjyA4REREpGsMOERERKRrDDhERESkaww4REREpGsMOERERKRrDDhERESkaww4REREpGsMOERERKRrDDhERESkaww4REREpGsMOERERKRrDDhERESkaww4REREpGsMOERERKRrDDhERESkaww4REREpGsMOERERKRrDDhERESkaww4REREpGsMOERERKRrDDhERESkaww4REREpGsMOERERKRrDDhERESkaww4REREpGsMOERERKRrDDhERESkaww4REREpGsMOERERKRrDDhERESkaww4REREpGsMOERERKRrDDhERESmawWFnx44dOHjwoPz+ww8/RGBgIIYMGYKcnByjFkdERERUUwaHnVdeeQV5eXkAgJ9++gkzZsxA79698euvv2L69OlGL5CIiIioJqwM/UB6ejr8/PwAAF999RUiIiKwYMECnDx5Er179zZ6gUREREQ1YfDIjkqlwp07dwAAu3fvRo8ePQAAzs7O8ogPERERkbkweGTnySefxPTp09GlSxccO3YMn3/+OQDg559/RqNGjYxeIBEREVFNGDyys2LFClhZWeHLL7/EypUr0bBhQwDA999/j549exq9QCIiIqKaMHhkp3Hjxti+fbtO+9KlS41SEBEREZExGTyyY2lpiezsbJ32mzdvwtLS0ihFERERERmLwWFHCFFhe1FREVQqVbULWbhwISRJwtSpU7WWFRMTAw8PD9ja2qJr1644d+6cznInTZoEV1dX2Nvbo1+/frhx40a16yAiIiJl0fs01gcffAAAkCQJn332GerUqSNPKy0txYEDB9CyZctqFXH8+HF88sknaNOmjVb74sWLERcXh8TERLRo0QLz589HWFgYLl26BAcHBwDA1KlTsW3bNmzatAkuLi6YMWMGIiIikJqaypEmIiIi0j/slF+TI4TAxx9/rBUkVCoVvL298fHHHxtcQEFBAYYOHYpPP/0U8+fPl9uFEFi2bBnmzJmDyMhIAMDq1avh5uaGDRs2YMyYMcjNzUV8fDzWrl2L0NBQAMC6devg6emJ3bt3Izw83OB6iIiISFn0Po2Vnp6O9PR0BAcH4/Tp0/L79PR0XLp0CTt37kTHjh0NLmDChAno06ePHFbuX15WVpb8HB8AUKvVCA4OxuHDhwEAqampKCkp0erj4eEBf39/uU9FioqKkJeXp/UiIiIiZTL4bqx9+/YZbeGbNm1CamoqTpw4oTMtKysLAODm5qbV7ubmhoyMDLmPSqVCvXr1dPqUf74iCxcuRGxsbE3LJyIiokeAwWGntLQUiYmJ2LNnD7Kzs1FWVqY1fe/evXrN5/r165gyZQp27doFGxubSvtJkqT1Xgih0/agqvpER0dr/Y5XXl4ePD099aqbiIiIHi0Gh50pU6YgMTERffr0gb+/f5XBozKpqanIzs5G+/bt5bbyC51XrFiBS5cuAfhn9Mbd3V3uk52dLY/2aDQaFBcXIycnR2t0Jzs7G507d6502Wq1Gmq1ulp1ExER0aPF4LCzadMmbN68ucY/+tm9e3f89NNPWm0jRoxAy5YtMXv2bDRp0gQajQbJyckICgoCABQXF2P//v1YtGgRAKB9+/awtrZGcnIyBg4cCADIzMzE2bNnsXjx4hrVR0RERMpgcNhRqVRo1qxZjRfs4OAAf39/rTZ7e3u4uLjI7VOnTsWCBQvQvHlzNG/eHAsWLICdnR2GDBkCAHBycsKoUaMwY8YMuLi4wNnZGTNnzkRAQIDOBc9ERET032Rw2JkxYwbef/99rFixotqnsPQ1a9YsFBYWYvz48cjJyUHHjh2xa9cu+Rk7wD+3xFtZWWHgwIEoLCxE9+7dkZiYyGfsEBEREYBqhJ2DBw9i3759+P7779G6dWtYW1trTd+yZUu1i0lJSdF6L0kSYmJiEBMTU+lnbGxssHz5cixfvrzayyUiIiLlMjjs1K1bF88++2xt1EJERERkdAaHnYSEhNqog4iIiKhWGPxDoERERESPEr1Gdtq1a4c9e/agXr16CAoKeuiFySdPnjRacUREREQ1pVfYeeaZZ+SH8PXv37826yEiIiIyKr3Czty5cyv8byIiIiJzZ/AFyuVSU1Nx4cIFSJIEPz8/+SnHRERERObE4LCTnZ2NwYMHIyUlBXXr1oUQArm5uQgJCcGmTZtQv3792qiTiIiIqFoMvhtr0qRJyMvLw7lz53Dr1i3k5OTg7NmzyMvLw+TJk2ujRiIiIqJqM3hkZ8eOHdi9ezdatWolt/n5+eHDDz9Ejx49jFocERERUU0ZPLJTVlam8xMRAGBtbY2ysjKjFEVERERkLAaHnW7dumHKlCn4/fff5bbffvsN06ZNQ/fu3Y1aHBEREVFNGRx2VqxYgfz8fHh7e6Np06Zo1qwZfHx8kJ+fzx/jJCIiIrNj8DU7np6eOHnyJJKTk3Hx4kUIIeDn54fQ0NDaqI+IiIioRqr9nJ2wsDCEhYUZsxYiIiIio6vWD4Hu2bMHERER8mmsiIgI7N6929i1EREREdVYta7Z6dmzJxwcHDBlyhRMnjwZjo6O6N27N1asWFEbNRIRERFVm8GnsRYuXIilS5di4sSJctvkyZPRpUsXvP3221rtRERERKZm8MhOXl4eevbsqdPeo0cP5OXlGaUoIiIiImMxOOz069cPSUlJOu1bt25F3759jVIUERERkbEYfBqrVatWePvtt5GSkoJOnToBAI4ePYpDhw5hxowZ+OCDD+S+/K0sIiIiMjWDw058fDzq1auH8+fP4/z583J73bp1ER8fL7+XJIlhh4iIiEzO4LCTnp5eG3UQERER1YpqPWeHiIiI6FHBsENERESKxrBDREREisawQ0RERIrGsENERESKVu1fPb9z5w6uXbuG4uJirfY2bdrUuCgiIiIiYzE47Pz5558YMWIEvv/++wqnl5aW1rgoIiIiImMx+DTW1KlTkZOTg6NHj8LW1hY7duzA6tWr0bx5c3zzzTe1USMRERFRtRk8srN3715s3boVjz32GCwsLODl5YWwsDA4Ojpi4cKF6NOnT23USURERFQtBo/s3L59Gw0aNAAAODs7488//wQABAQE4OTJk8atjoiIiKiGDA47vr6+uHTpEgAgMDAQ//vf//Dbb7/h448/hru7u9ELJCIiIqoJg09jTZ06FZmZmQCAuXPnIjw8HOvXr4dKpUJiYqKx6yMiIiKqEYPDztChQ+X/DgoKwtWrV3Hx4kU0btwYrq6uRi2OiIiIqKYMPo01b9483LlzR35vZ2eHdu3awd7eHvPmzTNqcUREREQ1ZXDYiY2NRUFBgU77nTt3EBsba5SiiIiIiIzF4LAjhIAkSTrtp0+fhrOzs1GKIiIiIjIWva/ZqVevHiRJgiRJaNGihVbgKS0tRUFBAcaOHVsrRRIRERFVl95hZ9myZRBCYOTIkYiNjYWTk5M8TaVSwdvbG506daqVIomIiIiqS++wExUVBQDw8fFB586dYW1tXWtFERERERmLwbeeBwcHy/9dWFiIkpISremOjo41r4qIiIjISAy+QPnOnTuYOHEiGjRogDp16qBevXpaLyIiIiJzYnDYeeWVV7B371589NFHUKvV+OyzzxAbGwsPDw+sWbOmNmokIiIiqjaDT2Nt27YNa9asQdeuXTFy5Eg89dRTaNasGby8vLB+/XqtJywTERERmZrBIzu3bt2Cj48PgH+uz7l16xYA4Mknn8SBAweMWx0RERFRDRkcdpo0aYKrV68CAPz8/LB582YA/4z41K1b15i1EREREdWYwWFnxIgROH36NAAgOjpavnZn2rRpeOWVV4xeIBEREVFNGHzNzrRp0+T/DgkJwcWLF3HixAk0bdoUbdu2NWpxRERERDVlcNh5UOPGjdG4cWNj1EJERERkdAaFnbKyMiQmJmLLli24evUqJEmCj48PnnvuObz44osV/kAoERERkSnpfc2OEAL9+vXDSy+9hN9++w0BAQFo3bo1MjIyMHz4cDz77LMGL3zlypVo06YNHB0d4ejoiE6dOuH777/XWmZMTAw8PDxga2uLrl274ty5c1rzKCoqwqRJk+Dq6gp7e3v069cPN27cMLgWIiIiUia9w05iYiIOHDiAPXv2IC0tDRs3bsSmTZtw+vRp7N69G3v37jX4oYKNGjXCO++8gxMnTuDEiRPo1q0bnnnmGTnQLF68GHFxcVixYgWOHz8OjUaDsLAw5Ofny/OYOnUqkpKSsGnTJhw8eBAFBQWIiIhAaWmpQbUQERGRMukddjZu3IjXXnsNISEhOtO6deuGV199FevXrzdo4X379kXv3r3RokULtGjRAm+//Tbq1KmDo0ePQgiBZcuWYc6cOYiMjIS/vz9Wr16NO3fuYMOGDQCA3NxcxMfHY8mSJQgNDUVQUBDWrVuHn376Cbt37zaoFiIiIlImvcPOmTNn0LNnz0qn9+rVS74lvTpKS0uxadMm3L59G506dUJ6ejqysrLQo0cPuY9arUZwcDAOHz4MAEhNTUVJSYlWHw8PD/j7+8t9KlJUVIS8vDytFxERESmT3mHn1q1bcHNzq3S6m5sbcnJyDC7gp59+Qp06daBWqzF27FgkJSXBz88PWVlZ8nwfXE75tKysLKhUKp0fIL2/T0UWLlwIJycn+eXp6Wlw3URERPRo0DvslJaWwsqq8pu3LC0tce/ePYML8PX1xalTp3D06FGMGzcOUVFROH/+vDz9wTu8hBBV3vVVVZ/o6Gjk5ubKr+vXrxtcNxERET0a9L71XAiB4cOHQ61WVzi9qKioWgWoVCo0a9YMANChQwccP34c77//PmbPng3gn9Ebd3d3uX92drY82qPRaFBcXIycnByt0Z3s7Gx07ty50mWq1epK14OIiIiURe+RnaioKDRo0EDr9M/9rwYNGmDYsGE1LkgIgaKiIvj4+ECj0SA5OVmeVlxcjP3798tBpn379rC2ttbqk5mZibNnzz407BAREdF/h94jOwkJCUZf+GuvvYZevXrB09MT+fn52LRpE1JSUrBjxw5IkoSpU6diwYIFaN68OZo3b44FCxbAzs4OQ4YMAQA4OTlh1KhRmDFjBlxcXODs7IyZM2ciICAAoaGhRq+XiIiIHj01/rmImvjjjz/w4osvIjMzE05OTmjTpg127NiBsLAwAMCsWbNQWFiI8ePHIycnBx07dsSuXbvg4OAgz2Pp0qWwsrLCwIEDUVhYiO7duyMxMRGWlpamWi0iIiIyIyYNO/Hx8Q+dLkkSYmJiEBMTU2kfGxsbLF++HMuXLzdydURERKQEel+zQ0RERPQoYtghIiIiRdMr7LRr105+YOC8efNw586dWi2KiIiIyFj0CjsXLlzA7du3AQCxsbEoKCio1aKIiIiIjEWvC5QDAwMxYsQIPPnkkxBC4L333kOdOnUq7Pvmm28atUAiIiKimtAr7CQmJmLu3LnYvn07JEnC999/X+FPR0iSxLBDREREZkWvsOPr64tNmzYBACwsLLBnzx40aNCgVgsjIiIiMgaDn7NTVlZWG3UQERER1YpqPVTwl19+wbJly3DhwgVIkoRWrVphypQpaNq0qbHrIyIiIqoRg5+zs3PnTvj5+eHYsWNo06YN/P398eOPP6J169ZaP8hJREREZA4MHtl59dVXMW3aNLzzzjs67bNnz5Z/14qIiIjIHBg8snPhwgWMGjVKp33kyJE4f/68UYoiIiIiMhaDw079+vVx6tQpnfZTp07xDi0iIiIyOwafxho9ejRefvll/Prrr+jcuTMkScLBgwexaNEizJgxozZqJCIiIqo2g8POG2+8AQcHByxZsgTR0dEAAA8PD8TExGDy5MlGL5CIiIioJgwOO5IkYdq0aZg2bRry8/MBAA4ODkYvjIiIiMgYqvWcnXIMOURERGTuDL5AmYiIiOhRwrBDREREisawQ0RERIpmUNgpKSlBSEgIfv7559qqh4iIiMioDAo71tbWOHv2LCRJqq16iIiIiIzK4NNYw4YNQ3x8fG3UQkRERGR0Bt96XlxcjM8++wzJycno0KED7O3ttabHxcUZrTgiIiKimjI47Jw9exbt2rUDAJ1rd3h6i4iIiMyNwWFn3759tVEHERERUa2o9q3nV65cwc6dO1FYWAgAEEIYrSgiIiIiYzE47Ny8eRPdu3dHixYt0Lt3b2RmZgIAXnrpJf7qOREREZkdg8POtGnTYG1tjWvXrsHOzk5uHzRoEHbs2GHU4oiIiIhqyuBrdnbt2oWdO3eiUaNGWu3NmzdHRkaG0QojIiIiMgaDR3Zu376tNaJT7q+//oJarTZKUURERETGYnDYefrpp7FmzRr5vSRJKCsrw7vvvouQkBCjFkdERERUUwafxnr33XfRtWtXnDhxAsXFxZg1axbOnTuHW7du4dChQ7VRIxEREVG1GTyy4+fnhzNnzuDxxx9HWFgYbt++jcjISKSlpaFp06a1USMRERFRtRk8sgMAGo0GsbGxxq6FiIiIyOiqFXZycnIQHx+PCxcuQJIktGrVCiNGjICzs7Ox6yMiIiKqEYNPY+3fvx8+Pj744IMPkJOTg1u3buGDDz6Aj48P9u/fXxs1EhEREVWbwSM7EyZMwMCBA7Fy5UpYWloCAEpLSzF+/HhMmDABZ8+eNXqRRERERNVl8MjOL7/8ghkzZshBBwAsLS0xffp0/PLLL0YtjoiIiKimDA477dq1w4ULF3TaL1y4gMDAQGPURERERGQ0ep3GOnPmjPzfkydPxpQpU3DlyhU88cQTAICjR4/iww8/xDvvvFM7VRIRERFVk15hJzAwEJIkQQght82aNUun35AhQzBo0CDjVUdERERUQ3qFnfT09Nqug4iIiKhW6BV2vLy8arsOIiIiolpRrYcK/vbbbzh06BCys7NRVlamNW3y5MlGKYyIiIjIGAwOOwkJCRg7dixUKhVcXFwgSZI8TZIkhh0iIiIyKwaHnTfffBNvvvkmoqOjYWFh8J3rRERERP8qg9PKnTt3MHjwYAYdIiIieiQYnFhGjRqFL774ojZqISIiIjI6g09jLVy4EBEREdixYwcCAgJgbW2tNT0uLs5oxRERERHVlMFhZ8GCBdi5cyd8fX0BQOcCZSIiIiJzYvBprLi4OKxatQoXLlxASkoK9u3bJ7/27t1r0LwWLlyIxx57DA4ODmjQoAH69++PS5cuafURQiAmJgYeHh6wtbVF165dce7cOa0+RUVFmDRpElxdXWFvb49+/frhxo0bhq4aERERKZDBYUetVqNLly5GWfj+/fsxYcIEHD16FMnJybh37x569OiB27dvy30WL16MuLg4rFixAsePH4dGo0FYWBjy8/PlPlOnTkVSUhI2bdqEgwcPoqCgABERESgtLTVKnURERPToMjjsTJkyBcuXLzfKwnfs2IHhw4ejdevWaNu2LRISEnDt2jWkpqYC+GdUZ9myZZgzZw4iIyPh7++P1atX486dO9iwYQMAIDc3F/Hx8ViyZAlCQ0MRFBSEdevW4aeffsLu3buNUicRERE9ugy+ZufYsWPYu3cvtm/fjtatW+tcoLxly5ZqF5ObmwsAcHZ2BvDPb3JlZWWhR48ech+1Wo3g4GAcPnwYY8aMQWpqKkpKSrT6eHh4wN/fH4cPH0Z4eLjOcoqKilBUVCS/z8vLq3bNREREZN4MDjt169ZFZGSk0QsRQmD69Ol48skn4e/vDwDIysoCALi5uWn1dXNzQ0ZGhtxHpVKhXr16On3KP/+ghQsXIjY21tirQERERGaoWj8XURsmTpyIM2fO4ODBgzrTHrzLSwhR5Z1fD+sTHR2N6dOny+/z8vLg6elZjaqJiIjI3JnFY5AnTZqEb775Bvv27UOjRo3kdo1GAwA6IzTZ2dnyaI9Go0FxcTFycnIq7fMgtVoNR0dHrRcREREpk8Fhx8fHB02aNKn0ZQghBCZOnIgtW7Zg79698PHx0VmWRqNBcnKy3FZcXIz9+/ejc+fOAID27dvD2tpaq09mZibOnj0r9yEiIqL/LoNPY02dOlXrfUlJCdLS0rBjxw688sorBs1rwoQJ2LBhA7Zu3QoHBwd5BMfJyQm2traQJAlTp07FggUL0Lx5czRv3hwLFiyAnZ0dhgwZIvcdNWoUZsyYARcXFzg7O2PmzJkICAhAaGiooatHRERECmNw2JkyZUqF7R9++CFOnDhh0LxWrlwJAOjatatWe0JCAoYPHw4AmDVrFgoLCzF+/Hjk5OSgY8eO2LVrFxwcHOT+S5cuhZWVFQYOHIjCwkJ0794diYmJsLS0NKgeIiIiUh6Dw05levXqhejoaIMuYBZCVNlHkiTExMQgJiam0j42NjZYvny50Z7/Q0RERMphtAuUv/zyS/n5OERERETmwuCRnaCgIK1buoUQyMrKwp9//omPPvrIqMURERER1ZTBYad///5a7y0sLFC/fn107doVLVu2NFZdREREREZhcNiZO3dubdRBREREVCvM4qGCRERERLVF75EdCwuLKn+iQZIk3Lt3r8ZFERERERmL3mEnKSmp0mmHDx/G8uXL9bqVnIiIiOjfpHfYeeaZZ3TaLl68iOjoaGzbtg1Dhw7FW2+9ZdTiiIiIiGqqWtfs/P777xg9ejTatGmDe/fuIS0tDatXr0bjxo2NXR8RERFRjRgUdnJzczF79mw0a9YM586dw549e7Bt2zYEBATUVn1ERERENaL3aazFixdj0aJF0Gg02LhxY4WntYiIiIjMjd5h59VXX4WtrS2aNWuG1atXY/Xq1RX227Jli9GKIyIiIqopvcPOsGHDqrz1nIiIiMjc6B12EhMTa7EMIiIiotrBJygTERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaKZNOwcOHAAffv2hYeHByRJwtdff601XQiBmJgYeHh4wNbWFl27dsW5c+e0+hQVFWHSpElwdXWFvb09+vXrhxs3bvyLa0FERETmzKRh5/bt22jbti1WrFhR4fTFixcjLi4OK1aswPHjx6HRaBAWFob8/Hy5z9SpU5GUlIRNmzbh4MGDKCgoQEREBEpLS/+t1SAiIiIzZmXKhffq1Qu9evWqcJoQAsuWLcOcOXMQGRkJAFi9ejXc3NywYcMGjBkzBrm5uYiPj8fatWsRGhoKAFi3bh08PT2xe/duhIeH/2vrQkRERObJbK/ZSU9PR1ZWFnr06CG3qdVqBAcH4/DhwwCA1NRUlJSUaPXx8PCAv7+/3KciRUVFyMvL03oRERGRMplt2MnKygIAuLm5abW7ubnJ07KysqBSqVCvXr1K+1Rk4cKFcHJykl+enp5Grp6IiIjMhdmGnXKSJGm9F0LotD2oqj7R0dHIzc2VX9evXzdKrURERGR+zDbsaDQaANAZocnOzpZHezQaDYqLi5GTk1Npn4qo1Wo4OjpqvYiIiEiZzDbs+Pj4QKPRIDk5WW4rLi7G/v370blzZwBA+/btYW1trdUnMzMTZ8+elfsQERHRf5tJ78YqKCjAlStX5Pfp6ek4deoUnJ2d0bhxY0ydOhULFixA8+bN0bx5cyxYsAB2dnYYMmQIAMDJyQmjRo3CjBkz4OLiAmdnZ8ycORMBAQHy3VlERET032bSsHPixAmEhITI76dPnw4AiIqKQmJiImbNmoXCwkKMHz8eOTk56NixI3bt2gUHBwf5M0uXLoWVlRUGDhyIwsJCdO/eHYmJibC0tPzX14eIiIjMj0nDTteuXSGEqHS6JEmIiYlBTExMpX1sbGywfPlyLF++vBYqJCIioked2V6zQ0RERGQMDDtERESkaAw7REREpGgMO0RERKRoDDtERESkaAw7REREpGgMO0RERKRoDDtERESkaAw7REREpGgMO0RERKRoDDtERESkaAw7REREpGgMO0RERKRoDDtERESkaAw7REREpGhWpi6AiIhIabxf/dYky736Th+TLNfccWSHiIiIFI1hh4iIiBSNYYeIiIgUjWGHiIiIFI1hh4iIiBSNd2MREdFDmerOIoB3F5FxcGSHiIiIFI0jO0RERP8R/9Xn/3Bkh4iIiBSNIztE9J/zX/2/W6L/KoYdIiJ6JPHCadIXT2MRERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaLxoYJERGaCD8kjqh0c2SEiIiJFY9ghIiIiRWPYISIiIkVj2CEiIiJFY9ghIiIiRWPYISIiIkVj2CEiIiJFY9ghIiIiRWPYISIiIkVj2CEiIiJFY9ghIiIiRWPYISIiIkVj2CEiIiJFY9ghIiIiRWPYISIiIkVTTNj56KOP4OPjAxsbG7Rv3x4//PCDqUsiIiIiM6CIsPP5559j6tSpmDNnDtLS0vDUU0+hV69euHbtmqlLIyIiIhNTRNiJi4vDqFGj8NJLL6FVq1ZYtmwZPD09sXLlSlOXRkRERCb2yIed4uJipKamokePHlrtPXr0wOHDh01UFREREZkLK1MXUFN//fUXSktL4ebmptXu5uaGrKysCj9TVFSEoqIi+X1ubi4AIC8vz+j1lRXdMfo89VXV+piqNtZluIfVZq51AdyXDzLXuoBH8xgz17oAHmMPqo2/r/fPVwjx8I7iEffbb78JAOLw4cNa7fPnzxe+vr4Vfmbu3LkCAF988cUXX3zxpYDX9evXH5oVHvmRHVdXV1haWuqM4mRnZ+uM9pSLjo7G9OnT5fdlZWW4desWXFxcIElSrdZriLy8PHh6euL69etwdHQ0dTky1mUYc60LMN/aWJdhWJfhzLU21mUYIQTy8/Ph4eHx0H6PfNhRqVRo3749kpOT8eyzz8rtycnJeOaZZyr8jFqthlqt1mqrW7dubZZZI46OjmZ1cJVjXYYx17oA862NdRmGdRnOXGtjXfpzcnKqss8jH3YAYPr06XjxxRfRoUMHdOrUCZ988gmuXbuGsWPHmro0IiIiMjFFhJ1Bgwbh5s2bmDdvHjIzM+Hv74/vvvsOXl5epi6NiIiITEwRYQcAxo8fj/Hjx5u6DKNSq9WYO3euzik3U2NdhjHXugDzrY11GYZ1Gc5ca2NdtUMSoqr7tYiIiIgeXY/8QwWJiIiIHoZhh4iIiBSNYYeIiIgUjWHHRBITEw16tk9KSgokScLff/9dazUBrKs6zLU21mUYc60LMN/azKUuc6njQazLjBjnRxuU79ChQ8LCwkKEh4cb/FkvLy+xdOlSrbY7d+6IP/74Q+95FBUViczMTFFWViaEECIhIUE4OTkZpa7JkyeLdu3aCZVKJQICAsyirpkzZ4rBgweLRo0aCRsbG9GiRQvx1ltv1bguIWq2Lz09PYWvr69wd3cXKpVKNGrUSIwZM0ZcuXKlxrUZ8xj766+/hIeHhwAgcnJyTF4XKni8+8qVK01eV/n8AgIChEqlEvXr1xcTJkyoUV1C1OwYc3FxqfSR+Pr+26zNbXbs2DHRrVs34eTkJJycnERwcLBIS0szqK6DBw8KCwsL4e/vL28zQ+u43507d8QXX3whOnXqJOrUqSM0Go2YNWuWKCkpeWgdpvo+PXPmjHj66aeFjY2N8PDwELGxsaKsrMykdRUWFoqoqCjh7+8vLC0txTPPPCNPe9ixXlP319W2bVud6fv27RP9+vUTGo1G2NnZibZt24p169YZvByO7Ohp1apVmDRpEg4ePIhr167VeH62trZo0KCB3v1VKhU0Go3Oz1kYoy4hBEaOHIlBgwbBwsLCLOq6ceMG6tevj3Xr1uHcuXN44403sGDBAqxYsaJGdRmjtoCAAHzzzTf4+eefkZiYiJSUFLzxxht6f74292W5UaNGoW3btgZ9prbrSkhIQGZmpvyKiooyeV1xcXGYM2cOXn31VZw/fx779u1DeHh4jeqqaW329vaIjY3V2lbh4eEIDg7W+99mbW2zu3fvIjw8HI0bN8aPP/6IQ4cOwdXVFeHh4SgpKdG7roSEBEyaNAmXL19GWVmZwXU86PLlyxg6dCh69uyJtLQ0bNq0Cd988w1effXVh9Zhiu/TvLw8hIWFwcPDA8ePH8fy5cvx3nvvIS4uzqR1lZaWwtbWFpMnT0ZoaKjWtIcd6zV1f10VOXz4MNq0aYOvvvoKZ86cwciRIzFs2DBs27bN4AVRFQoKCoSDg4O4ePGiGDRokIiNjdXps3XrVtG+fXuhVquFi4uLePbZZ4UQQgQHB+v835kQ2sn44sWLAoC4cOGC1jyXLFkivLy8RFlZmdi3b5/8f+nl/33/q3Xr1iIkJET4+/vr1GVnZycsLS2rrGvu3LnC09PT7Ooq314qlUqEhIQYpa4JEyYIf39/0aBBA5192aRJE+Hu7q73vhwyZIiQJMmstllwcLB45ZVX5OWYS13l+9JcjzFj1mWsYyw7O1tYWloKOzs7s9xmDg4OAoDYtWuX3nU5ODiI1atXV/gdFBsbKxo3bqzzfdquXTvh5eVVYR19+vQRlpaWWttn+fLlwsbGRuTl5Zlk+1T2ffrmm28KJycncffuXbmuunXrCnd3d7F3716z+J6PiooSrVu31nt7le+3B+sSQoh27dqJN954Q6f9QXPnzq1wZKcivXv3FiNGjNCrbzmGHT3Ex8eLDh06CCGE2LZtm/D29paH84QQYvv27cLS0lK8+eab4vz58+LUqVPi7bffFkIIcfPmTdGoUSMxb948kZmZKTIzM4UQusOA7du3F6+//rrWctu3by+io6OFEELrYCsqKhLLli0TNjY2om3btiIzM1Ns3rxZeHp6CkmSxLFjx7TqAiB27txZZV0P/iMwl7rKt5e1tbUYMGBAtetydHQUcXFxom3btiI/P18kJCQIAOLHH3+U57F8+XIBQEyaNEmvffnbb78JX19fYW1tbRbbLCUlRdSvX19kZGSI2bNny8sxdV0AhEajES4uLsLb21vY2tqK0tJSk9Y1cOBAoVKpxPvvvy9atmwp6tatK6ytrcW1a9fM6hh77733hK2trVn8u5wzZ45wdnYWM2bMEEVFReJ///ufUKlUonXr1qKkpETvuoKCgkRRUZEYPXq0kCRJ/P777yIzM1Pk5+eLxMREAUC89NJL8vaZNGmSkCRJpKamVvj9EB4eLoed8mU+//zzAoDYt2/fv3qsV/V9GhAQIPr166fVNmLECAFAbNiwwSy+56OiooSTk1OVx3r5PPPz88X169eFhYWFXJcQQpw+fVpIkiR++eUXURVDwk6XLl3EjBkz9OpbjmFHD507dxbLli0TQghRUlIiXF1dRXJysjy9U6dOYujQoZV+vqJzzA+Gnbi4ONGkSRP5/aVLlwQAce7cOSGE9sFW/nlLS0uduh577DExbtw4ua6WLVuKrl276lVXRf8IzKEuIYSYM2eO/H+P1a3LyclJZ19aW1uLvn37yvNxd3ev8P/EH6xt8ODBwtbWVgAQgYGBZrHN3n33XdGmTRuxdu1aIYTQCTum3JdvvfWWOHz4sEhLSxODBg0SAORrsExVV58+fYS1tbXw9fUVO3bsEK+//rqwsrISvr6+oqioyOTHWDk/Pz8REhJiFsfY0qVLxdmzZ0XTpk2FhYWFkCRJWFhYiIyMDIPqWrhwoRBCiM8++0xIkqTzferh4SHXJYQQU6dOleuq6PthxowZcli4d++emDt3rrCxsZHbzOn71NbWVowePVpr+5TXs2LFCrP4nu/fv79ex/qDevXqVel+q4q+YeeLL74QKpVKnD17Vq/5luM1O1W4dOkSjh07hsGDBwMArKysMGjQIKxatUruc+rUKXTv3r1Gyxk8eDAyMjJw9OhRAMD69esRGBgIPz+/CvtnZmaitLRUpy4bGxts3LgRd+/exalTp/Dbb79h5MiRj3Rd586dwwcffAAbGxuEhYVVqy7gn3PSD+7L0NBQ7NixA3fv3kVJSQkyMzPRr1+/KmtaunQpTp48ia+//hrZ2dkoLCyUp5lqm23fvh2tWrXCCy+8UOF0U+7L119/HZ06dUJgYCB69uwJGxsbvPvuuyatSwiBkpISfPDBBwgPD0fTpk1hZ2eHy5cvY9++fSY/xgDgyJEjOH/+PJ5++mmtdlNts5KSEowcORJdunTB0aNHMWfOHFhaWqJ3794oLCyssq7y600iIyMBAJaWlrC2ttb5Pn322WflukpKSrB+/fqH1uXv7w8bGxuMHTsWarUaixcvRnFxsbwMc/o+vXv3LrKzs7W2T/PmzQFA55oYU33Pp6enw8nJ6aHHekVGjx5t0H4zVEpKCoYPH45PP/0UrVu3NuizivltrNoSHx+Pe/fuoWHDhnKbEALW1tbIyclBvXr1YGtrW+PluLu7IyQkBBs2bMATTzyBjRs3YsyYMZX2/+GHHwCgwrocHR2RlJQES0tLlJSUYMCAAY9sXefPn0e3bt0QHBwsz7s6dQFAcXFxhfuyrKwMa9euhYuLCyRJQvv27ausS6PRQKPRoGXLlvjxxx+xcOFCZGZmwt3d3WTb7PLly/jhhx/w5ZdfAoB84aerqyvmzJmD2NhYsznGrKyskJeXhz/++MNk28vR0REAtL7QJUmCq6srrl27hvDwcJMeYwDw2WefITAwEN7e3lrtptpmqampuHr1Ko4cOQILCwucO3cOdnZ2SE9Px9atWzF48OCH1vXdd98B+P/bvHzbbNmyRev7NDAwEF9++SWSkpKgVqtRVFRU5TGmVquRk5ODzMxM1KtXD927d8eRI0fg4+OD119/3Wy+T93c3HDmzBkAkLdPefipV6+eyeq6f7+lp6fD09PT4Pn07dsXarXaoP2mr/3796Nv376Ii4vDsGHDDP48w85D3Lt3D2vWrMGSJUvQo0cPrWkDBgzA+vXrMXHiRLRp0wZ79uzBiBEjKpyPSqVCaWlplcsbOnQoZs+ejeeffx6//PKLnOYrquvw4cNQqVRITU3Vqatx48ZISEiAWq2GRqOBnZ3dI1nXuXPn0K1bN0RFRcHPz08r7BhSFwD5C6Giffn0009jyZIlaN68OTQaDQ4ePIixY8c+tLaKFBUVGVybMbfZ888/j6FDh8ptS5cuxapVq/DDDz+gadOmJqurou1VWloKGxsb+VkfpqjLy8sLwD+jt40aNQLwzx+Sv/76S55mymOsoKAAmzdvxsKFCyvsZ4ptVlRUBAsLC50RCEmS5HBdWV337t3Drl27AAAHDhyAo6Mjvv32W8TGxsLT01Pr+zQlJQVRUVFyXYMHD5breti/QUmS4OHhAQCoX78+LCwsUFRUZFbfp2FhYVi3bh0OHDgg17Vu3Tp4eHhAo9GYrK7791t+fr5WwNJ3nlZWVpXut5pISUlBREQEFi1ahJdffrl6MzHopNd/TFJSklCpVOLvv//Wmfbaa6+JwMBAIcQ/5zMtLCzkC5TPnDkjFi1aJPcNCwsT/fr1Ezdu3BB//vmnEKLic565ubnyxWjdu3fXmnb/OdOkpCRhbW0tAIjdu3eLP//8U9y+fVuuq1WrVsLS0lJYWFjoVdcPP/wg9u7dK8aMGSPc3NxEnTp1RFpamigqKjJZXSEhIcLZ2VkMGDBAZGZmyhfEZWdnG7y9hBBi4cKFAoD4+uuvteoSQoixY8cKAMLS0lJ8+OGHD60tKChIBAYGit27d4vU1FTx7bffCg8PD62LI025L+8/xh68ZsdUdT3++ONi0aJF4sCBA+LKlSti+PDhAoCYPHmyybdXjx49hK+vrzh06JB46623hJWVlfDz8xPFxcUmO8bKa3v33XeFWq0Wt27dMpvvi27dugmVSiWGDx8uzp8/L+bPny+sra2Fk5OT+P333x9a1/11lG+zQ4cOCQBiyJAhwt/fX9y+fVv+Pp0wYYJc0/3PPqrs+9TGxkacOXNGnD17VsybN09YWVnJz24xp+/Ta9euCQCibt26omPHjmLLli3C0dFRvPfeeyb/nler1aJFixbC1dVVdO3aVaSlpYm0tDSdY718vz1YlxBC/Pzzz8LS0lJYWlqKo0ePiqpcvnxZpKWliTFjxogWLVrIyyyva9++fcLOzk5ER0fLF0RnZmaKmzdvVjnv+zHsPERERITo3bt3hdNSU1MFAJGamiqEEOKrr74SgYGBQqVSCVdXVxEZGSn3PXLkiGjTpo1Qq9XyrZKVXeD1f//3fwKAWLVqlVb7/QdbeV1jx46VH0A2d+5crbqCgoKEn5+fXnVJkqRzKyEAkZ6ebrK63NzcKqzJy8vL4O1Vvi8bN26sU9f9tfn4+FS5L1esWCHs7Ozkepo3by569+4tHB0dzWJf3n+MVRR2TFGXj4+PfIzZ2dmJhg0bChsbG50Hvplye9WtW1fY29tr3Y1lSF1CGO8Ye/DfpRDm9X1R/gfYyclJ2NnZCSsrK3HkyJEq64qIiBAdO3bUOSbHjh0rnJycBADx8ssva20fSZKEpaWlXt+nVlZWwsnJSdjY2IiOHTuK7777zmy/T3v06CEACCsrK6HRaERMTIzOLd6mqOv+77b7Xw8e6+X7raJjXQghnnrqKeHn5yf0UdHt8ffXFRUVVeH04OBgveZfjmFHgcrKykSLFi3EkiVLTF2KFtZlOHOtjXUZxlzrEsJ8azOXusyljgexLsMw7CjMH3/8Id577z1hb28vbt26ZepyZKzLcOZaG+syjLnWJYT51mYudZlLHQ9iXYbjBcoK4+bmBldXV3zyySc6V/abEusynLnWxroMY651AeZbm7nUZS51PIh1GU4SQghTF0FERERUW/hQQSIiIlI0hh0iIiJSNIYdIiIiUjSGHSIiIlI0hh0i+tclJibKPxWhj5SUFEiShL///rvWaqoub29vLFu2rEbziImJQWBgoFHqISJdDDtEVKXDhw/D0tISPXv2NPizFYWBQYMG4eeff9Z7Hp07d0ZmZiacnJwAGB6WKnP16lVIkoRTp07VeF5EZL4YdoioSqtWrcKkSZNw8OBBXLt2rcbzs7W1RYMGDfTur1KpoNFodH6AkohIHww7RPRQt2/fxubNmzFu3DhEREQgMTFRp88333yDDh06wMbGBq6uroiMjAQAdO3aFRkZGZg2bRokSZLDyv0jM5cuXYIkSbh48aLWPOPi4uDt7Q0hhNZprJSUFIwYMQK5ubnyPGNiYjBv3jwEBATo1Na+fXu8+eab1Vr3X375Bc888wzc3NxQp04dPPbYY9i9e7dOv/z8fAwZMgR16tSBh4cHli9frjU9NzcXL7/8Mho0aABHR0d069YNp0+frnS5KSkpePzxx2Fvb4+6deuiS5cuyMjIqNY6EBHDDhFV4fPPP4evry98fX3xwgsvICEhAfc/i/Tbb79FZGQk+vTpg7S0NOzZswcdOnQAAGzZsgWNGjXCvHnzkJmZiczMTJ35+/r6on379li/fr1W+4YNGzBkyBCd0ZzOnTtj2bJlcHR0lOc5c+ZMjBw5EufPn8fx48flvmfOnEFaWhqGDx9erXUvKChA7969sXv3bqSlpSE8PBx9+/bVGd1699130aZNG5w8eRLR0dGYNm0akpOTAQBCCPTp0wdZWVn47rvvkJqainbt2qF79+64deuWzjLv3buH/v37Izg4GGfOnMGRI0fw8ssvc1SLqCZM+mMVRGT2OnfuLJYtWyaEEKKkpES4urqK5ORkeXqnTp3E0KFDK/28l5eXWLp0qVbbg7/iHRcXJ5o0aSK/v3TpkgAgzp07J4TQ/YXxyn4FvFevXmLcuHHy+6lTp4quXbtWWlt6eroAINLS0irt8yA/Pz+xfPlyrfXr2bOnVp9BgwaJXr16CSGE2LNnj3B0dBR3797V6tO0aVPxv//9TwghxNy5c0Xbtm2FEELcvHlTABApKSl610RED8eRHSKq1KVLl3Ds2DEMHjwYAGBlZYVBgwZh1apVcp9Tp06he/fuNVrO4MGDkZGRgaNHjwIA1q9fj8DAQPj5+Rk0n9GjR2Pjxo24e/cuSkpKsH79eowcObLadd2+fRuzZs2Cn58f6tatizp16uDixYs6IzudOnXSeX/hwgUAQGpqKgoKCuDi4oI6derIr/T0dPzyyy86y3R2dsbw4cPlUaT333+/whExItIffwiUiCoVHx+Pe/fuoWHDhnKbEALW1tbIyclBvXr1YGtrW+PluLu7IyQkBBs2bMATTzyBjRs3YsyYMQbPp2/fvlCr1UhKSoJarUZRUREGDBhQ7bpeeeUV7Ny5E++99x6aNWsGW1tbPPfccyguLq7ys+WnncrKyuDu7o6UlBSdPpXdUZaQkIDJkydjx44d+Pzzz/H6668jOTkZTzzxRLXXhei/jGGHiCp07949rFmzBkuWLEGPHj20pg0YMADr16/HxIkT0aZNG+zZswcjRoyocD4qlQqlpaVVLm/o0KGYPXs2nn/+efzyyy/yaJIh87SyskJUVBQSEhKgVqsxePBg2NnZVbnsyvzwww8YPnw4nn32WQD/XMNz9epVnX7lI1L3v2/ZsiUAoF27dsjKyoKVlRW8vb31XnZQUBCCgoIQHR2NTp06yUGQiAzHsENEFdq+fTtycnIwatQo+fk25Z577jnEx8dj4sSJmDt3Lrp3746mTZti8ODBuHfvHr7//nvMmjULwD/P2Tlw4AAGDx4MtVoNV1fXCpcXGRmJcePGYdy4cQgJCdEaTXqQt7c3CgoKsGfPHrRt2xZ2dnZyqHnppZfQqlUrAMChQ4f0WtdLly7ptPn5+aFZs2bYsmUL+vbtC0mS8MYbb6CsrEyn76FDh7B48WL0798fycnJ+OKLL/Dtt98CAEJDQ9GpUyf0798fixYtgq+vL37//Xd899136N+/v3wxd7n09HR88skn6NevHzw8PHDp0iX8/PPPGDZsmF7rQkQVMPVFQ0RkniIiIkTv3r0rnJaamioAiNTUVCGEEF999ZUIDAwUKpVKuLq6isjISLnvkSNHRJs2bYRarRblXzmVXWD8f//3fwKAWLVqlVb7gxcoCyHE2LFjhYuLiwAg5s6dq9X/qaeeEn5+flWuY/kFyhW90tPTRXp6uggJCRG2trbC09NTrFixQgQHB4spU6bI8/Dy8hKxsbFi4MCBws7OTri5uckXdJfLy8sTkyZNEh4eHsLa2lp4enqKoUOHimvXrgkhtC9QzsrKEv379xfu7u5CpVIJLy8v8eabb4rS0tIq14eIKiYJcd89pEREjzghBFq2bIkxY8Zg+vTppi6HiMwAT2MRkWJkZ2dj7dq1+O233yq9hoiI/nsYdohIMdzc3ODq6opPPvkE9erVM3U5RGQmGHaISDF4Vp6IKsKHChIREZGiMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaIx7BAREZGiMewQERGRojHsEBERkaL9P1y4h2GLvzsLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# apply create_training_testing_data to scaled dataset type II\n",
    "[X_2_train, X_2_test, y_2_train, y_2_test] = create_training_testing_data(scaled_type_II,train_users,test_users,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store train test files type II in the dictionary \n",
    "train_test_files_dic[2]= [X_2_train, X_2_test, y_2_train, y_2_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "______________________________Dataset type III Train features & labels info:______________________________________\n",
      "\n",
      "_____ The weights of each activity _____\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "      <th>Activity 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Weights</th>\n",
       "      <td>0.164495</td>\n",
       "      <td>0.146433</td>\n",
       "      <td>0.138821</td>\n",
       "      <td>0.147981</td>\n",
       "      <td>0.159334</td>\n",
       "      <td>0.158818</td>\n",
       "      <td>0.084118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  \\\n",
       "Weights    0.164495    0.146433    0.138821    0.147981    0.159334   \n",
       "\n",
       "         Activity 6  Activity 7  \n",
       "Weights    0.158818    0.084118  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "______________________________Test features & labels info:______________________________________\n",
      "\n",
      "_____ The weights of each activity _____\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity 1</th>\n",
       "      <th>Activity 2</th>\n",
       "      <th>Activity 3</th>\n",
       "      <th>Activity 4</th>\n",
       "      <th>Activity 5</th>\n",
       "      <th>Activity 6</th>\n",
       "      <th>Activity 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Weights</th>\n",
       "      <td>0.164761</td>\n",
       "      <td>0.158605</td>\n",
       "      <td>0.150982</td>\n",
       "      <td>0.138962</td>\n",
       "      <td>0.151568</td>\n",
       "      <td>0.146878</td>\n",
       "      <td>0.088244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Activity 1  Activity 2  Activity 3  Activity 4  Activity 5  \\\n",
       "Weights    0.164761    0.158605    0.150982    0.138962    0.151568   \n",
       "\n",
       "         Activity 6  Activity 7  \n",
       "Weights    0.146878    0.088244  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# apply create_training_testing_data to scaled dataset type II\n",
    "[X_3_train, X_3_test, y_3_train, y_3_test] = create_training_testing_data(scaled_type_III,train_users,test_users,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store train test files type III in the dictionary \n",
    "train_test_files_dic[3]=[X_3_train, X_3_test, y_3_train, y_3_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI. Train-Test PipeLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB as NB # import gaussian naive bayes classifier\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC # import decision tree classifier\n",
    "from sklearn.linear_model import LogisticRegression as LR # import logistic regression classifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score as accuracy # import accuracy score\n",
    "from sklearn.metrics import confusion_matrix as cm # import confusion matrix\n",
    "\n",
    "# intialize models\n",
    "Benchmark_model =NB()\n",
    "Clf1=DTC(random_state=337)\n",
    "Clf2=LR(random_state=337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the adpted confusion matrix\n",
    "def full_confusion_matrix(Df): \n",
    "    # input: \n",
    "    #   Df : pandas dataframe, the contingency table resulted from the confusion matrix defined earlier as cm\n",
    "    \n",
    "    columns=Df.columns # activity names\n",
    "    # add new columns containing detailed scores\n",
    "    new_columns=list(columns)+['data points number','precision %','sensitivity %','specificity %']\n",
    "    \n",
    "    # create the index from the same old columns add an other row called total\n",
    "    new_index=list(columns)+['Total']\n",
    "    \n",
    "    # intialize the confustion matrix dataframe\n",
    "    new_Df=pd.DataFrame(data=None,columns=new_columns, index= new_index)\n",
    "    # intilize values\n",
    "    total_TP=0 # sum of true positives\n",
    "    total_FN=0 # sum of false negatives\n",
    "    total_data_points_number=0 # total number of datapoints\n",
    "    \n",
    "    for column in columns:\n",
    "        \n",
    "        TP=Df.loc[column][column] # extract true postives from the contingency table\n",
    "        FN=Df.loc[column].sum()-TP # calculate FN(false negatives)\n",
    "        FP=Df[column].sum()-TP # calculate FP(false positives)\n",
    "        TN=(Df.sum()).sum()-TP-FN-FP # calculate TN(true negatives)\n",
    "        class_data_points=TP+FN  # number of datapoints per activity\n",
    "        # precision score in %\n",
    "        precision= TP/float(TP+FP) * 100\n",
    "        # Recall or sensitivity in %\n",
    "        sensitivity= TP/float(TP+FN) *100\n",
    "        # sepecificity score in %\n",
    "        specificity=TN/float(TN+FP) * 100\n",
    "        \n",
    "        new_row =list(Df.loc[column])+[class_data_points,precision,sensitivity,specificity]# contenate new scores in one row\n",
    "        new_Df.loc[column]=new_row # append the row to the dataframe\n",
    "        \n",
    "        # update intialized values\n",
    "        total_data_points_number= total_data_points_number+class_data_points \n",
    "        total_TP=total_TP+TP\n",
    "        total_FN=total_FN+FN\n",
    "    \n",
    "    # after iterting throw all activity types\n",
    "    # the general accuracy of the model is:\n",
    "    total_accuracy= total_TP/float(total_TP+total_FN) * 100\n",
    "    \n",
    "    # add total values to the dataframe\n",
    "    new_Df.loc['Total'] [['data points number','precision %','sensitivity %','specificity %']]=['data points number='+str(total_data_points_number),'','','accuracy= '+str(total_accuracy)[0:6]+'%']\n",
    "    new_Df.loc['Total'][columns]=['' for i in range(len(columns))]\n",
    "    \n",
    "    return new_Df # return the adapted confusion matrix\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(classifier, sample_size, X_train, X_test, y_train,  y_test,typ): \n",
    "    \n",
    "    # inputs:\n",
    "    #   classifier: the learning algorithm to be trained and predicted on\n",
    "    #   sample_size: the size of samples (number) to be drawn from training set\n",
    "    #   X_train: features training set\n",
    "    #   y_train: Activity_number_ID training set\n",
    "    #   X_test: features testing set\n",
    "    #   y_test: Activity_number_ID testing set\n",
    "    \n",
    "    # Empty dictionary will include all dataframes and info related to training and testing.\n",
    "    results = {}\n",
    "    \n",
    "    # Fitting the classifier to the training data using slicing with 'sample_size'\n",
    "    start= timer() # Get start time\n",
    "    classifier = classifier.fit(X_train[0:sample_size,:],y_train[0:sample_size])# fiting the classfier\n",
    "    end = timer() # Get end time\n",
    "    \n",
    "    # Calculate the training time\n",
    "    results['train_time'] = end-start\n",
    "        \n",
    "    # Get the predictions on the test set(X_test),\n",
    "    # then get predictions on the first 3000 training samples(X_train) using .predict()\n",
    "    start = timer() # Get start time\n",
    "    predictions_test = classifier.predict(X_test) # predict\n",
    "    predictions_train =classifier.predict(X_train[:3000,:])\n",
    "    end = timer() # Get end time\n",
    "    \n",
    "    # Calculate the total prediction time\n",
    "    results['pred_time'] =end-start\n",
    "            \n",
    "    # Compute accuracy on the first 300 training samples which is y_train[:300]\n",
    "    results['acc_train'] = accuracy(y_train[:3000],predictions_train)\n",
    "        \n",
    "    # Compute accuracy on test set using accuracy_score()\n",
    "    results['acc_test'] = accuracy(y_test,predictions_test)\n",
    "    \n",
    "    # Adapting the confusion matrix shape to the type of data used\n",
    "    if typ==1:\n",
    "        confusion_matrix=cm(y_test, predictions_test, labels=[1,2,3,4,5,6], sample_weight=None) # \n",
    "        columns=['WK','WU','WD','SI','ST','LD']\n",
    "        index=['WK','WU','WD','SI','ST','LD']\n",
    "    if typ==2:\n",
    "        confusion_matrix=cm(y_test, predictions_test, labels=[1,2,3,4,5,6,7,8,9,10,11,12], sample_weight=None)\n",
    "        columns=['WK','WU','WD','SI','ST','LD','St-Si','Si-St','Si-Li','Li-Si','St-Li','Li-St']\n",
    "        index=  ['WK','WU','WD','SI','ST','LD','St-Si','Si-St','Si-Li','Li-Si','St-Li','Li-St'] \n",
    "    if typ==3:   \n",
    "        confusion_matrix=cm(y_test, predictions_test, labels=[1,2,3,4,5,6,7], sample_weight=None)\n",
    "        columns=['WK','WU','WD','SI','ST','LD','PT']\n",
    "        index=['WK','WU','WD','SI','ST','LD','PT']\n",
    "    \n",
    "    if sample_size==len(X_train):# if 100% of training is achieved\n",
    "        # apply the confusion matrix function to the last contingency table generated\n",
    "        confusion_matrix_df=(pd.DataFrame(data=confusion_matrix,columns=columns,index=index)).pipe(full_confusion_matrix)\n",
    "    else:# if not\n",
    "        # create a dataframe from the contingency table\n",
    "        confusion_matrix_df=pd.DataFrame(data=confusion_matrix,columns=columns,index=index)\n",
    "        \n",
    "    # Return the results\n",
    "    return (results,confusion_matrix_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def train_test_report(classifier,dataset_type):\n",
    "    # Inputs:\n",
    "    #  classifier: model will be trained tested and evaluated on all sample sizes\n",
    "    #  Dataset_type: \"All\"  or integers 1,2,3 \n",
    "    # if \"All\" the classifier will be trained, tested and evaluated on all datasets\n",
    "    # if integer 1, 2 or 3: the classifier the classifier will be trained, tested and evaluated on one dataset(I,II or III)\n",
    "    \n",
    "    if dataset_type!='All': # dataset type equal to 1 ,2 or 3\n",
    "        # extract train and test files related to dataset type\n",
    "        new_dic={dataset_type:train_test_files_dic[dataset_type]}\n",
    "    \n",
    "    else:# the model will be trained , tested and evaluted on all datasets\n",
    "        new_dic=train_test_files_dic # import all train and test files\n",
    "    \n",
    "    for key in sorted(new_dic.keys()):# iterating throw dataset types\n",
    "        clf=classifier # reintialize the classifier\n",
    "        # adapt the dataset name switch the case\n",
    "        if key==1:\n",
    "            Dataset_name='Dataset type I'\n",
    "        if key==2:\n",
    "            Dataset_name='Dataset type II'\n",
    "        if key==3:\n",
    "            Dataset_name='Dataset type III'\n",
    "        \n",
    "        files = new_dic[key] # copy train and test files related to the dataset type\n",
    "        # create a temporal dictionary where train, test and evaluation results will be stored\n",
    "        results = {}\n",
    "        print(\"_____________________\"+Dataset_name+\" Training and Testing______________________\")\n",
    "        print(\"\")\n",
    "        \n",
    "        # copy train and test files\n",
    "        X_train, X_test, y_train, y_test,= files[0], files[1], files[2], files[3]\n",
    "        # extract the name of the classifier\n",
    "        clf_name = clf.__class__.__name__\n",
    "        \n",
    "        # training started\n",
    "        print(\"{} started training....\".format(clf_name) )   \n",
    "        \n",
    "        results[clf_name] = {}\n",
    "        # generate sample sizes\n",
    "        samples_10 = int(len(X_train)/10) # 10%\n",
    "        samples_50 = int(len(X_train)/2) # 50%\n",
    "        samples_100 = int(len(X_train)) # 100%\n",
    "        \n",
    "        \n",
    "        for i, samples in enumerate([samples_10, samples_50, samples_100]): # iterate throw each sample size\n",
    "            print(\"...\")\n",
    "            if samples==len(X_train):# when 100% of training will be achieved\n",
    "                # store results related to the classier and sample size in results dictionary\n",
    "                # store the full confusion matrix\n",
    "                results[clf_name][i],confusion_matrix = train_predict(clf, samples, X_train, X_test, y_train, y_test,key)\n",
    "            else:# if not\n",
    "                # store results related to the classier and sample size in results dictionary\n",
    "                results[clf_name][i]= train_predict(clf, samples, X_train,X_test, y_train,  y_test,key)[0]\n",
    "\n",
    "        print( \"Success: {} Finished Training and Testing.\".format(clf_name))\n",
    "        print(\"\")\n",
    "        print (\"________\"+clf_name+\" results:__________\")\n",
    "        print(\"\")\n",
    "        print(\"\")\n",
    "        print(\"Accuracy and duration per training size\")\n",
    "        # display train and test results\n",
    "        display(pd.DataFrame(results[clf_name]).rename(columns={0:'10% of train', 1:'50% of train', 2:'100% of train'}))\n",
    "        print(\"\")\n",
    "        print(\"Confusion Matrix Sensitivity and Recall when 100% of train is achieved\")\n",
    "        # display the full confusion matrix results\n",
    "        display(confusion_matrix)\n",
    "        print(\"____________________________________________________________________\")\n",
    "        print(\"\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VII. Benchmark Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________Dataset type I Training and Testing______________________\n",
      "\n",
      "GaussianNB started training....\n",
      "...\n",
      "...\n",
      "...\n",
      "Success: GaussianNB Finished Training and Testing.\n",
      "\n",
      "________GaussianNB results:__________\n",
      "\n",
      "\n",
      "Accuracy and duration per training size\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10% of train</th>\n",
       "      <th>50% of train</th>\n",
       "      <th>100% of train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_time</th>\n",
       "      <td>0.045975</td>\n",
       "      <td>0.047681</td>\n",
       "      <td>0.089696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_time</th>\n",
       "      <td>0.362178</td>\n",
       "      <td>0.381262</td>\n",
       "      <td>0.369893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>0.703667</td>\n",
       "      <td>0.758667</td>\n",
       "      <td>0.755000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.700283</td>\n",
       "      <td>0.722930</td>\n",
       "      <td>0.720807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            10% of train  50% of train  100% of train\n",
       "train_time      0.045975      0.047681       0.089696\n",
       "pred_time       0.362178      0.381262       0.369893\n",
       "acc_train       0.703667      0.758667       0.755000\n",
       "acc_test        0.700283      0.722930       0.720807"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix Sensitivity and Recall when 100% of train is achieved\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WK</th>\n",
       "      <th>WU</th>\n",
       "      <th>WD</th>\n",
       "      <th>SI</th>\n",
       "      <th>ST</th>\n",
       "      <th>LD</th>\n",
       "      <th>data points number</th>\n",
       "      <th>precision %</th>\n",
       "      <th>sensitivity %</th>\n",
       "      <th>specificity %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WK</th>\n",
       "      <td>267</td>\n",
       "      <td>222</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>505</td>\n",
       "      <td>80.664653</td>\n",
       "      <td>52.871287</td>\n",
       "      <td>97.242568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WU</th>\n",
       "      <td>12</td>\n",
       "      <td>461</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>477</td>\n",
       "      <td>58.060453</td>\n",
       "      <td>96.645702</td>\n",
       "      <td>85.823755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WD</th>\n",
       "      <td>52</td>\n",
       "      <td>107</td>\n",
       "      <td>269</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>428</td>\n",
       "      <td>93.079585</td>\n",
       "      <td>62.850467</td>\n",
       "      <td>99.165972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SI</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>365</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>442</td>\n",
       "      <td>55.30303</td>\n",
       "      <td>82.579186</td>\n",
       "      <td>87.625839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>295</td>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "      <td>493</td>\n",
       "      <td>71.586716</td>\n",
       "      <td>39.350913</td>\n",
       "      <td>96.699529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LD</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>481</td>\n",
       "      <td>481</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>data points number=2826</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>accuracy= 72.080%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WK   WU   WD   SI   ST   LD       data points number precision %  \\\n",
       "WK     267  222   16    0    0    0                      505   80.664653   \n",
       "WU      12  461    4    0    0    0                      477   58.060453   \n",
       "WD      52  107  269    0    0    0                      428   93.079585   \n",
       "SI       0    0    0  365   77    0                      442    55.30303   \n",
       "ST       0    4    0  295  194    0                      493   71.586716   \n",
       "LD       0    0    0    0    0  481                      481       100.0   \n",
       "Total                                data points number=2826               \n",
       "\n",
       "      sensitivity %      specificity %  \n",
       "WK        52.871287          97.242568  \n",
       "WU        96.645702          85.823755  \n",
       "WD        62.850467          99.165972  \n",
       "SI        82.579186          87.625839  \n",
       "ST        39.350913          96.699529  \n",
       "LD            100.0              100.0  \n",
       "Total                accuracy= 72.080%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________\n",
      "\n",
      "\n",
      "_____________________Dataset type II Training and Testing______________________\n",
      "\n",
      "GaussianNB started training....\n",
      "...\n",
      "...\n",
      "...\n",
      "Success: GaussianNB Finished Training and Testing.\n",
      "\n",
      "________GaussianNB results:__________\n",
      "\n",
      "\n",
      "Accuracy and duration per training size\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10% of train</th>\n",
       "      <th>50% of train</th>\n",
       "      <th>100% of train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_time</th>\n",
       "      <td>0.005758</td>\n",
       "      <td>0.054817</td>\n",
       "      <td>0.106182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_time</th>\n",
       "      <td>0.749010</td>\n",
       "      <td>0.791993</td>\n",
       "      <td>0.815981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>0.655667</td>\n",
       "      <td>0.717667</td>\n",
       "      <td>0.707000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.654060</td>\n",
       "      <td>0.649077</td>\n",
       "      <td>0.654647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            10% of train  50% of train  100% of train\n",
       "train_time      0.005758      0.054817       0.106182\n",
       "pred_time       0.749010      0.791993       0.815981\n",
       "acc_train       0.655667      0.717667       0.707000\n",
       "acc_test        0.654060      0.649077       0.654647"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix Sensitivity and Recall when 100% of train is achieved\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WK</th>\n",
       "      <th>WU</th>\n",
       "      <th>WD</th>\n",
       "      <th>SI</th>\n",
       "      <th>ST</th>\n",
       "      <th>LD</th>\n",
       "      <th>St-Si</th>\n",
       "      <th>Si-St</th>\n",
       "      <th>Si-Li</th>\n",
       "      <th>Li-Si</th>\n",
       "      <th>St-Li</th>\n",
       "      <th>Li-St</th>\n",
       "      <th>data points number</th>\n",
       "      <th>precision %</th>\n",
       "      <th>sensitivity %</th>\n",
       "      <th>specificity %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WK</th>\n",
       "      <td>305</td>\n",
       "      <td>225</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>562</td>\n",
       "      <td>78.205128</td>\n",
       "      <td>54.270463</td>\n",
       "      <td>97.016497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WU</th>\n",
       "      <td>13</td>\n",
       "      <td>425</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "      <td>541</td>\n",
       "      <td>55.26658</td>\n",
       "      <td>78.558226</td>\n",
       "      <td>88.013937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WD</th>\n",
       "      <td>72</td>\n",
       "      <td>118</td>\n",
       "      <td>309</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>515</td>\n",
       "      <td>95.665635</td>\n",
       "      <td>60.0</td>\n",
       "      <td>99.516575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SI</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>412</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>474</td>\n",
       "      <td>54.64191</td>\n",
       "      <td>86.919831</td>\n",
       "      <td>88.355465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>517</td>\n",
       "      <td>72.727273</td>\n",
       "      <td>30.947776</td>\n",
       "      <td>97.926745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LD</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>493</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>501</td>\n",
       "      <td>99.59596</td>\n",
       "      <td>98.403194</td>\n",
       "      <td>99.931271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>St-Si</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>50.0</td>\n",
       "      <td>34.693878</td>\n",
       "      <td>99.494349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si-St</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>38.75</td>\n",
       "      <td>93.939394</td>\n",
       "      <td>98.549438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si-Li</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>10.909091</td>\n",
       "      <td>99.016687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Li-Si</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>32.352941</td>\n",
       "      <td>70.212766</td>\n",
       "      <td>97.94887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>St-Li</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "      <td>18.27957</td>\n",
       "      <td>52.307692</td>\n",
       "      <td>95.457262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Li-St</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "      <td>42.105263</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>99.672522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>data points number=3411</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>accuracy= 65.464%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WK   WU   WD   SI   ST   LD St-Si Si-St Si-Li Li-Si St-Li Li-St  \\\n",
       "WK     305  225   14    0    0    0     1     0     0     0    16     1   \n",
       "WU      13  425    0    0    0    0    11     2     6     0    81     3   \n",
       "WD      72  118  309    0    0    0     1     0     1     0    14     0   \n",
       "SI       0    0    0  412   60    2     0     0     0     0     0     0   \n",
       "ST       0    0    0  342  160    0     0    13     0     2     0     0   \n",
       "LD       0    0    0    0    0  493     0     0     0     8     0     0   \n",
       "St-Si    0    0    0    0    0    0    17    23     1     2     5     1   \n",
       "Si-St    0    0    0    0    0    0     2    31     0     0     0     0   \n",
       "Si-Li    0    0    0    0    0    0     0     4     6    23    21     1   \n",
       "Li-Si    0    0    0    0    0    0     0     6     4    33     2     2   \n",
       "St-Li    0    0    0    0    0    0     1     0    14    13    34     3   \n",
       "Li-St    0    1    0    0    0    0     1     1     7    21    13     8   \n",
       "Total                                                                     \n",
       "\n",
       "            data points number precision % sensitivity %      specificity %  \n",
       "WK                         562   78.205128     54.270463          97.016497  \n",
       "WU                         541    55.26658     78.558226          88.013937  \n",
       "WD                         515   95.665635          60.0          99.516575  \n",
       "SI                         474    54.64191     86.919831          88.355465  \n",
       "ST                         517   72.727273     30.947776          97.926745  \n",
       "LD                         501    99.59596     98.403194          99.931271  \n",
       "St-Si                       49        50.0     34.693878          99.494349  \n",
       "Si-St                       33       38.75     93.939394          98.549438  \n",
       "Si-Li                       55   15.384615     10.909091          99.016687  \n",
       "Li-Si                       47   32.352941     70.212766           97.94887  \n",
       "St-Li                       65    18.27957     52.307692          95.457262  \n",
       "Li-St                       52   42.105263     15.384615          99.672522  \n",
       "Total  data points number=3411                            accuracy= 65.464%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________\n",
      "\n",
      "\n",
      "_____________________Dataset type III Training and Testing______________________\n",
      "\n",
      "GaussianNB started training....\n",
      "...\n",
      "...\n",
      "...\n",
      "Success: GaussianNB Finished Training and Testing.\n",
      "\n",
      "________GaussianNB results:__________\n",
      "\n",
      "\n",
      "Accuracy and duration per training size\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10% of train</th>\n",
       "      <th>50% of train</th>\n",
       "      <th>100% of train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_time</th>\n",
       "      <td>0.010888</td>\n",
       "      <td>0.054555</td>\n",
       "      <td>0.112070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_time</th>\n",
       "      <td>0.506600</td>\n",
       "      <td>0.458690</td>\n",
       "      <td>0.506327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>0.697000</td>\n",
       "      <td>0.758000</td>\n",
       "      <td>0.752667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.703313</td>\n",
       "      <td>0.706831</td>\n",
       "      <td>0.712108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            10% of train  50% of train  100% of train\n",
       "train_time      0.010888      0.054555       0.112070\n",
       "pred_time       0.506600      0.458690       0.506327\n",
       "acc_train       0.697000      0.758000       0.752667\n",
       "acc_test        0.703313      0.706831       0.712108"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix Sensitivity and Recall when 100% of train is achieved\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WK</th>\n",
       "      <th>WU</th>\n",
       "      <th>WD</th>\n",
       "      <th>SI</th>\n",
       "      <th>ST</th>\n",
       "      <th>LD</th>\n",
       "      <th>PT</th>\n",
       "      <th>data points number</th>\n",
       "      <th>precision %</th>\n",
       "      <th>sensitivity %</th>\n",
       "      <th>specificity %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WK</th>\n",
       "      <td>305</td>\n",
       "      <td>230</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>562</td>\n",
       "      <td>78.205128</td>\n",
       "      <td>54.270463</td>\n",
       "      <td>97.016497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WU</th>\n",
       "      <td>13</td>\n",
       "      <td>447</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>541</td>\n",
       "      <td>55.597015</td>\n",
       "      <td>82.624769</td>\n",
       "      <td>87.560976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WD</th>\n",
       "      <td>72</td>\n",
       "      <td>125</td>\n",
       "      <td>309</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>515</td>\n",
       "      <td>95.076923</td>\n",
       "      <td>60.0</td>\n",
       "      <td>99.447514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SI</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>412</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>474</td>\n",
       "      <td>54.64191</td>\n",
       "      <td>86.919831</td>\n",
       "      <td>88.355465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>342</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>517</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>31.914894</td>\n",
       "      <td>97.926745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LD</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>493</td>\n",
       "      <td>8</td>\n",
       "      <td>501</td>\n",
       "      <td>99.59596</td>\n",
       "      <td>98.403194</td>\n",
       "      <td>99.931271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>298</td>\n",
       "      <td>301</td>\n",
       "      <td>71.291866</td>\n",
       "      <td>99.003322</td>\n",
       "      <td>96.141479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>data points number=3411</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>accuracy= 71.210%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WK   WU   WD   SI   ST   LD   PT       data points number precision %  \\\n",
       "WK     305  230   15    0    0    0   12                      562   78.205128   \n",
       "WU      13  447    0    0    0    0   81                      541   55.597015   \n",
       "WD      72  125  309    0    0    0    9                      515   95.076923   \n",
       "SI       0    0    0  412   60    2    0                      474    54.64191   \n",
       "ST       0    0    0  342  165    0   10                      517   73.333333   \n",
       "LD       0    0    0    0    0  493    8                      501    99.59596   \n",
       "PT       0    2    1    0    0    0  298                      301   71.291866   \n",
       "Total                                     data points number=3411               \n",
       "\n",
       "      sensitivity %      specificity %  \n",
       "WK        54.270463          97.016497  \n",
       "WU        82.624769          87.560976  \n",
       "WD             60.0          99.447514  \n",
       "SI        86.919831          88.355465  \n",
       "ST        31.914894          97.926745  \n",
       "LD        98.403194          99.931271  \n",
       "PT        99.003322          96.141479  \n",
       "Total                accuracy= 71.210%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training, testing and evaluating the benchmark model on all datasets\n",
    "train_test_report(Benchmark_model,'All')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIII. Elected Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________Dataset type I Training and Testing______________________\n",
      "\n",
      "DecisionTreeClassifier started training....\n",
      "...\n",
      "...\n",
      "...\n",
      "Success: DecisionTreeClassifier Finished Training and Testing.\n",
      "\n",
      "________DecisionTreeClassifier results:__________\n",
      "\n",
      "\n",
      "Accuracy and duration per training size\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10% of train</th>\n",
       "      <th>50% of train</th>\n",
       "      <th>100% of train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_time</th>\n",
       "      <td>0.256061</td>\n",
       "      <td>2.622621</td>\n",
       "      <td>8.777621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_time</th>\n",
       "      <td>0.013214</td>\n",
       "      <td>0.016337</td>\n",
       "      <td>0.017536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>0.722333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.739915</td>\n",
       "      <td>0.820594</td>\n",
       "      <td>0.876504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            10% of train  50% of train  100% of train\n",
       "train_time      0.256061      2.622621       8.777621\n",
       "pred_time       0.013214      0.016337       0.017536\n",
       "acc_train       0.722333      1.000000       1.000000\n",
       "acc_test        0.739915      0.820594       0.876504"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix Sensitivity and Recall when 100% of train is achieved\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WK</th>\n",
       "      <th>WU</th>\n",
       "      <th>WD</th>\n",
       "      <th>SI</th>\n",
       "      <th>ST</th>\n",
       "      <th>LD</th>\n",
       "      <th>data points number</th>\n",
       "      <th>precision %</th>\n",
       "      <th>sensitivity %</th>\n",
       "      <th>specificity %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WK</th>\n",
       "      <td>445</td>\n",
       "      <td>9</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>505</td>\n",
       "      <td>87.084149</td>\n",
       "      <td>88.118812</td>\n",
       "      <td>97.156398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WU</th>\n",
       "      <td>38</td>\n",
       "      <td>380</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>477</td>\n",
       "      <td>87.962963</td>\n",
       "      <td>79.66457</td>\n",
       "      <td>97.786292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WD</th>\n",
       "      <td>28</td>\n",
       "      <td>42</td>\n",
       "      <td>358</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>428</td>\n",
       "      <td>76.495726</td>\n",
       "      <td>83.64486</td>\n",
       "      <td>95.412844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SI</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>359</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>442</td>\n",
       "      <td>90.201005</td>\n",
       "      <td>81.221719</td>\n",
       "      <td>98.364094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>454</td>\n",
       "      <td>0</td>\n",
       "      <td>493</td>\n",
       "      <td>84.701493</td>\n",
       "      <td>92.089249</td>\n",
       "      <td>96.485212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LD</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>481</td>\n",
       "      <td>481</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>data points number=2826</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>accuracy= 87.650%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WK   WU   WD   SI   ST   LD       data points number precision %  \\\n",
       "WK     445    9   51    0    0    0                      505   87.084149   \n",
       "WU      38  380   59    0    0    0                      477   87.962963   \n",
       "WD      28   42  358    0    0    0                      428   76.495726   \n",
       "SI       0    1    0  359   82    0                      442   90.201005   \n",
       "ST       0    0    0   39  454    0                      493   84.701493   \n",
       "LD       0    0    0    0    0  481                      481       100.0   \n",
       "Total                                data points number=2826               \n",
       "\n",
       "      sensitivity %      specificity %  \n",
       "WK        88.118812          97.156398  \n",
       "WU         79.66457          97.786292  \n",
       "WD         83.64486          95.412844  \n",
       "SI        81.221719          98.364094  \n",
       "ST        92.089249          96.485212  \n",
       "LD            100.0              100.0  \n",
       "Total                accuracy= 87.650%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________\n",
      "\n",
      "\n",
      "_____________________Dataset type II Training and Testing______________________\n",
      "\n",
      "DecisionTreeClassifier started training....\n",
      "...\n",
      "...\n",
      "...\n",
      "Success: DecisionTreeClassifier Finished Training and Testing.\n",
      "\n",
      "________DecisionTreeClassifier results:__________\n",
      "\n",
      "\n",
      "Accuracy and duration per training size\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10% of train</th>\n",
       "      <th>50% of train</th>\n",
       "      <th>100% of train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_time</th>\n",
       "      <td>0.378742</td>\n",
       "      <td>4.208790</td>\n",
       "      <td>12.269386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_time</th>\n",
       "      <td>0.017755</td>\n",
       "      <td>0.019301</td>\n",
       "      <td>0.021476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>0.762000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.691000</td>\n",
       "      <td>0.781589</td>\n",
       "      <td>0.826737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            10% of train  50% of train  100% of train\n",
       "train_time      0.378742      4.208790      12.269386\n",
       "pred_time       0.017755      0.019301       0.021476\n",
       "acc_train       0.762000      1.000000       1.000000\n",
       "acc_test        0.691000      0.781589       0.826737"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix Sensitivity and Recall when 100% of train is achieved\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WK</th>\n",
       "      <th>WU</th>\n",
       "      <th>WD</th>\n",
       "      <th>SI</th>\n",
       "      <th>ST</th>\n",
       "      <th>LD</th>\n",
       "      <th>St-Si</th>\n",
       "      <th>Si-St</th>\n",
       "      <th>Si-Li</th>\n",
       "      <th>Li-Si</th>\n",
       "      <th>St-Li</th>\n",
       "      <th>Li-St</th>\n",
       "      <th>data points number</th>\n",
       "      <th>precision %</th>\n",
       "      <th>sensitivity %</th>\n",
       "      <th>specificity %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WK</th>\n",
       "      <td>525</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>562</td>\n",
       "      <td>85.784314</td>\n",
       "      <td>93.41637</td>\n",
       "      <td>96.946297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WU</th>\n",
       "      <td>41</td>\n",
       "      <td>443</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>541</td>\n",
       "      <td>85.356455</td>\n",
       "      <td>81.885397</td>\n",
       "      <td>97.351916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WD</th>\n",
       "      <td>45</td>\n",
       "      <td>65</td>\n",
       "      <td>405</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>515</td>\n",
       "      <td>84.728033</td>\n",
       "      <td>78.640777</td>\n",
       "      <td>97.479282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SI</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>388</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>474</td>\n",
       "      <td>85.651214</td>\n",
       "      <td>81.85654</td>\n",
       "      <td>97.786857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>517</td>\n",
       "      <td>83.955224</td>\n",
       "      <td>87.040619</td>\n",
       "      <td>97.028334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LD</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>499</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>501</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.600798</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>St-Si</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>43.478261</td>\n",
       "      <td>40.816327</td>\n",
       "      <td>99.226651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si-St</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>48.484848</td>\n",
       "      <td>48.484848</td>\n",
       "      <td>99.496744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si-Li</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>55</td>\n",
       "      <td>36.206897</td>\n",
       "      <td>38.181818</td>\n",
       "      <td>98.897497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Li-Si</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>47</td>\n",
       "      <td>24.444444</td>\n",
       "      <td>23.404255</td>\n",
       "      <td>98.989298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>St-Li</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>65</td>\n",
       "      <td>30.30303</td>\n",
       "      <td>30.769231</td>\n",
       "      <td>98.625224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Li-St</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>52</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>42.307692</td>\n",
       "      <td>98.690086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>data points number=3411</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>accuracy= 82.673%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WK   WU   WD   SI   ST   LD St-Si Si-St Si-Li Li-Si St-Li Li-St  \\\n",
       "WK     525    9   20    0    0    0     6     2     0     0     0     0   \n",
       "WU      41  443   52    0    0    0     3     0     0     0     2     0   \n",
       "WD      45   65  405    0    0    0     0     0     0     0     0     0   \n",
       "SI       0    0    0  388   86    0     0     0     0     0     0     0   \n",
       "ST       0    0    0   65  450    0     0     0     0     2     0     0   \n",
       "LD       0    0    0    0    0  499     0     0     0     1     0     1   \n",
       "St-Si    1    0    0    0    0    0    20    12     1     2     7     6   \n",
       "Si-St    0    2    0    0    0    0    11    16     2     0     0     2   \n",
       "Si-Li    0    0    0    0    0    0     1     0    21    10    13    10   \n",
       "Li-Si    0    0    0    0    0    0     3     2    10    11    12     9   \n",
       "St-Li    0    0    0    0    0    0     1     0    16    12    20    16   \n",
       "Li-St    0    0    1    0    0    0     1     1     8     7    12    22   \n",
       "Total                                                                     \n",
       "\n",
       "            data points number precision % sensitivity %      specificity %  \n",
       "WK                         562   85.784314      93.41637          96.946297  \n",
       "WU                         541   85.356455     81.885397          97.351916  \n",
       "WD                         515   84.728033     78.640777          97.479282  \n",
       "SI                         474   85.651214      81.85654          97.786857  \n",
       "ST                         517   83.955224     87.040619          97.028334  \n",
       "LD                         501       100.0     99.600798              100.0  \n",
       "St-Si                       49   43.478261     40.816327          99.226651  \n",
       "Si-St                       33   48.484848     48.484848          99.496744  \n",
       "Si-Li                       55   36.206897     38.181818          98.897497  \n",
       "Li-Si                       47   24.444444     23.404255          98.989298  \n",
       "St-Li                       65    30.30303     30.769231          98.625224  \n",
       "Li-St                       52   33.333333     42.307692          98.690086  \n",
       "Total  data points number=3411                            accuracy= 82.673%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________\n",
      "\n",
      "\n",
      "_____________________Dataset type III Training and Testing______________________\n",
      "\n",
      "DecisionTreeClassifier started training....\n",
      "...\n",
      "...\n",
      "...\n",
      "Success: DecisionTreeClassifier Finished Training and Testing.\n",
      "\n",
      "________DecisionTreeClassifier results:__________\n",
      "\n",
      "\n",
      "Accuracy and duration per training size\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10% of train</th>\n",
       "      <th>50% of train</th>\n",
       "      <th>100% of train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_time</th>\n",
       "      <td>0.311743</td>\n",
       "      <td>3.764707</td>\n",
       "      <td>11.711749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_time</th>\n",
       "      <td>0.018903</td>\n",
       "      <td>0.020683</td>\n",
       "      <td>0.019012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>0.781000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.760188</td>\n",
       "      <td>0.843741</td>\n",
       "      <td>0.874524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            10% of train  50% of train  100% of train\n",
       "train_time      0.311743      3.764707      11.711749\n",
       "pred_time       0.018903      0.020683       0.019012\n",
       "acc_train       0.781000      1.000000       1.000000\n",
       "acc_test        0.760188      0.843741       0.874524"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix Sensitivity and Recall when 100% of train is achieved\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WK</th>\n",
       "      <th>WU</th>\n",
       "      <th>WD</th>\n",
       "      <th>SI</th>\n",
       "      <th>ST</th>\n",
       "      <th>LD</th>\n",
       "      <th>PT</th>\n",
       "      <th>data points number</th>\n",
       "      <th>precision %</th>\n",
       "      <th>sensitivity %</th>\n",
       "      <th>specificity %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WK</th>\n",
       "      <td>511</td>\n",
       "      <td>23</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>562</td>\n",
       "      <td>84.323432</td>\n",
       "      <td>90.925267</td>\n",
       "      <td>96.665497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WU</th>\n",
       "      <td>65</td>\n",
       "      <td>432</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>541</td>\n",
       "      <td>82.600382</td>\n",
       "      <td>79.852126</td>\n",
       "      <td>96.829268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WD</th>\n",
       "      <td>29</td>\n",
       "      <td>66</td>\n",
       "      <td>418</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>515</td>\n",
       "      <td>88.185654</td>\n",
       "      <td>81.165049</td>\n",
       "      <td>98.066298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SI</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>377</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>474</td>\n",
       "      <td>85.10158</td>\n",
       "      <td>79.535865</td>\n",
       "      <td>97.752809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>449</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>517</td>\n",
       "      <td>82.234432</td>\n",
       "      <td>86.847195</td>\n",
       "      <td>96.648238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LD</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>499</td>\n",
       "      <td>2</td>\n",
       "      <td>501</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.600798</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>297</td>\n",
       "      <td>301</td>\n",
       "      <td>92.8125</td>\n",
       "      <td>98.671096</td>\n",
       "      <td>99.26045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>data points number=3411</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>accuracy= 87.452%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WK   WU   WD   SI   ST   LD   PT       data points number precision %  \\\n",
       "WK     511   23   26    0    0    0    2                      562   84.323432   \n",
       "WU      65  432   29    0    0    0   15                      541   82.600382   \n",
       "WD      29   66  418    0    0    0    2                      515   88.185654   \n",
       "SI       0    0    0  377   97    0    0                      474    85.10158   \n",
       "ST       0    0    0   66  449    0    2                      517   82.234432   \n",
       "LD       0    0    0    0    0  499    2                      501       100.0   \n",
       "PT       1    2    1    0    0    0  297                      301     92.8125   \n",
       "Total                                     data points number=3411               \n",
       "\n",
       "      sensitivity %      specificity %  \n",
       "WK        90.925267          96.665497  \n",
       "WU        79.852126          96.829268  \n",
       "WD        81.165049          98.066298  \n",
       "SI        79.535865          97.752809  \n",
       "ST        86.847195          96.648238  \n",
       "LD        99.600798              100.0  \n",
       "PT        98.671096           99.26045  \n",
       "Total                accuracy= 87.452%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training, testing and evaluating Decision tree classifier on all datasets\n",
    "train_test_report(Clf1,'All')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________Dataset type I Training and Testing______________________\n",
      "\n",
      "LogisticRegression started training....\n",
      "...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "Success: LogisticRegression Finished Training and Testing.\n",
      "\n",
      "________LogisticRegression results:__________\n",
      "\n",
      "\n",
      "Accuracy and duration per training size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10% of train</th>\n",
       "      <th>50% of train</th>\n",
       "      <th>100% of train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_time</th>\n",
       "      <td>0.364207</td>\n",
       "      <td>0.689905</td>\n",
       "      <td>1.350923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_time</th>\n",
       "      <td>0.012425</td>\n",
       "      <td>0.009896</td>\n",
       "      <td>0.019197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>0.887333</td>\n",
       "      <td>0.995667</td>\n",
       "      <td>0.984000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.882166</td>\n",
       "      <td>0.938429</td>\n",
       "      <td>0.958245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            10% of train  50% of train  100% of train\n",
       "train_time      0.364207      0.689905       1.350923\n",
       "pred_time       0.012425      0.009896       0.019197\n",
       "acc_train       0.887333      0.995667       0.984000\n",
       "acc_test        0.882166      0.938429       0.958245"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix Sensitivity and Recall when 100% of train is achieved\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WK</th>\n",
       "      <th>WU</th>\n",
       "      <th>WD</th>\n",
       "      <th>SI</th>\n",
       "      <th>ST</th>\n",
       "      <th>LD</th>\n",
       "      <th>data points number</th>\n",
       "      <th>precision %</th>\n",
       "      <th>sensitivity %</th>\n",
       "      <th>specificity %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WK</th>\n",
       "      <td>499</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>505</td>\n",
       "      <td>96.332046</td>\n",
       "      <td>98.811881</td>\n",
       "      <td>99.181387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WU</th>\n",
       "      <td>15</td>\n",
       "      <td>462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>477</td>\n",
       "      <td>97.674419</td>\n",
       "      <td>96.855346</td>\n",
       "      <td>99.531716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WD</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>418</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>428</td>\n",
       "      <td>99.761337</td>\n",
       "      <td>97.663551</td>\n",
       "      <td>99.958299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SI</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>379</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>442</td>\n",
       "      <td>94.044665</td>\n",
       "      <td>85.746606</td>\n",
       "      <td>98.993289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>469</td>\n",
       "      <td>0</td>\n",
       "      <td>493</td>\n",
       "      <td>88.157895</td>\n",
       "      <td>95.131846</td>\n",
       "      <td>97.299614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LD</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>481</td>\n",
       "      <td>481</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>data points number=2826</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>accuracy= 95.824%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WK   WU   WD   SI   ST   LD       data points number precision %  \\\n",
       "WK     499    5    1    0    0    0                      505   96.332046   \n",
       "WU      15  462    0    0    0    0                      477   97.674419   \n",
       "WD       4    6  418    0    0    0                      428   99.761337   \n",
       "SI       0    0    0  379   63    0                      442   94.044665   \n",
       "ST       0    0    0   24  469    0                      493   88.157895   \n",
       "LD       0    0    0    0    0  481                      481       100.0   \n",
       "Total                                data points number=2826               \n",
       "\n",
       "      sensitivity %      specificity %  \n",
       "WK        98.811881          99.181387  \n",
       "WU        96.855346          99.531716  \n",
       "WD        97.663551          99.958299  \n",
       "SI        85.746606          98.993289  \n",
       "ST        95.131846          97.299614  \n",
       "LD            100.0              100.0  \n",
       "Total                accuracy= 95.824%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________\n",
      "\n",
      "\n",
      "_____________________Dataset type II Training and Testing______________________\n",
      "\n",
      "LogisticRegression started training....\n",
      "...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "Success: LogisticRegression Finished Training and Testing.\n",
      "\n",
      "________LogisticRegression results:__________\n",
      "\n",
      "\n",
      "Accuracy and duration per training size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10% of train</th>\n",
       "      <th>50% of train</th>\n",
       "      <th>100% of train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_time</th>\n",
       "      <td>0.498732</td>\n",
       "      <td>1.778876</td>\n",
       "      <td>3.319018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_time</th>\n",
       "      <td>0.014198</td>\n",
       "      <td>0.012248</td>\n",
       "      <td>0.010358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>0.830667</td>\n",
       "      <td>0.987667</td>\n",
       "      <td>0.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.812958</td>\n",
       "      <td>0.906186</td>\n",
       "      <td>0.919672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            10% of train  50% of train  100% of train\n",
       "train_time      0.498732      1.778876       3.319018\n",
       "pred_time       0.014198      0.012248       0.010358\n",
       "acc_train       0.830667      0.987667       0.970000\n",
       "acc_test        0.812958      0.906186       0.919672"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix Sensitivity and Recall when 100% of train is achieved\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WK</th>\n",
       "      <th>WU</th>\n",
       "      <th>WD</th>\n",
       "      <th>SI</th>\n",
       "      <th>ST</th>\n",
       "      <th>LD</th>\n",
       "      <th>St-Si</th>\n",
       "      <th>Si-St</th>\n",
       "      <th>Si-Li</th>\n",
       "      <th>Li-Si</th>\n",
       "      <th>St-Li</th>\n",
       "      <th>Li-St</th>\n",
       "      <th>data points number</th>\n",
       "      <th>precision %</th>\n",
       "      <th>sensitivity %</th>\n",
       "      <th>specificity %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WK</th>\n",
       "      <td>550</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>562</td>\n",
       "      <td>96.322242</td>\n",
       "      <td>97.864769</td>\n",
       "      <td>99.262899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WU</th>\n",
       "      <td>18</td>\n",
       "      <td>510</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>541</td>\n",
       "      <td>96.226415</td>\n",
       "      <td>94.269871</td>\n",
       "      <td>99.303136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WD</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>499</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>515</td>\n",
       "      <td>96.332046</td>\n",
       "      <td>96.893204</td>\n",
       "      <td>99.343923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SI</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>414</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>474</td>\n",
       "      <td>93.665158</td>\n",
       "      <td>87.341772</td>\n",
       "      <td>99.046646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>490</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>517</td>\n",
       "      <td>89.090909</td>\n",
       "      <td>94.777563</td>\n",
       "      <td>97.926745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LD</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>501</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>501</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>St-Si</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>73.809524</td>\n",
       "      <td>63.265306</td>\n",
       "      <td>99.672814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si-St</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>68.421053</td>\n",
       "      <td>78.787879</td>\n",
       "      <td>99.64476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si-Li</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>57.777778</td>\n",
       "      <td>47.272727</td>\n",
       "      <td>99.43385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Li-Si</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>47</td>\n",
       "      <td>50.877193</td>\n",
       "      <td>61.702128</td>\n",
       "      <td>99.167658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>St-Li</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>65</td>\n",
       "      <td>50.666667</td>\n",
       "      <td>58.461538</td>\n",
       "      <td>98.894202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Li-St</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>54.761905</td>\n",
       "      <td>44.230769</td>\n",
       "      <td>99.434355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>data points number=3411</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>accuracy= 91.967%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WK   WU   WD   SI   ST   LD St-Si Si-St Si-Li Li-Si St-Li Li-St  \\\n",
       "WK     550    5    7    0    0    0     0     0     0     0     0     0   \n",
       "WU      18  510   12    0    0    0     1     0     0     0     0     0   \n",
       "WD       2   14  499    0    0    0     0     0     0     0     0     0   \n",
       "SI       0    0    0  414   60    0     0     0     0     0     0     0   \n",
       "ST       0    0    0   27  490    0     0     0     0     0     0     0   \n",
       "LD       0    0    0    0    0  501     0     0     0     0     0     0   \n",
       "St-Si    0    0    0    0    0    0    31    11     1     2     3     1   \n",
       "Si-St    0    0    0    0    0    0     7    26     0     0     0     0   \n",
       "Si-Li    0    0    0    0    0    0     0     0    26     7    20     2   \n",
       "Li-Si    0    0    0    0    0    0     1     0     3    29     5     9   \n",
       "St-Li    0    0    0    1    0    0     1     0    11     7    38     7   \n",
       "Li-St    1    1    0    0    0    0     1     1     4    12     9    23   \n",
       "Total                                                                     \n",
       "\n",
       "            data points number precision % sensitivity %      specificity %  \n",
       "WK                         562   96.322242     97.864769          99.262899  \n",
       "WU                         541   96.226415     94.269871          99.303136  \n",
       "WD                         515   96.332046     96.893204          99.343923  \n",
       "SI                         474   93.665158     87.341772          99.046646  \n",
       "ST                         517   89.090909     94.777563          97.926745  \n",
       "LD                         501       100.0         100.0              100.0  \n",
       "St-Si                       49   73.809524     63.265306          99.672814  \n",
       "Si-St                       33   68.421053     78.787879           99.64476  \n",
       "Si-Li                       55   57.777778     47.272727           99.43385  \n",
       "Li-Si                       47   50.877193     61.702128          99.167658  \n",
       "St-Li                       65   50.666667     58.461538          98.894202  \n",
       "Li-St                       52   54.761905     44.230769          99.434355  \n",
       "Total  data points number=3411                            accuracy= 91.967%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________\n",
      "\n",
      "\n",
      "_____________________Dataset type III Training and Testing______________________\n",
      "\n",
      "LogisticRegression started training....\n",
      "...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "Success: LogisticRegression Finished Training and Testing.\n",
      "\n",
      "________LogisticRegression results:__________\n",
      "\n",
      "\n",
      "Accuracy and duration per training size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10% of train</th>\n",
       "      <th>50% of train</th>\n",
       "      <th>100% of train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_time</th>\n",
       "      <td>0.379178</td>\n",
       "      <td>1.008676</td>\n",
       "      <td>1.904513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_time</th>\n",
       "      <td>0.010975</td>\n",
       "      <td>0.011460</td>\n",
       "      <td>0.011921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>0.874000</td>\n",
       "      <td>0.991000</td>\n",
       "      <td>0.983000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.875110</td>\n",
       "      <td>0.944884</td>\n",
       "      <td>0.961595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            10% of train  50% of train  100% of train\n",
       "train_time      0.379178      1.008676       1.904513\n",
       "pred_time       0.010975      0.011460       0.011921\n",
       "acc_train       0.874000      0.991000       0.983000\n",
       "acc_test        0.875110      0.944884       0.961595"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix Sensitivity and Recall when 100% of train is achieved\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WK</th>\n",
       "      <th>WU</th>\n",
       "      <th>WD</th>\n",
       "      <th>SI</th>\n",
       "      <th>ST</th>\n",
       "      <th>LD</th>\n",
       "      <th>PT</th>\n",
       "      <th>data points number</th>\n",
       "      <th>precision %</th>\n",
       "      <th>sensitivity %</th>\n",
       "      <th>specificity %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WK</th>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>562</td>\n",
       "      <td>96.385542</td>\n",
       "      <td>99.644128</td>\n",
       "      <td>99.262899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WU</th>\n",
       "      <td>16</td>\n",
       "      <td>518</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>541</td>\n",
       "      <td>97.920605</td>\n",
       "      <td>95.748614</td>\n",
       "      <td>99.616725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WD</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>515</td>\n",
       "      <td>98.818898</td>\n",
       "      <td>97.475728</td>\n",
       "      <td>99.792818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SI</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>415</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>474</td>\n",
       "      <td>93.049327</td>\n",
       "      <td>87.552743</td>\n",
       "      <td>98.944501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>487</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>517</td>\n",
       "      <td>89.194139</td>\n",
       "      <td>94.197292</td>\n",
       "      <td>97.961299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LD</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>501</td>\n",
       "      <td>0</td>\n",
       "      <td>501</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>297</td>\n",
       "      <td>301</td>\n",
       "      <td>99.0</td>\n",
       "      <td>98.671096</td>\n",
       "      <td>99.903537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>data points number=3411</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>accuracy= 96.159%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WK   WU   WD   SI   ST   LD   PT       data points number precision %  \\\n",
       "WK     560    1    1    0    0    0    0                      562   96.385542   \n",
       "WU      16  518    5    0    0    0    2                      541   97.920605   \n",
       "WD       4    9  502    0    0    0    0                      515   98.818898   \n",
       "SI       0    0    0  415   58    0    1                      474   93.049327   \n",
       "ST       0    0    0   30  487    0    0                      517   89.194139   \n",
       "LD       0    0    0    0    0  501    0                      501       100.0   \n",
       "PT       1    1    0    1    1    0  297                      301        99.0   \n",
       "Total                                     data points number=3411               \n",
       "\n",
       "      sensitivity %      specificity %  \n",
       "WK        99.644128          99.262899  \n",
       "WU        95.748614          99.616725  \n",
       "WD        97.475728          99.792818  \n",
       "SI        87.552743          98.944501  \n",
       "ST        94.197292          97.961299  \n",
       "LD            100.0              100.0  \n",
       "PT        98.671096          99.903537  \n",
       "Total                accuracy= 96.159%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training, testing and evaluating Logistic Regression  classifier on all datasets\n",
    "train_test_report(Clf2,'All')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IX. Tunning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV # import grid search cv to tune parameters\n",
    "clf_chosen=LR(random_state=337) # intialize the LR model\n",
    "\n",
    "# scaled dataset type I activity weights\n",
    "weights_dic_1= {1:0.179248,2:0.15867,3:0.144265,4:0.161919,5:0.17849,6:0.177407}\n",
    "\n",
    "# scaled dataset type II activity weights\n",
    "weights_dic_2={1 : 0.164576, 2 : 0.150152, 3 : 0.142537, 4 : 0.145225,\n",
    "               5 : 0.156961, 6 : 0.155169, 7 : 0.012991, 8 : 0.009138,\n",
    "               9 : 0.015857, 10: 0.015320, 11: 0.018903,12 : 0.013170}\n",
    "# scaled dataset type III activity weights\n",
    "weights_dic_3={1:0.164576,2:0.150152,3:0.142537,4:0.145225,5:0.156961,6:0.155169,7:0.085379}\n",
    "\n",
    "# possible values for the parameter \"class_weight\" for each dataset\n",
    "\n",
    "class_weight_1=[None,weights_dic_1] # scaled dataset I\n",
    "class_weight_2=[None,weights_dic_2] # scaled dataset II\n",
    "class_weight_3=[None,weights_dic_3] # scaled dataset III\n",
    "\n",
    "# possible parameters dictionary for each dataset:\n",
    "\n",
    "# dataset type I\n",
    "params_1={'penalty':['l2'], 'solver':['newton-cg','sag','lbfgs'],'dual':[False],\n",
    "          'multi_class':['ovr','multinomial'],'class_weight':class_weight_1}\n",
    "params_2={'penalty':['l2'], 'solver':['liblinear'],'dual':[True],'multi_class':['ovr'],'class_weight':class_weight_1}\n",
    "params_3={'penalty':['l1'], 'solver':['liblinear'],'dual':[False],'multi_class':['ovr'],'class_weight':class_weight_1}\n",
    "\n",
    "# dataset type II\n",
    "params_4={'penalty':['l2'], 'solver':['newton-cg','sag','lbfgs'],'dual':[False],\n",
    "          'multi_class':['ovr','multinomial'],'class_weight':class_weight_2}\n",
    "params_5={'penalty':['l2'], 'solver':['liblinear'],'dual':[True],'multi_class':['ovr'],'class_weight':class_weight_2}\n",
    "params_6={'penalty':['l1'], 'solver':['liblinear'],'dual':[False],'multi_class':['ovr'],'class_weight':class_weight_2}\n",
    "\n",
    "# dataset type III\n",
    "params_7={'penalty':['l2'], 'solver':['newton-cg','sag','lbfgs'],'dual':[False],\n",
    "          'multi_class':['ovr','multinomial'],'class_weight':class_weight_3}\n",
    "params_8={'penalty':['l2'], 'solver':['liblinear'],'dual':[True],'multi_class':['ovr'],'class_weight':class_weight_3}\n",
    "params_9={'penalty':['l1'], 'solver':['liblinear'],'dual':[False],'multi_class':['ovr'],'class_weight':class_weight_3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4080\\3979270130.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# train models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mtuned_model1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_1_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_1_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mtuned_model2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_1_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_1_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mtuned_model3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_1_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_1_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    836\u001b[0m                     )\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1587\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1588\u001b[0m             \u001b[0mprefer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"processes\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1589\u001b[1;33m         fold_coefs_ = Parallel(\n\u001b[0m\u001b[0;32m   1590\u001b[0m             \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1591\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[0;32m    804\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m             ]\n\u001b[1;32m--> 806\u001b[1;33m             opt_res = optimize.minimize(\n\u001b[0m\u001b[0;32m    807\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    808\u001b[0m                 \u001b[0mw0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    697\u001b[0m                                  **options)\n\u001b[0;32m    698\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l-bfgs-b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m         res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[0;32m    700\u001b[0m                                callback=callback, **options)\n\u001b[0;32m    701\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    360\u001b[0m             \u001b[1;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m             \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 251\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[1;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[1;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             \u001b[0mfx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m             \u001b[1;31m# Make sure the function returns a true scalar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\_optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[0mfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36m_logistic_loss_and_grad\u001b[1;34m(w, X, y, alpha, sample_weight)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m     \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_intercept_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36m_intercept_dot\u001b[1;34m(w, X, y)\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m     \u001b[0myz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     if (\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Dataset type I:\n",
    "# insert parameters in the grid seach for each path \n",
    "# store each future results in a model\n",
    "tuned_model1 =GridSearchCV(estimator =clf_chosen,\n",
    "                          param_grid=params_1)\n",
    "tuned_model2 =GridSearchCV(estimator =clf_chosen,\n",
    "                          param_grid=params_2)\n",
    "tuned_model3 =GridSearchCV(estimator =clf_chosen,\n",
    "                          param_grid=params_3)\n",
    "\n",
    "# train models\n",
    "tuned_model1.fit(X_1_train,y_1_train)\n",
    "tuned_model2.fit(X_1_train,y_1_train)\n",
    "tuned_model3.fit(X_1_train,y_1_train)\n",
    "\n",
    "# display best parameters of each model\n",
    "print(\"Tuned model 1 best params:\",tuned_model1.best_params_)\n",
    "print(\"Tuned model 2 best params:\",tuned_model2.best_params_)\n",
    "print(\"Tuned model 3 best params:\",tuned_model3.best_params_)\n",
    "\n",
    "# store predictions and generate accuracies for each model\n",
    "predictions1=tuned_model1.predict(X_1_test)\n",
    "print( \"tuned model 1 accuracy:\",accuracy(y_1_test,predictions1))\n",
    "\n",
    "predictions2=tuned_model2.predict(X_1_test)\n",
    "print( \"tuned model 2 accuracy:\",accuracy(y_1_test,predictions2))\n",
    "\n",
    "predictions3 = tuned_model3.predict(X_1_test)\n",
    "print( \"tuned model 3 accuracy:\",accuracy(y_1_test,predictions3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned model 4 best params: {'class_weight': None, 'dual': False, 'multi_class': 'multinomial', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Tuned model 5 best params: {'class_weight': None, 'dual': True, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Tuned model 6 best params: {'class_weight': None, 'dual': False, 'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "tuned model 4 accuracy: 0.9240691879214307\n",
      "tuned model 5 accuracy: 0.9261213720316622\n",
      "tuned model 6 accuracy: 0.9220170038111991\n"
     ]
    }
   ],
   "source": [
    "# Dataset type II: same process will be applied for dataset type II\n",
    "tuned_model4 =GridSearchCV(estimator =clf_chosen,\n",
    "                          param_grid=params_4)\n",
    "tuned_model5 =GridSearchCV(estimator =clf_chosen,\n",
    "                          param_grid=params_5)\n",
    "tuned_model6 =GridSearchCV(estimator =clf_chosen,\n",
    "                          param_grid=params_6)\n",
    "\n",
    "tuned_model4.fit(X_2_train,y_2_train)\n",
    "tuned_model5.fit(X_2_train,y_2_train)\n",
    "tuned_model6.fit(X_2_train,y_2_train)\n",
    "\n",
    "print(\"Tuned model 4 best params:\",tuned_model4.best_params_)\n",
    "print(\"Tuned model 5 best params:\",tuned_model5.best_params_)\n",
    "print(\"Tuned model 6 best params:\",tuned_model6.best_params_)\n",
    "\n",
    "predictions4=tuned_model4.predict(X_2_test)\n",
    "print( \"tuned model 4 accuracy:\",accuracy(y_2_test,predictions4))\n",
    "\n",
    "predictions5=tuned_model5.predict(X_2_test)\n",
    "print( \"tuned model 5 accuracy:\",accuracy(y_2_test,predictions5))\n",
    "\n",
    "predictions6=tuned_model6.predict(X_2_test)\n",
    "print( \"tuned model 6 accuracy:\",accuracy(y_2_test,predictions6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned model 7 best params: {'class_weight': None, 'dual': False, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Tuned model 8 best params: {'class_weight': None, 'dual': True, 'multi_class': 'ovr', 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Tuned model 9 best params: {'class_weight': None, 'dual': False, 'multi_class': 'ovr', 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "tuned model 7 accuracy: 0.960715332746995\n",
      "tuned model 8 accuracy: 0.9610085019055995\n",
      "tuned model 9 accuracy: 0.9583699794781589\n"
     ]
    }
   ],
   "source": [
    "# Dataset type III: same process will be applied for dataset type III\n",
    "tuned_model7 =GridSearchCV(estimator =clf_chosen,\n",
    "                          param_grid=params_7)\n",
    "tuned_model8 =GridSearchCV(estimator =clf_chosen,\n",
    "                       param_grid=params_8)\n",
    "tuned_model9 =GridSearchCV(estimator =clf_chosen,\n",
    "                          param_grid=params_9)\n",
    "\n",
    "tuned_model7.fit(X_3_train,y_3_train)\n",
    "tuned_model8.fit(X_3_train,y_3_train)\n",
    "tuned_model9.fit(X_3_train,y_3_train)\n",
    "\n",
    "print(\"Tuned model 7 best params:\",tuned_model7.best_params_)\n",
    "print(\"Tuned model 8 best params:\",tuned_model8.best_params_)\n",
    "print(\"Tuned model 9 best params:\",tuned_model9.best_params_)\n",
    "\n",
    "predictions7=tuned_model7.predict(X_3_test)\n",
    "print( \"tuned model 7 accuracy:\",accuracy(y_3_test,predictions7))\n",
    "\n",
    "predictions8=tuned_model8.predict(X_3_test)\n",
    "print( \"tuned model 8 accuracy:\",accuracy(y_3_test,predictions8))\n",
    "\n",
    "predictions9=tuned_model9.predict(X_3_test)\n",
    "print( \"tuned model 9 accuracy:\",accuracy(y_3_test,predictions9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter C Search:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Warning:** Running duration of this part is a least **5 hours**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C hyper-parameter search\n",
    "\n",
    "# C values from 0.1 to 20 with a step of 0.1\n",
    "C_values=[(i+1)*0.1 for i in range(200)]       \n",
    "\n",
    "def max_c(results,typ):\n",
    "    # inputs:\n",
    "    #   results: dictionary={c_value: accuracy of the model}\n",
    "    #   typ: float possible values are: 1,2,3 and 3.5\n",
    "    \n",
    "    # extract C values\n",
    "    C_values=sorted(results.keys())\n",
    "    # extract related accuracies \n",
    "    accuracy_values=[results[key] for key in C_values]\n",
    "    \n",
    "    # extract c value having the maximum accuracy\n",
    "    max_c=C_values[np.array(accuracy_values).argmax()]\n",
    "    \n",
    "    # display results\n",
    "    print(\"max accuracy :\",max(accuracy_values))\n",
    "    print(\"C value:\",max_c)\n",
    "    \n",
    "    plt.plot(C_values,accuracy_values)# plot the curve\n",
    "    plt.xlabel(\"C values\")  # set X axis info\n",
    "    plt.ylabel(\"accuracy\") # set Y axis info\n",
    "    \n",
    "    # Set the right title switch the case\n",
    "    if typ==1:# if dataset type I\n",
    "        plt.title(\"model 1 accuracy variation on dataset type I\")\n",
    "    if typ==2:# if dataset type II\n",
    "        plt.title(\"model 5 accuracy variation on dataset type II\")\n",
    "    \n",
    "    if typ==3:# if the first model of dataset type III\n",
    "        plt.title(\"model 7 accuracy variation on dataset type III\")\n",
    "    \n",
    "    if typ==3.5:# if the second model of dataset type III\n",
    "        plt.title(\"model 8 accuracy variation on dataset type III\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ** To run the search function below for dataset type 1 decomment the last line** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset type I\n",
    "def lookup_best_c(x_train,y_train,x_test,y_test):\n",
    "    accuracy_results={} # empty dictionary will contain c values and accuracies related\n",
    "    \n",
    "    for value in C_values:# iterate throw each C value\n",
    "        #tuned model 1 best parameters + C variable\n",
    "        tmp_model=LR(solver='lbfgs',class_weight= None,multi_class= 'ovr', \n",
    "                  dual=False, penalty= 'l2',random_state=337,C=value)\n",
    "        # train the model\n",
    "        tmp_model.fit(x_train,y_train)\n",
    "        \n",
    "        # predicting activity labels\n",
    "        tmp_predictions=tmp_model.predict(x_test)\n",
    "        # accuracy score\n",
    "        tmp_accuracy=accuracy(tmp_predictions,y_test)\n",
    "        # store the tuple c_value and accuracy value in the dictionary\n",
    "        accuracy_results[value]=tmp_accuracy\n",
    "    \n",
    "    # after iterating throw all c values\n",
    "    return accuracy_results # return results\n",
    "\n",
    "# apply lookup_best_c to train and test files type I\n",
    "#results_I = lookup_best_c(X_1_train,y_1_train,X_1_test,y_1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ** To visualize results_I,  Decomment the last line of the cell below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing results\n",
    "#max_c(results_I,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ** To run the search function below for dataset type 2 models decomment the last line** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same process will be applied for dataset type II model\n",
    "def lookup_best_c(x_train,y_train,x_test,y_test):\n",
    "    i=0\n",
    "    accuracy_results={}\n",
    "    for value in C_values:\n",
    "        \n",
    "        #tuned model 5 best parameters + C variable\n",
    "        tmp_model=LR(solver='liblinear', class_weight= None, multi_class= 'ovr',\n",
    "                  dual= True, penalty= 'l2',random_state=337,C=value)\n",
    "        tmp_model.fit(x_train,y_train)\n",
    "        tmp_predictions=tmp_model.predict(x_test)\n",
    "        tmp_accuracy=accuracy(tmp_predictions,y_test)\n",
    "        accuracy_results[value]=tmp_accuracy\n",
    "    return accuracy_results\n",
    "\n",
    "# apply lookup_best_c to train and test files type II\n",
    "#results_II =lookup_best_c(X_2_train,y_2_train,X_2_test,y_2_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ** To visualize results_II,  Decomment the last line of the cell below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing results\n",
    "#max_c(results_II,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ** To run the search function below for dataset type 3 models decomment the last line** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same process for Dataset type III first model(tuned model 7)\n",
    "def lookup_best_c(x_train,y_train,x_test,y_test):\n",
    "    accuracy_results={}\n",
    "    for value in C_values:\n",
    "        #tuned model 7 best parameters + C variable\n",
    "        tmp_model=LR(solver= 'newton-cg', class_weight= None, multi_class= 'ovr', \n",
    "                  dual= False, penalty= 'l2',random_state=337,C=value)\n",
    "        tmp_model.fit(x_train,y_train)\n",
    "        tmp_predictions=tmp_model.predict(x_test)\n",
    "        tmp_accuracy=accuracy(tmp_predictions,y_test)\n",
    "        accuracy_results[value]=tmp_accuracy\n",
    "    return accuracy_results\n",
    "# apply lookup_best_c to train and test files type III using model 7 best parameters\n",
    "#results_III=lookup_best_c(X_3_train,y_3_train,X_3_test,y_3_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ** To visualize results_III,  Decomment the last line of the cell below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualizing results\n",
    "#max_c(results_III,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ** To run the search function below for dataset type 3 models decomment the last line** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_best_c(x_train,y_train,x_test,y_test):\n",
    "    accuracy_results={}\n",
    "    for value in C_values:\n",
    "        #tuned model 8 best parameters + C variable\n",
    "        tmp_model=LR(solver= 'liblinear', class_weight= None, multi_class= 'ovr', \n",
    "                  dual= True, penalty= 'l2',random_state=337,C=value)\n",
    "        tmp_model.fit(x_train,y_train)\n",
    "        tmp_predictions=tmp_model.predict(x_test)\n",
    "        tmp_accuracy=accuracy(tmp_predictions,y_test)\n",
    "        accuracy_results[value]=tmp_accuracy\n",
    "    return accuracy_results\n",
    "# apply lookup_best_c to train and test files type III using model 8 best parameters\n",
    "#results_III_5=lookup_best_c(X_3_train,y_3_train,X_3_test,y_3_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ** To visualize results_III_5,  Decomment the last line of the cell below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualizing results\n",
    "#max_c(results_III_5,3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ** To run the search function below for dataset type 3 models decomment the last line** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy is still increasing for model 8 best params\n",
    "# changing C values ranges from [0.1,20] to [20.1, 40]\n",
    "# C values from 20.1 to 40 with a step of 0.1\n",
    "C_values=[20+(i+1)*0.1 for i in range(200)]\n",
    "def lookup_best_c(x_train,y_train,x_test,y_test):\n",
    "    accuracy_results={}\n",
    "    for value in C_values:\n",
    "        # tuned model 8 best parameters\n",
    "        tmp_model=LR(solver= 'liblinear', class_weight= None, multi_class= 'ovr', \n",
    "                  dual= True, penalty= 'l2',random_state=337,C=value)\n",
    "        tmp_model.fit(x_train,y_train)\n",
    "        tmp_predictions=tmp_model.predict(x_test)\n",
    "        tmp_accuracy=accuracy(tmp_predictions,y_test)\n",
    "        accuracy_results[value]=tmp_accuracy\n",
    "    return accuracy_results\n",
    "# apply lookup_best_c to train and test files type III using tuned model 8 best parameters\n",
    "#results_III_6=lookup_best_c(X_3_train,y_3_train,X_3_test,y_3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ** To visualize results_III_6,  Decomment the last line of the cell below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing results\n",
    "#max_c(results_III_6,3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Duration=  4805.9996397\n"
     ]
    }
   ],
   "source": [
    "fin=timer()\n",
    "print('Running Duration= ',fin-Debut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best C values was selected from each search \n",
    "final_model_I=LR(solver='lbfgs',class_weight= None,multi_class= 'ovr', \n",
    "                  dual=False, penalty= 'l2',random_state=337,C=4.7)\n",
    "final_model_II=LR(solver='liblinear', class_weight= None, multi_class= 'ovr',\n",
    "                  dual= True, penalty= 'l2',random_state=337,C=0.8)\n",
    "\n",
    "# for dataset type III model 7 best parameters + best C value have the highest accuracy compared to model 8 best C value \n",
    "final_model_III=LR(solver= 'newton-cg', class_weight= None, multi_class= 'ovr', \n",
    "                  dual= False, penalty= 'l2',random_state=337,C=8.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________Dataset type I Training and Testing______________________\n",
      "\n",
      "LogisticRegression started training....\n",
      "...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: LogisticRegression Finished Training and Testing.\n",
      "\n",
      "________LogisticRegression results:__________\n",
      "\n",
      "\n",
      "Accuracy and duration per training size\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10% of train</th>\n",
       "      <th>50% of train</th>\n",
       "      <th>100% of train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_time</th>\n",
       "      <td>0.563313</td>\n",
       "      <td>1.456493</td>\n",
       "      <td>2.070272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_time</th>\n",
       "      <td>0.025172</td>\n",
       "      <td>0.007507</td>\n",
       "      <td>0.012266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>0.882000</td>\n",
       "      <td>0.997333</td>\n",
       "      <td>0.989000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.865888</td>\n",
       "      <td>0.944091</td>\n",
       "      <td>0.968861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            10% of train  50% of train  100% of train\n",
       "train_time      0.563313      1.456493       2.070272\n",
       "pred_time       0.025172      0.007507       0.012266\n",
       "acc_train       0.882000      0.997333       0.989000\n",
       "acc_test        0.865888      0.944091       0.968861"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix Sensitivity and Recall when 100% of train is achieved\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WK</th>\n",
       "      <th>WU</th>\n",
       "      <th>WD</th>\n",
       "      <th>SI</th>\n",
       "      <th>ST</th>\n",
       "      <th>LD</th>\n",
       "      <th>data points number</th>\n",
       "      <th>precision %</th>\n",
       "      <th>sensitivity %</th>\n",
       "      <th>specificity %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WK</th>\n",
       "      <td>503</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>505</td>\n",
       "      <td>98.242188</td>\n",
       "      <td>99.60396</td>\n",
       "      <td>99.612236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WU</th>\n",
       "      <td>7</td>\n",
       "      <td>470</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>477</td>\n",
       "      <td>99.156118</td>\n",
       "      <td>98.532495</td>\n",
       "      <td>99.829715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WD</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>423</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>428</td>\n",
       "      <td>99.764151</td>\n",
       "      <td>98.831776</td>\n",
       "      <td>99.958299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SI</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>389</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>442</td>\n",
       "      <td>94.878049</td>\n",
       "      <td>88.00905</td>\n",
       "      <td>99.119128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>472</td>\n",
       "      <td>0</td>\n",
       "      <td>493</td>\n",
       "      <td>89.904762</td>\n",
       "      <td>95.740365</td>\n",
       "      <td>97.728247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LD</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>481</td>\n",
       "      <td>481</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>data points number=2826</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>accuracy= 96.886%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WK   WU   WD   SI   ST   LD       data points number precision %  \\\n",
       "WK     503    1    1    0    0    0                      505   98.242188   \n",
       "WU       7  470    0    0    0    0                      477   99.156118   \n",
       "WD       2    3  423    0    0    0                      428   99.764151   \n",
       "SI       0    0    0  389   53    0                      442   94.878049   \n",
       "ST       0    0    0   21  472    0                      493   89.904762   \n",
       "LD       0    0    0    0    0  481                      481       100.0   \n",
       "Total                                data points number=2826               \n",
       "\n",
       "      sensitivity %      specificity %  \n",
       "WK         99.60396          99.612236  \n",
       "WU        98.532495          99.829715  \n",
       "WD        98.831776          99.958299  \n",
       "SI         88.00905          99.119128  \n",
       "ST        95.740365          97.728247  \n",
       "LD            100.0              100.0  \n",
       "Total                accuracy= 96.886%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train, test and evaluate final model I on dataset type I\n",
    "train_test_report(final_model_I,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________Dataset type II Training and Testing______________________\n",
      "\n",
      "LogisticRegression started training....\n",
      "...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "Success: LogisticRegression Finished Training and Testing.\n",
      "\n",
      "________LogisticRegression results:__________\n",
      "\n",
      "\n",
      "Accuracy and duration per training size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10% of train</th>\n",
       "      <th>50% of train</th>\n",
       "      <th>100% of train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_time</th>\n",
       "      <td>1.010520</td>\n",
       "      <td>6.378334</td>\n",
       "      <td>16.320047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_time</th>\n",
       "      <td>0.011215</td>\n",
       "      <td>0.012419</td>\n",
       "      <td>0.013554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>0.825333</td>\n",
       "      <td>0.986333</td>\n",
       "      <td>0.973667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.796247</td>\n",
       "      <td>0.907065</td>\n",
       "      <td>0.926121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            10% of train  50% of train  100% of train\n",
       "train_time      1.010520      6.378334      16.320047\n",
       "pred_time       0.011215      0.012419       0.013554\n",
       "acc_train       0.825333      0.986333       0.973667\n",
       "acc_test        0.796247      0.907065       0.926121"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix Sensitivity and Recall when 100% of train is achieved\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WK</th>\n",
       "      <th>WU</th>\n",
       "      <th>WD</th>\n",
       "      <th>SI</th>\n",
       "      <th>ST</th>\n",
       "      <th>LD</th>\n",
       "      <th>St-Si</th>\n",
       "      <th>Si-St</th>\n",
       "      <th>Si-Li</th>\n",
       "      <th>Li-Si</th>\n",
       "      <th>St-Li</th>\n",
       "      <th>Li-St</th>\n",
       "      <th>data points number</th>\n",
       "      <th>precision %</th>\n",
       "      <th>sensitivity %</th>\n",
       "      <th>specificity %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WK</th>\n",
       "      <td>560</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>562</td>\n",
       "      <td>95.400341</td>\n",
       "      <td>99.644128</td>\n",
       "      <td>99.052299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WU</th>\n",
       "      <td>16</td>\n",
       "      <td>520</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>541</td>\n",
       "      <td>97.014925</td>\n",
       "      <td>96.118299</td>\n",
       "      <td>99.442509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WD</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>503</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>515</td>\n",
       "      <td>99.015748</td>\n",
       "      <td>97.669903</td>\n",
       "      <td>99.827348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SI</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>420</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>474</td>\n",
       "      <td>92.307692</td>\n",
       "      <td>88.607595</td>\n",
       "      <td>98.808308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>485</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>517</td>\n",
       "      <td>89.648799</td>\n",
       "      <td>93.810445</td>\n",
       "      <td>98.064962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LD</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>501</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>501</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>St-Si</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>75.0</td>\n",
       "      <td>61.22449</td>\n",
       "      <td>99.702558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si-St</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>62.857143</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>99.615157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Si-Li</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>59.649123</td>\n",
       "      <td>61.818182</td>\n",
       "      <td>99.31466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Li-Si</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>47</td>\n",
       "      <td>57.692308</td>\n",
       "      <td>63.829787</td>\n",
       "      <td>99.346017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>St-Li</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "      <td>65</td>\n",
       "      <td>53.448276</td>\n",
       "      <td>47.692308</td>\n",
       "      <td>99.193066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Li-St</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>56.097561</td>\n",
       "      <td>44.230769</td>\n",
       "      <td>99.464126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>data points number=3411</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>accuracy= 92.612%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WK   WU   WD   SI   ST   LD St-Si Si-St Si-Li Li-Si St-Li Li-St  \\\n",
       "WK     560    1    1    0    0    0     0     0     0     0     0     0   \n",
       "WU      16  520    4    0    0    0     0     1     0     0     0     0   \n",
       "WD       4    8  503    0    0    0     0     0     0     0     0     0   \n",
       "SI       0    0    0  420   54    0     0     0     0     0     0     0   \n",
       "ST       0    0    0   32  485    0     0     0     0     0     0     0   \n",
       "LD       0    0    0    0    0  501     0     0     0     0     0     0   \n",
       "St-Si    0    3    0    1    0    0    30    12     0     1     1     1   \n",
       "Si-St    0    0    0    1    1    0     9    22     0     0     0     0   \n",
       "Si-Li    0    2    0    0    0    0     0     0    34     5    12     2   \n",
       "Li-Si    0    0    0    0    0    0     1     0     4    30     4     8   \n",
       "St-Li    3    1    0    1    1    0     0     0    14     7    31     7   \n",
       "Li-St    4    1    0    0    0    0     0     0     5     9    10    23   \n",
       "Total                                                                     \n",
       "\n",
       "            data points number precision % sensitivity %      specificity %  \n",
       "WK                         562   95.400341     99.644128          99.052299  \n",
       "WU                         541   97.014925     96.118299          99.442509  \n",
       "WD                         515   99.015748     97.669903          99.827348  \n",
       "SI                         474   92.307692     88.607595          98.808308  \n",
       "ST                         517   89.648799     93.810445          98.064962  \n",
       "LD                         501       100.0         100.0              100.0  \n",
       "St-Si                       49        75.0      61.22449          99.702558  \n",
       "Si-St                       33   62.857143     66.666667          99.615157  \n",
       "Si-Li                       55   59.649123     61.818182           99.31466  \n",
       "Li-Si                       47   57.692308     63.829787          99.346017  \n",
       "St-Li                       65   53.448276     47.692308          99.193066  \n",
       "Li-St                       52   56.097561     44.230769          99.464126  \n",
       "Total  data points number=3411                            accuracy= 92.612%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train, test and evaluate final model II on dataset type II\n",
    "train_test_report(final_model_II,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________Dataset type III Training and Testing______________________\n",
      "\n",
      "LogisticRegression started training....\n",
      "...\n",
      "...\n",
      "...\n",
      "Success: LogisticRegression Finished Training and Testing.\n",
      "\n",
      "________LogisticRegression results:__________\n",
      "\n",
      "\n",
      "Accuracy and duration per training size\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10% of train</th>\n",
       "      <th>50% of train</th>\n",
       "      <th>100% of train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_time</th>\n",
       "      <td>1.460441</td>\n",
       "      <td>11.595399</td>\n",
       "      <td>24.776813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_time</th>\n",
       "      <td>0.011743</td>\n",
       "      <td>0.008550</td>\n",
       "      <td>0.011184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>0.855667</td>\n",
       "      <td>0.997667</td>\n",
       "      <td>0.988667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.856347</td>\n",
       "      <td>0.949868</td>\n",
       "      <td>0.966579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            10% of train  50% of train  100% of train\n",
       "train_time      1.460441     11.595399      24.776813\n",
       "pred_time       0.011743      0.008550       0.011184\n",
       "acc_train       0.855667      0.997667       0.988667\n",
       "acc_test        0.856347      0.949868       0.966579"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix Sensitivity and Recall when 100% of train is achieved\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WK</th>\n",
       "      <th>WU</th>\n",
       "      <th>WD</th>\n",
       "      <th>SI</th>\n",
       "      <th>ST</th>\n",
       "      <th>LD</th>\n",
       "      <th>PT</th>\n",
       "      <th>data points number</th>\n",
       "      <th>precision %</th>\n",
       "      <th>sensitivity %</th>\n",
       "      <th>specificity %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WK</th>\n",
       "      <td>562</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>562</td>\n",
       "      <td>96.068376</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.192699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WU</th>\n",
       "      <td>14</td>\n",
       "      <td>522</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>541</td>\n",
       "      <td>98.490566</td>\n",
       "      <td>96.487985</td>\n",
       "      <td>99.721254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WD</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>505</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>515</td>\n",
       "      <td>99.214145</td>\n",
       "      <td>98.058252</td>\n",
       "      <td>99.861878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SI</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>422</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>474</td>\n",
       "      <td>94.407159</td>\n",
       "      <td>89.029536</td>\n",
       "      <td>99.148791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>493</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>517</td>\n",
       "      <td>90.458716</td>\n",
       "      <td>95.357834</td>\n",
       "      <td>98.203179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LD</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>501</td>\n",
       "      <td>0</td>\n",
       "      <td>501</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>292</td>\n",
       "      <td>301</td>\n",
       "      <td>99.319728</td>\n",
       "      <td>97.009967</td>\n",
       "      <td>99.935691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>data points number=3411</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>accuracy= 96.657%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WK   WU   WD   SI   ST   LD   PT       data points number precision %  \\\n",
       "WK     562    0    0    0    0    0    0                      562   96.068376   \n",
       "WU      14  522    4    0    0    0    1                      541   98.490566   \n",
       "WD       4    6  505    0    0    0    0                      515   99.214145   \n",
       "SI       0    0    0  422   52    0    0                      474   94.407159   \n",
       "ST       0    0    0   23  493    0    1                      517   90.458716   \n",
       "LD       0    0    0    0    0  501    0                      501       100.0   \n",
       "PT       5    2    0    2    0    0  292                      301   99.319728   \n",
       "Total                                     data points number=3411               \n",
       "\n",
       "      sensitivity %      specificity %  \n",
       "WK            100.0          99.192699  \n",
       "WU        96.487985          99.721254  \n",
       "WD        98.058252          99.861878  \n",
       "SI        89.029536          99.148791  \n",
       "ST        95.357834          98.203179  \n",
       "LD            100.0              100.0  \n",
       "PT        97.009967          99.935691  \n",
       "Total                accuracy= 96.657%  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train, test and evaluate final model III on dataset type III\n",
    "train_test_report(final_model_III,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Some Samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test samples indexes for each dataset\n",
    "indexes_I=[0,500,300,800,900,1000]\n",
    "indexes_II=[91,134,124,14,0,46,189,27,72,56,40,89]\n",
    "indexes_III=[92,135,125,15,1,47,190]\n",
    "\n",
    "# activity labels for Datasets type I and II\n",
    "AL={\n",
    "        1: 'WALKING', 2: 'WALKING_UPSTAIRS', 3: 'WALKING_DOWNSTAIRS', # 3 dynamic activities\n",
    "        4: 'SITTING', 5: 'STANDING', 6: 'LIYING', # 3 static activities\n",
    "        \n",
    "        7: 'STAND_TO_SIT',  8: 'SIT_TO_STAND',  9: 'SIT_TO_LIE', 10: 'LIE_TO_SIT', \n",
    "    11: 'STAND_TO_LIE', 12: 'LIE_TO_STAND',# 6 postural Transitions\n",
    "       } \n",
    "# activity labels for dataset type III\n",
    "AL3={1: 'WALKING', 2: 'WALKING_UPSTAIRS', 3: 'WALKING_DOWNSTAIRS', # 3 dynamic activities\n",
    "        4: 'SITTING', 5: 'STANDING', 6: 'LIYING', # 3 static activities\n",
    "        \n",
    "        7: 'Postural Transition',}\n",
    "\n",
    "def Samples_Results(x_test,y_test,model,samples_index,dataset_type):\n",
    "    # Inputs:\n",
    "    #  X_test: 2D numpy array (test features)\n",
    "    #  y_test: 1D numpy array (test labels)\n",
    "    #  sample index: integer from 0 to lenght of X_test-1    \n",
    "    # Dataset type: integer possible values are 1,2 or 3\n",
    "    \n",
    "    # Intialize a pandas dataframe will contain predictions' results\n",
    "    Df=pd.DataFrame(data=[],columns=['Row index','real identifier','predicted identifier'])\n",
    "    \n",
    "    for indice in samples_index:# iterate throw indicies\n",
    "        \n",
    "        real_value=int(y_test[indice]) # activity label of the sample\n",
    "        features_row=x_test[indice,:] # features vector of the sample\n",
    "        #print(x_test.shape)\n",
    "        #print(y_test.shape)\n",
    "        #print(features_row.shape)\n",
    "        #print(samples_index)\n",
    "        #print(indice)\n",
    "        \n",
    "        prediction=int(model.predict(features_row.reshape(1,-1))) # predicted activity label\n",
    "        # Adapting the activity name switch the dataset type\n",
    "        if dataset_type==1:\n",
    "            activity_name=AL[real_value]\n",
    "        if dataset_type==2:\n",
    "            activity_name=AL[real_value]\n",
    "        if dataset_type==3:\n",
    "            activity_name=AL3[real_value]\n",
    "        \n",
    "        # append the row index the activity id and the predicted activity id\n",
    "        Df.loc[activity_name]=[indice,real_value,prediction]\n",
    "    return Df # return the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_I=LR(solver='lbfgs',class_weight= None,multi_class= 'ovr', \n",
    "                  dual=False, penalty= 'l2',random_state=337,C=4.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy\n",
    "#final_model_I=numpy.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row index</th>\n",
       "      <th>real identifier</th>\n",
       "      <th>predicted identifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>300</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "      <td>800</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <td>900</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIYING</th>\n",
       "      <td>1000</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Row index  real identifier  predicted identifier\n",
       "STANDING                    0                5                     5\n",
       "WALKING                   500                1                     1\n",
       "SITTING                   300                4                     4\n",
       "WALKING_UPSTAIRS          800                2                     2\n",
       "WALKING_DOWNSTAIRS        900                3                     3\n",
       "LIYING                   1000                6                     6"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the final model I on dataset type I\n",
    "final_model_I.fit(X_1_train,y_1_train)\n",
    "# display results\n",
    "Samples_Results(X_1_test,y_1_test,final_model_I,indexes_I,1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssand\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row index</th>\n",
       "      <th>real identifier</th>\n",
       "      <th>predicted identifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "      <td>134</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <td>124</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIYING</th>\n",
       "      <td>46</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STAND_TO_SIT</th>\n",
       "      <td>189</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIT_TO_STAND</th>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIT_TO_LIE</th>\n",
       "      <td>72</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIE_TO_SIT</th>\n",
       "      <td>56</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STAND_TO_LIE</th>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIE_TO_STAND</th>\n",
       "      <td>89</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Row index  real identifier  predicted identifier\n",
       "WALKING                    91                1                     1\n",
       "WALKING_UPSTAIRS          134                2                     2\n",
       "WALKING_DOWNSTAIRS        124                3                     3\n",
       "SITTING                    14                4                     4\n",
       "STANDING                    0                5                     5\n",
       "LIYING                     46                6                     6\n",
       "STAND_TO_SIT              189                7                     7\n",
       "SIT_TO_STAND               27                8                     8\n",
       "SIT_TO_LIE                 72                9                     9\n",
       "LIE_TO_SIT                 56               10                    10\n",
       "STAND_TO_LIE               40               11                    11\n",
       "LIE_TO_STAND               89               12                    12"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the final model II on dataset type II\n",
    "final_model_II.fit(X_2_train,y_2_train)\n",
    "# display results\n",
    "Samples_Results(X_2_test,y_2_test,final_model_II,indexes_II,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row index</th>\n",
       "      <th>real identifier</th>\n",
       "      <th>predicted identifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>WALKING</th>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_UPSTAIRS</th>\n",
       "      <td>135</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WALKING_DOWNSTAIRS</th>\n",
       "      <td>125</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SITTING</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STANDING</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIYING</th>\n",
       "      <td>47</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Postural Transition</th>\n",
       "      <td>190</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Row index  real identifier  predicted identifier\n",
       "WALKING                     92                1                     1\n",
       "WALKING_UPSTAIRS           135                2                     2\n",
       "WALKING_DOWNSTAIRS         125                3                     3\n",
       "SITTING                     15                4                     4\n",
       "STANDING                     1                5                     5\n",
       "LIYING                      47                6                     6\n",
       "Postural Transition        190                7                     7"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the final model III on dataset type III\n",
    "final_model_III.fit(X_3_train,y_3_train)\n",
    "# display results\n",
    "Samples_Results(X_3_test,y_3_test,final_model_III,indexes_III,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
